<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://lovkush-a.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lovkush-a.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-11-08T15:30:55-06:00</updated><id>https://lovkush-a.github.io/blog/feed.xml</id><title type="html">Lovkush Agarwal</title><subtitle>A blog for my data science learning and projects</subtitle><entry><title type="html">Squash rankings, Part III, All hail Bokeh!</title><link href="https://lovkush-a.github.io/blog/python/data%20science/data%20viz/2020/11/01/squash3.html" rel="alternate" type="text/html" title="Squash rankings, Part III, All hail Bokeh!" /><published>2020-11-01T00:00:00-05:00</published><updated>2020-11-01T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/data%20viz/2020/11/01/squash3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/data%20viz/2020/11/01/squash3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/09/28/squash2.html&quot;&gt;Squash rankings, Part II, dimension reduction and clustering&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/scraping/2020/09/17/squash1.html&quot;&gt;Squash rankings, Part I, Scraping wikipedia and data analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;One of my mentors at the Faculty Fellowship, Sania Jevtic, recommended I try using Bokeh to plot various charts I was making. I tried it and without too much effort I managed to get it to work. It is AMAZING! The interactivity you get from it is fantastic and allows for much easier understanding of your data and richer presentation of your data. I will try to illustrate by redrawing some of the charts from Part II of this series.&lt;/p&gt;

&lt;p&gt;I will be re-making the three charts below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_malecluster.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recall that the colours are clusters made by doing k-mean clustering on the original dataset, not doing clustering on each of the dimensionally-reduced datasets.&lt;/p&gt;

&lt;h2 id=&quot;bokeh-charts&quot;&gt;Bokeh charts&lt;/h2&gt;

&lt;html lang=&quot;en&quot;&gt;
  
  &lt;head&gt;
    
      &lt;meta charset=&quot;utf-8&quot; /&gt;
      &lt;title&gt;Bokeh Plot&lt;/title&gt;
      
      
        
          
        
        
          
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js&quot; integrity=&quot;sha384-T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
            Bokeh.set_log_level(&quot;info&quot;);
        &lt;/script&gt;
        
      
      
    
  &lt;/head&gt;
  
  
  &lt;body&gt;
    
      
        
          
          
            
              &lt;div class=&quot;bk-root&quot; id=&quot;a1121850-5f93-4e82-a97f-6e47190ce637&quot; data-root-id=&quot;3676&quot;&gt;&lt;/div&gt;
            
          
        
      
      
        &lt;script type=&quot;application/json&quot; id=&quot;3968&quot;&gt;
          {&quot;c67160e1-6f6b-4b1d-b68f-5b2a1204fa65&quot;:{&quot;roots&quot;:{&quot;references&quot;:[{&quot;attributes&quot;:{&quot;background_fill_color&quot;:&quot;white&quot;,&quot;below&quot;:[{&quot;id&quot;:&quot;3687&quot;}],&quot;center&quot;:[{&quot;id&quot;:&quot;3690&quot;},{&quot;id&quot;:&quot;3694&quot;}],&quot;left&quot;:[{&quot;id&quot;:&quot;3691&quot;}],&quot;renderers&quot;:[{&quot;id&quot;:&quot;3706&quot;}],&quot;title&quot;:{&quot;id&quot;:&quot;3677&quot;},&quot;toolbar&quot;:{&quot;id&quot;:&quot;3699&quot;},&quot;x_range&quot;:{&quot;id&quot;:&quot;3679&quot;},&quot;x_scale&quot;:{&quot;id&quot;:&quot;3683&quot;},&quot;y_range&quot;:{&quot;id&quot;:&quot;3681&quot;},&quot;y_scale&quot;:{&quot;id&quot;:&quot;3685&quot;}},&quot;id&quot;:&quot;3676&quot;,&quot;subtype&quot;:&quot;Figure&quot;,&quot;type&quot;:&quot;Plot&quot;},{&quot;attributes&quot;:{&quot;bottom_units&quot;:&quot;screen&quot;,&quot;fill_alpha&quot;:0.5,&quot;fill_color&quot;:&quot;lightgrey&quot;,&quot;left_units&quot;:&quot;screen&quot;,&quot;level&quot;:&quot;overlay&quot;,&quot;line_alpha&quot;:1.0,&quot;line_color&quot;:&quot;black&quot;,&quot;line_dash&quot;:[4,4],&quot;line_width&quot;:2,&quot;right_units&quot;:&quot;screen&quot;,&quot;top_units&quot;:&quot;screen&quot;},&quot;id&quot;:&quot;3698&quot;,&quot;type&quot;:&quot;BoxAnnotation&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3712&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{&quot;overlay&quot;:{&quot;id&quot;:&quot;3698&quot;}},&quot;id&quot;:&quot;3695&quot;,&quot;type&quot;:&quot;BoxZoomTool&quot;},{&quot;attributes&quot;:{&quot;text&quot;:&quot;PCA of Male Squash Player Rankings&quot;},&quot;id&quot;:&quot;3677&quot;,&quot;type&quot;:&quot;Title&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3714&quot;,&quot;type&quot;:&quot;Selection&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3713&quot;,&quot;type&quot;:&quot;UnionRenderers&quot;},{&quot;attributes&quot;:{&quot;fill_alpha&quot;:{&quot;value&quot;:0.1},&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3675&quot;}},&quot;line_alpha&quot;:{&quot;value&quot;:0.1},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3675&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3705&quot;,&quot;type&quot;:&quot;Scatter&quot;},{&quot;attributes&quot;:{&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3675&quot;}},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3675&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3704&quot;,&quot;type&quot;:&quot;Scatter&quot;},{&quot;attributes&quot;:{&quot;active_drag&quot;:&quot;auto&quot;,&quot;active_inspect&quot;:&quot;auto&quot;,&quot;active_multi&quot;:null,&quot;active_scroll&quot;:&quot;auto&quot;,&quot;active_tap&quot;:&quot;auto&quot;,&quot;tools&quot;:[{&quot;id&quot;:&quot;3695&quot;},{&quot;id&quot;:&quot;3696&quot;},{&quot;id&quot;:&quot;3697&quot;}]},&quot;id&quot;:&quot;3699&quot;,&quot;type&quot;:&quot;Toolbar&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3710&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3683&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{&quot;source&quot;:{&quot;id&quot;:&quot;3674&quot;}},&quot;id&quot;:&quot;3707&quot;,&quot;type&quot;:&quot;CDSView&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3687&quot;},&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3690&quot;,&quot;type&quot;:&quot;Grid&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3681&quot;,&quot;type&quot;:&quot;DataRange1d&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3710&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3692&quot;}},&quot;id&quot;:&quot;3691&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{&quot;callback&quot;:null,&quot;tooltips&quot;:[[&quot;Player&quot;,&quot;@players&quot;],[&quot;Best rank&quot;,&quot;@best_rank&quot;],[&quot;Years in Top 10&quot;,&quot;@years_in_top10&quot;],[&quot;Earliest year&quot;,&quot;@earliest_year&quot;]]},&quot;id&quot;:&quot;3696&quot;,&quot;type&quot;:&quot;HoverTool&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3688&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3685&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3692&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{&quot;data&quot;:{&quot;best_rank&quot;:[1,1,1,1,1,1,1,2,2,1,1,1,4,4,1,1,3,1,2,5,6,6,5,2,5,4,4,1,5,7,7,4,3,7,4,5,7,5,5,3,7,8,9,9,8,9,9,10,10,10,10],&quot;clusters&quot;:[&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;1&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;],&quot;earliest_year&quot;:[&quot;1996&quot;,&quot;2016&quot;,&quot;1996&quot;,&quot;1997&quot;,&quot;2010&quot;,&quot;2006&quot;,&quot;2003&quot;,&quot;1997&quot;,&quot;1996&quot;,&quot;2004&quot;,&quot;2000&quot;,&quot;2004&quot;,&quot;1998&quot;,&quot;2001&quot;,&quot;2001&quot;,&quot;2005&quot;,&quot;2002&quot;,&quot;2003&quot;,&quot;2015&quot;,&quot;1998&quot;,&quot;1996&quot;,&quot;1998&quot;,&quot;2016&quot;,&quot;1999&quot;,&quot;2017&quot;,&quot;2012&quot;,&quot;2014&quot;,&quot;2002&quot;,&quot;2015&quot;,&quot;2019&quot;,&quot;1999&quot;,&quot;2000&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;2013&quot;,&quot;2008&quot;,&quot;1996&quot;,&quot;2014&quot;,&quot;2001&quot;,&quot;1996&quot;,&quot;2010&quot;,&quot;1999&quot;,&quot;2007&quot;,&quot;2015&quot;,&quot;2000&quot;,&quot;1998&quot;,&quot;2011&quot;,&quot;2018&quot;,&quot;2012&quot;],&quot;players&quot;:[&quot; Peter Nicol&quot;,&quot; Ali Farag&quot;,&quot; Jansher Khan&quot;,&quot; Jonathon Power&quot;,&quot; Mohamed El Shorbagy&quot;,&quot; Ramy Ashour&quot;,&quot; Gr\u00e9gory Gaultier&quot;,&quot; Ahmed Barada&quot;,&quot; Rodney Eyles&quot;,&quot; Nick Matthew&quot;,&quot; David Palmer&quot;,&quot; Amr Shabana&quot;,&quot; Paul Johnson&quot;,&quot; Stewart Boswell&quot;,&quot; Thierry Lincou&quot;,&quot; James Willstrop&quot;,&quot; Anthony Ricketts&quot;,&quot; Karim Darwish&quot;,&quot; Karim Abdel Gawad&quot;,&quot; Martin Heath&quot;,&quot; Del Harris&quot;,&quot; Dan Jenson&quot;,&quot; Marwan El Shorbagy&quot;,&quot; John White&quot;,&quot; Paul Coll&quot;,&quot; Omar Mosaad&quot;,&quot; Tarek Momen&quot;,&quot; Lee Beachill&quot;,&quot; Miguel \u00c1ngel Rodr\u00edguez&quot;,&quot; Diego Elias&quot;,&quot; Stefan Casteleyn&quot;,&quot; David Evans&quot;,&quot; Simon Parke&quot;,&quot; Craig Rowland&quot;,&quot; Chris Walker&quot;,&quot; Brett Martin&quot;,&quot; Borja Gol\u00e1n&quot;,&quot; Peter Barker&quot;,&quot; Anthony Hill&quot;,&quot; Simon R\u00f6sner&quot;,&quot; Ong Beng Hee&quot;,&quot; Mark Chaloner&quot;,&quot; Laurens Jan Anjema&quot;,&quot; Alex Gough&quot;,&quot; Wael El Hindi&quot;,&quot; Mathieu Castagnet&quot;,&quot; Paul Price&quot;,&quot; Derek Ryan&quot;,&quot; Mohd Azlan Iskandar&quot;,&quot; Mohamed Abouelghar&quot;,&quot; Daryl Selby&quot;],&quot;x&quot;:{&quot;__ndarray__&quot;:&quot;6UhB5GHoHcAojcaOrzkvQAhxhMmXlSrAe75Q4b9tG8AOASrFpo4oQBvkZLzOjx1ALxPLk31nHUAO6vfU9CwmwA8dG7gapirANUJq09W8HEDL7xCNDB/Mv9kilmgKnxJAZ7dMcoAMJcBxKm3pQrIcwK+F3k9H1ti/bVEc7PReHkAFSjlwJ3wKwIkKaXqWYglAwSV0hpFqLkDVFAB8vh4lwNv1fy+daizAekavFo91KMCPNeur0lkvQC7pIBNVpxDAg0B0LyI4MEBDvhjjXWMlQDyycOWA+yxA80dosim/CMB9dG6Vt/EtQMqhZFhrUTFAVMkVDBGUJcAXKWWiX9kgwOOp5jH5FCfAEdjQzrMCLsAQkl77jRcswFtSSztCLSzANiv/PppvI0BdnBIyaMAbQASICBpRAynAyL3SGnkvLUCfgB2hbRgZwPQpCtAPfiTAT7qcoqb1EkBvfrMPI8YjwMBjYNfb1wFAfiUyVJYyKUCWMlEfxOIgwOW6QkXFLSjAlrTPt6K4GEABKc47kQQwQKY50gXm1SBA&quot;,&quot;dtype&quot;:&quot;float64&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;y&quot;:{&quot;__ndarray__&quot;:&quot;ofkUQYeBIUBnMV8nQcTZP9//q5jorf8/AeCpTCB1HUCrWn9nxbkaQL0y7FHO6B9A7P3MIRjMKEDdyNBCLez/P+WHSiogrPI/u0qRU0DFJUCKi1+Y3qUhQG5vrl/kFyBApE74wNj/0b/jcelCScv5v+evDqxlbx1AbDmye2ewIEDifEks4yrpP6rt5HqkFR1Ap1Mg3rsh7z9O88gFDv7vv3BcyoUXOQLA8cI233iqC8CTCwiwp1ADwEcLHJHHBBJAa+Ccz+LmDMBR2fUuU9/+v74Cx6Zmr+K/YizlZZJAAUBUDXYkYdQGwIamBxPlZxvA+sqaOz9iEcBo6ULruDz/v9xojz1/e/0/r+2UtszCD8Bb0+s+NDj3v2EVHNrVsf+/w607OxOuFMAkxvCIYf3xPw418P9/0eu/17JwpFwO2D+axfpGHzQHwBeZ7CHfgP6/ZJqKdM/+HMC+auMmlMMTwMOUF/9N7xHAx4A60xjIG8Dxz99+BbsUwPxBg3QmCBrA8wFFIOlFIMDFDvgl5gYiwMckJHT6Ux3A&quot;,&quot;dtype&quot;:&quot;float64&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;years_in_top10&quot;:[10,4,3,9,10,11,15,4,3,14,11,11,3,2,10,11,4,10,6,3,2,1,4,7,3,3,5,5,3,1,1,2,5,1,2,2,2,7,3,6,3,3,1,2,3,2,2,1,1,1,2]},&quot;selected&quot;:{&quot;id&quot;:&quot;3714&quot;},&quot;selection_policy&quot;:{&quot;id&quot;:&quot;3713&quot;}},&quot;id&quot;:&quot;3674&quot;,&quot;type&quot;:&quot;ColumnDataSource&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3679&quot;,&quot;type&quot;:&quot;DataRange1d&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3712&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3688&quot;}},&quot;id&quot;:&quot;3687&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3697&quot;,&quot;type&quot;:&quot;ResetTool&quot;},{&quot;attributes&quot;:{&quot;data_source&quot;:{&quot;id&quot;:&quot;3674&quot;},&quot;glyph&quot;:{&quot;id&quot;:&quot;3704&quot;},&quot;hover_glyph&quot;:null,&quot;muted_glyph&quot;:null,&quot;nonselection_glyph&quot;:{&quot;id&quot;:&quot;3705&quot;},&quot;selection_glyph&quot;:null,&quot;view&quot;:{&quot;id&quot;:&quot;3707&quot;}},&quot;id&quot;:&quot;3706&quot;,&quot;type&quot;:&quot;GlyphRenderer&quot;},{&quot;attributes&quot;:{&quot;factors&quot;:[&quot;0&quot;,&quot;1&quot;,&quot;2&quot;],&quot;palette&quot;:[&quot;#1f77b4&quot;,&quot;#ff7f0e&quot;,&quot;#2ca02c&quot;]},&quot;id&quot;:&quot;3675&quot;,&quot;type&quot;:&quot;CategoricalColorMapper&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3691&quot;},&quot;dimension&quot;:1,&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3694&quot;,&quot;type&quot;:&quot;Grid&quot;}],&quot;root_ids&quot;:[&quot;3676&quot;]},&quot;title&quot;:&quot;Bokeh Application&quot;,&quot;version&quot;:&quot;2.2.3&quot;}}
        &lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('3968').textContent;
                  var render_items = [{&quot;docid&quot;:&quot;c67160e1-6f6b-4b1d-b68f-5b2a1204fa65&quot;,&quot;root_ids&quot;:[&quot;3676&quot;],&quot;roots&quot;:{&quot;3676&quot;:&quot;a1121850-5f93-4e82-a97f-6e47190ce637&quot;}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts &gt; 100) {
                          clearInterval(timer);
                          console.log(&quot;Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing&quot;);
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != &quot;loading&quot;) fn();
            else document.addEventListener(&quot;DOMContentLoaded&quot;, fn);
          })();
        &lt;/script&gt;
    
  &lt;/body&gt;
  
&lt;/html&gt;

&lt;html lang=&quot;en&quot;&gt;
  
  &lt;head&gt;
    
      &lt;meta charset=&quot;utf-8&quot; /&gt;
      &lt;title&gt;Bokeh Plot&lt;/title&gt;
      
      
        
          
        
        
          
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js&quot; integrity=&quot;sha384-T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
            Bokeh.set_log_level(&quot;info&quot;);
        &lt;/script&gt;
        
      
      
    
  &lt;/head&gt;
  
  
  &lt;body&gt;
    
      
        
          
          
            
              &lt;div class=&quot;bk-root&quot; id=&quot;bcf7546e-220d-461c-b866-c8bf1b1deab6&quot; data-root-id=&quot;3381&quot;&gt;&lt;/div&gt;
            
          
        
      
      
        &lt;script type=&quot;application/json&quot; id=&quot;3665&quot;&gt;
          {&quot;a027ea3a-ca4e-4258-936c-ac9559330638&quot;:{&quot;roots&quot;:{&quot;references&quot;:[{&quot;attributes&quot;:{&quot;background_fill_color&quot;:&quot;white&quot;,&quot;below&quot;:[{&quot;id&quot;:&quot;3392&quot;}],&quot;center&quot;:[{&quot;id&quot;:&quot;3395&quot;},{&quot;id&quot;:&quot;3399&quot;}],&quot;left&quot;:[{&quot;id&quot;:&quot;3396&quot;}],&quot;renderers&quot;:[{&quot;id&quot;:&quot;3411&quot;}],&quot;title&quot;:{&quot;id&quot;:&quot;3382&quot;},&quot;toolbar&quot;:{&quot;id&quot;:&quot;3404&quot;},&quot;x_range&quot;:{&quot;id&quot;:&quot;3384&quot;},&quot;x_scale&quot;:{&quot;id&quot;:&quot;3388&quot;},&quot;y_range&quot;:{&quot;id&quot;:&quot;3386&quot;},&quot;y_scale&quot;:{&quot;id&quot;:&quot;3390&quot;}},&quot;id&quot;:&quot;3381&quot;,&quot;subtype&quot;:&quot;Figure&quot;,&quot;type&quot;:&quot;Plot&quot;},{&quot;attributes&quot;:{&quot;data_source&quot;:{&quot;id&quot;:&quot;3379&quot;},&quot;glyph&quot;:{&quot;id&quot;:&quot;3409&quot;},&quot;hover_glyph&quot;:null,&quot;muted_glyph&quot;:null,&quot;nonselection_glyph&quot;:{&quot;id&quot;:&quot;3410&quot;},&quot;selection_glyph&quot;:null,&quot;view&quot;:{&quot;id&quot;:&quot;3412&quot;}},&quot;id&quot;:&quot;3411&quot;,&quot;type&quot;:&quot;GlyphRenderer&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3402&quot;,&quot;type&quot;:&quot;ResetTool&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3388&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3390&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3380&quot;}},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3380&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3409&quot;,&quot;type&quot;:&quot;Scatter&quot;},{&quot;attributes&quot;:{&quot;callback&quot;:null,&quot;tooltips&quot;:[[&quot;Player&quot;,&quot;@players&quot;],[&quot;Best rank&quot;,&quot;@best_rank&quot;],[&quot;Years in Top 10&quot;,&quot;@years_in_top10&quot;],[&quot;Earliest year&quot;,&quot;@earliest_year&quot;]]},&quot;id&quot;:&quot;3401&quot;,&quot;type&quot;:&quot;HoverTool&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3397&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3393&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{&quot;fill_alpha&quot;:{&quot;value&quot;:0.1},&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3380&quot;}},&quot;line_alpha&quot;:{&quot;value&quot;:0.1},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3380&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3410&quot;,&quot;type&quot;:&quot;Scatter&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3415&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3397&quot;}},&quot;id&quot;:&quot;3396&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3417&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3393&quot;}},&quot;id&quot;:&quot;3392&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3418&quot;,&quot;type&quot;:&quot;UnionRenderers&quot;},{&quot;attributes&quot;:{&quot;text&quot;:&quot;tSNE of Male Squash Player Rankings&quot;},&quot;id&quot;:&quot;3382&quot;,&quot;type&quot;:&quot;Title&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3419&quot;,&quot;type&quot;:&quot;Selection&quot;},{&quot;attributes&quot;:{&quot;overlay&quot;:{&quot;id&quot;:&quot;3403&quot;}},&quot;id&quot;:&quot;3400&quot;,&quot;type&quot;:&quot;BoxZoomTool&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3396&quot;},&quot;dimension&quot;:1,&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3399&quot;,&quot;type&quot;:&quot;Grid&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3392&quot;},&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3395&quot;,&quot;type&quot;:&quot;Grid&quot;},{&quot;attributes&quot;:{&quot;data&quot;:{&quot;best_rank&quot;:[1,1,1,1,1,1,1,2,2,1,1,1,4,4,1,1,3,1,2,5,6,6,5,2,5,4,4,1,5,7,7,4,3,7,4,5,7,5,5,3,7,8,9,9,8,9,9,10,10,10,10],&quot;clusters&quot;:[&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;1&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;],&quot;earliest_year&quot;:[&quot;1996&quot;,&quot;2016&quot;,&quot;1996&quot;,&quot;1997&quot;,&quot;2010&quot;,&quot;2006&quot;,&quot;2003&quot;,&quot;1997&quot;,&quot;1996&quot;,&quot;2004&quot;,&quot;2000&quot;,&quot;2004&quot;,&quot;1998&quot;,&quot;2001&quot;,&quot;2001&quot;,&quot;2005&quot;,&quot;2002&quot;,&quot;2003&quot;,&quot;2015&quot;,&quot;1998&quot;,&quot;1996&quot;,&quot;1998&quot;,&quot;2016&quot;,&quot;1999&quot;,&quot;2017&quot;,&quot;2012&quot;,&quot;2014&quot;,&quot;2002&quot;,&quot;2015&quot;,&quot;2019&quot;,&quot;1999&quot;,&quot;2000&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;2013&quot;,&quot;2008&quot;,&quot;1996&quot;,&quot;2014&quot;,&quot;2001&quot;,&quot;1996&quot;,&quot;2010&quot;,&quot;1999&quot;,&quot;2007&quot;,&quot;2015&quot;,&quot;2000&quot;,&quot;1998&quot;,&quot;2011&quot;,&quot;2018&quot;,&quot;2012&quot;],&quot;players&quot;:[&quot; Peter Nicol&quot;,&quot; Ali Farag&quot;,&quot; Jansher Khan&quot;,&quot; Jonathon Power&quot;,&quot; Mohamed El Shorbagy&quot;,&quot; Ramy Ashour&quot;,&quot; Gr\u00e9gory Gaultier&quot;,&quot; Ahmed Barada&quot;,&quot; Rodney Eyles&quot;,&quot; Nick Matthew&quot;,&quot; David Palmer&quot;,&quot; Amr Shabana&quot;,&quot; Paul Johnson&quot;,&quot; Stewart Boswell&quot;,&quot; Thierry Lincou&quot;,&quot; James Willstrop&quot;,&quot; Anthony Ricketts&quot;,&quot; Karim Darwish&quot;,&quot; Karim Abdel Gawad&quot;,&quot; Martin Heath&quot;,&quot; Del Harris&quot;,&quot; Dan Jenson&quot;,&quot; Marwan El Shorbagy&quot;,&quot; John White&quot;,&quot; Paul Coll&quot;,&quot; Omar Mosaad&quot;,&quot; Tarek Momen&quot;,&quot; Lee Beachill&quot;,&quot; Miguel \u00c1ngel Rodr\u00edguez&quot;,&quot; Diego Elias&quot;,&quot; Stefan Casteleyn&quot;,&quot; David Evans&quot;,&quot; Simon Parke&quot;,&quot; Craig Rowland&quot;,&quot; Chris Walker&quot;,&quot; Brett Martin&quot;,&quot; Borja Gol\u00e1n&quot;,&quot; Peter Barker&quot;,&quot; Anthony Hill&quot;,&quot; Simon R\u00f6sner&quot;,&quot; Ong Beng Hee&quot;,&quot; Mark Chaloner&quot;,&quot; Laurens Jan Anjema&quot;,&quot; Alex Gough&quot;,&quot; Wael El Hindi&quot;,&quot; Mathieu Castagnet&quot;,&quot; Paul Price&quot;,&quot; Derek Ryan&quot;,&quot; Mohd Azlan Iskandar&quot;,&quot; Mohamed Abouelghar&quot;,&quot; Daryl Selby&quot;],&quot;x&quot;:{&quot;__ndarray__&quot;:&quot;A0Agw7mNwEIkWZbBINwWwwpQ2MLE1OfC8YKmwiN27MHR+IDBYyS6wtgOBMOai+LCdYctwm+7UcKSivnCG4zNwiW598I1bu3CvDvGQs3aV8J7XKrCcRujwtVc9EKegQbDlMkFQ9Q+GUNf2eJCjzAAw1cRAENEeBRDhsGjwtozK8JiQirCT66vwvNrccLCBYrCImYkQzPfFEMod2HCvBHMQtonVcIOiXrC+Y9PQ9oSkMKh1VRDhuUrQ1uqgcK0gKbC6MtEQ2rZJkM5Sj9D&quot;,&quot;dtype&quot;:&quot;float32&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;y&quot;:{&quot;__ndarray__&quot;:&quot;ARc5wtM3bsJgsRZDH/oqwkn6BsMVnevCSRHjwl8jCkOeFQxD0tzWwhqNoMIenczC+ob8QrEz3UKbIJDCAObqwvGuT8GW27bCB3qTwhc8AENlRhhD/2oKQw2kh8ICvArCDwl+wjKj2MIF9qXCLfLAwSaEnsIm5HPCO+X9QqHLu0IsUTlD1oMjQ9sCK0OtnDFDW53LwtDi9sIl+zdDVweuwi56o0ILV0hCt6zPwhZpdkIcE+fC6Myown3vikItEYdCIUPbwj9skcKE2sTC&quot;,&quot;dtype&quot;:&quot;float32&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;years_in_top10&quot;:[10,4,3,9,10,11,15,4,3,14,11,11,3,2,10,11,4,10,6,3,2,1,4,7,3,3,5,5,3,1,1,2,5,1,2,2,2,7,3,6,3,3,1,2,3,2,2,1,1,1,2]},&quot;selected&quot;:{&quot;id&quot;:&quot;3419&quot;},&quot;selection_policy&quot;:{&quot;id&quot;:&quot;3418&quot;}},&quot;id&quot;:&quot;3379&quot;,&quot;type&quot;:&quot;ColumnDataSource&quot;},{&quot;attributes&quot;:{&quot;active_drag&quot;:&quot;auto&quot;,&quot;active_inspect&quot;:&quot;auto&quot;,&quot;active_multi&quot;:null,&quot;active_scroll&quot;:&quot;auto&quot;,&quot;active_tap&quot;:&quot;auto&quot;,&quot;tools&quot;:[{&quot;id&quot;:&quot;3400&quot;},{&quot;id&quot;:&quot;3401&quot;},{&quot;id&quot;:&quot;3402&quot;}]},&quot;id&quot;:&quot;3404&quot;,&quot;type&quot;:&quot;Toolbar&quot;},{&quot;attributes&quot;:{&quot;source&quot;:{&quot;id&quot;:&quot;3379&quot;}},&quot;id&quot;:&quot;3412&quot;,&quot;type&quot;:&quot;CDSView&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3415&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3384&quot;,&quot;type&quot;:&quot;DataRange1d&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3417&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{&quot;bottom_units&quot;:&quot;screen&quot;,&quot;fill_alpha&quot;:0.5,&quot;fill_color&quot;:&quot;lightgrey&quot;,&quot;left_units&quot;:&quot;screen&quot;,&quot;level&quot;:&quot;overlay&quot;,&quot;line_alpha&quot;:1.0,&quot;line_color&quot;:&quot;black&quot;,&quot;line_dash&quot;:[4,4],&quot;line_width&quot;:2,&quot;right_units&quot;:&quot;screen&quot;,&quot;top_units&quot;:&quot;screen&quot;},&quot;id&quot;:&quot;3403&quot;,&quot;type&quot;:&quot;BoxAnnotation&quot;},{&quot;attributes&quot;:{&quot;factors&quot;:[&quot;0&quot;,&quot;1&quot;,&quot;2&quot;],&quot;palette&quot;:[&quot;#1f77b4&quot;,&quot;#ff7f0e&quot;,&quot;#2ca02c&quot;]},&quot;id&quot;:&quot;3380&quot;,&quot;type&quot;:&quot;CategoricalColorMapper&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3386&quot;,&quot;type&quot;:&quot;DataRange1d&quot;}],&quot;root_ids&quot;:[&quot;3381&quot;]},&quot;title&quot;:&quot;Bokeh Application&quot;,&quot;version&quot;:&quot;2.2.3&quot;}}
        &lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('3665').textContent;
                  var render_items = [{&quot;docid&quot;:&quot;a027ea3a-ca4e-4258-936c-ac9559330638&quot;,&quot;root_ids&quot;:[&quot;3381&quot;],&quot;roots&quot;:{&quot;3381&quot;:&quot;bcf7546e-220d-461c-b866-c8bf1b1deab6&quot;}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts &gt; 100) {
                          clearInterval(timer);
                          console.log(&quot;Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing&quot;);
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != &quot;loading&quot;) fn();
            else document.addEventListener(&quot;DOMContentLoaded&quot;, fn);
          })();
        &lt;/script&gt;
    
  &lt;/body&gt;
  
&lt;/html&gt;

&lt;html lang=&quot;en&quot;&gt;
  
  &lt;head&gt;
    
      &lt;meta charset=&quot;utf-8&quot; /&gt;
      &lt;title&gt;Bokeh Plot&lt;/title&gt;
      
      
        
          
        
        
          
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js&quot; integrity=&quot;sha384-T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
            Bokeh.set_log_level(&quot;info&quot;);
        &lt;/script&gt;
        
      
      
    
  &lt;/head&gt;
  
  
  &lt;body&gt;
    
      
        
          
          
            
              &lt;div class=&quot;bk-root&quot; id=&quot;77dbe8d8-934a-4568-938e-5fd1ff971c0c&quot; data-root-id=&quot;3094&quot;&gt;&lt;/div&gt;
            
          
        
      
      
        &lt;script type=&quot;application/json&quot; id=&quot;3370&quot;&gt;
          {&quot;6ecdfff2-0dec-4bda-b5d9-aa2a2108e600&quot;:{&quot;roots&quot;:{&quot;references&quot;:[{&quot;attributes&quot;:{&quot;background_fill_color&quot;:&quot;white&quot;,&quot;below&quot;:[{&quot;id&quot;:&quot;3105&quot;}],&quot;center&quot;:[{&quot;id&quot;:&quot;3108&quot;},{&quot;id&quot;:&quot;3112&quot;}],&quot;left&quot;:[{&quot;id&quot;:&quot;3109&quot;}],&quot;renderers&quot;:[{&quot;id&quot;:&quot;3124&quot;}],&quot;title&quot;:{&quot;id&quot;:&quot;3095&quot;},&quot;toolbar&quot;:{&quot;id&quot;:&quot;3117&quot;},&quot;x_range&quot;:{&quot;id&quot;:&quot;3097&quot;},&quot;x_scale&quot;:{&quot;id&quot;:&quot;3101&quot;},&quot;y_range&quot;:{&quot;id&quot;:&quot;3099&quot;},&quot;y_scale&quot;:{&quot;id&quot;:&quot;3103&quot;}},&quot;id&quot;:&quot;3094&quot;,&quot;subtype&quot;:&quot;Figure&quot;,&quot;type&quot;:&quot;Plot&quot;},{&quot;attributes&quot;:{&quot;data&quot;:{&quot;best_rank&quot;:[1,1,1,1,1,1,1,2,2,1,1,1,4,4,1,1,3,1,2,5,6,6,5,2,5,4,4,1,5,7,7,4,3,7,4,5,7,5,5,3,7,8,9,9,8,9,9,10,10,10,10],&quot;clusters&quot;:[&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;1&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;0&quot;,&quot;0&quot;,&quot;2&quot;,&quot;2&quot;,&quot;2&quot;],&quot;earliest_year&quot;:[&quot;1996&quot;,&quot;2016&quot;,&quot;1996&quot;,&quot;1997&quot;,&quot;2010&quot;,&quot;2006&quot;,&quot;2003&quot;,&quot;1997&quot;,&quot;1996&quot;,&quot;2004&quot;,&quot;2000&quot;,&quot;2004&quot;,&quot;1998&quot;,&quot;2001&quot;,&quot;2001&quot;,&quot;2005&quot;,&quot;2002&quot;,&quot;2003&quot;,&quot;2015&quot;,&quot;1998&quot;,&quot;1996&quot;,&quot;1998&quot;,&quot;2016&quot;,&quot;1999&quot;,&quot;2017&quot;,&quot;2012&quot;,&quot;2014&quot;,&quot;2002&quot;,&quot;2015&quot;,&quot;2019&quot;,&quot;1999&quot;,&quot;2000&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;1996&quot;,&quot;2013&quot;,&quot;2008&quot;,&quot;1996&quot;,&quot;2014&quot;,&quot;2001&quot;,&quot;1996&quot;,&quot;2010&quot;,&quot;1999&quot;,&quot;2007&quot;,&quot;2015&quot;,&quot;2000&quot;,&quot;1998&quot;,&quot;2011&quot;,&quot;2018&quot;,&quot;2012&quot;],&quot;players&quot;:[&quot; Peter Nicol&quot;,&quot; Ali Farag&quot;,&quot; Jansher Khan&quot;,&quot; Jonathon Power&quot;,&quot; Mohamed El Shorbagy&quot;,&quot; Ramy Ashour&quot;,&quot; Gr\u00e9gory Gaultier&quot;,&quot; Ahmed Barada&quot;,&quot; Rodney Eyles&quot;,&quot; Nick Matthew&quot;,&quot; David Palmer&quot;,&quot; Amr Shabana&quot;,&quot; Paul Johnson&quot;,&quot; Stewart Boswell&quot;,&quot; Thierry Lincou&quot;,&quot; James Willstrop&quot;,&quot; Anthony Ricketts&quot;,&quot; Karim Darwish&quot;,&quot; Karim Abdel Gawad&quot;,&quot; Martin Heath&quot;,&quot; Del Harris&quot;,&quot; Dan Jenson&quot;,&quot; Marwan El Shorbagy&quot;,&quot; John White&quot;,&quot; Paul Coll&quot;,&quot; Omar Mosaad&quot;,&quot; Tarek Momen&quot;,&quot; Lee Beachill&quot;,&quot; Miguel \u00c1ngel Rodr\u00edguez&quot;,&quot; Diego Elias&quot;,&quot; Stefan Casteleyn&quot;,&quot; David Evans&quot;,&quot; Simon Parke&quot;,&quot; Craig Rowland&quot;,&quot; Chris Walker&quot;,&quot; Brett Martin&quot;,&quot; Borja Gol\u00e1n&quot;,&quot; Peter Barker&quot;,&quot; Anthony Hill&quot;,&quot; Simon R\u00f6sner&quot;,&quot; Ong Beng Hee&quot;,&quot; Mark Chaloner&quot;,&quot; Laurens Jan Anjema&quot;,&quot; Alex Gough&quot;,&quot; Wael El Hindi&quot;,&quot; Mathieu Castagnet&quot;,&quot; Paul Price&quot;,&quot; Derek Ryan&quot;,&quot; Mohd Azlan Iskandar&quot;,&quot; Mohamed Abouelghar&quot;,&quot; Daryl Selby&quot;],&quot;x&quot;:{&quot;__ndarray__&quot;:&quot;GLQIQcz3QkCSxxtB6B8GQccG4EBGyeNAxJ/9QOyNF0HgGhpB00P4QG0w9kAOKuxAFyUQQUSECkG12/9ACLXtQDC6AEF59/BAyAU/QKp2DUENexFBuV8LQRiLUkDFNv9AoG9CQDgXhUAoaGFAVCEBQRw2WUBqW1tAC64HQQoHB0F3KRVBTRcNQS83GEHvrhNBbaKLQOOzq0CUZQlB5hdjQIhJ/EAjpv5AkcKeQKmQ+UAqc6pAY/6HQKQnAEG28QNBhqqTQIsEd0Aa+5JA&quot;,&quot;dtype&quot;:&quot;float32&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;y&quot;:{&quot;__ndarray__&quot;:&quot;kzI6PqVWgEBAXaO/q1MVP9pCJkDfQA1AnwfxP5QVYr/DpLC/oMoBQN61iT9XYPQ/NMCPvz2TLr9LLJI/fKYWQKlzJL5WHMs/p/6FQHqyrr8gnQfAURrbv8lne0AYIAc/i4xkQMjJaUDGV4xAuf0wPtOae0A6VltAvF3Tv91whL9x7M6/gdQRwPwgCcAPwe+/BmCJQIxSX0BNcA/AXwZlQGJDh79nA/u//UCJQOzC0b/58IJAmqd9QE8qwb+aUvW/XamNQP/VgUC0hYBA&quot;,&quot;dtype&quot;:&quot;float32&quot;,&quot;order&quot;:&quot;little&quot;,&quot;shape&quot;:[51]},&quot;years_in_top10&quot;:[10,4,3,9,10,11,15,4,3,14,11,11,3,2,10,11,4,10,6,3,2,1,4,7,3,3,5,5,3,1,1,2,5,1,2,2,2,7,3,6,3,3,1,2,3,2,2,1,1,1,2]},&quot;selected&quot;:{&quot;id&quot;:&quot;3132&quot;},&quot;selection_policy&quot;:{&quot;id&quot;:&quot;3131&quot;}},&quot;id&quot;:&quot;3092&quot;,&quot;type&quot;:&quot;ColumnDataSource&quot;},{&quot;attributes&quot;:{&quot;fill_alpha&quot;:{&quot;value&quot;:0.1},&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3093&quot;}},&quot;line_alpha&quot;:{&quot;value&quot;:0.1},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3093&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3123&quot;,&quot;type&quot;:&quot;Scatter&quot;},{&quot;attributes&quot;:{&quot;data_source&quot;:{&quot;id&quot;:&quot;3092&quot;},&quot;glyph&quot;:{&quot;id&quot;:&quot;3122&quot;},&quot;hover_glyph&quot;:null,&quot;muted_glyph&quot;:null,&quot;nonselection_glyph&quot;:{&quot;id&quot;:&quot;3123&quot;},&quot;selection_glyph&quot;:null,&quot;view&quot;:{&quot;id&quot;:&quot;3125&quot;}},&quot;id&quot;:&quot;3124&quot;,&quot;type&quot;:&quot;GlyphRenderer&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3110&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3099&quot;,&quot;type&quot;:&quot;DataRange1d&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3131&quot;,&quot;type&quot;:&quot;UnionRenderers&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3115&quot;,&quot;type&quot;:&quot;ResetTool&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3128&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3130&quot;,&quot;type&quot;:&quot;BasicTickFormatter&quot;},{&quot;attributes&quot;:{&quot;text&quot;:&quot;UMAP of Male Squash Player Rankings&quot;},&quot;id&quot;:&quot;3095&quot;,&quot;type&quot;:&quot;Title&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3103&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3128&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3110&quot;}},&quot;id&quot;:&quot;3109&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3106&quot;,&quot;type&quot;:&quot;BasicTicker&quot;},{&quot;attributes&quot;:{&quot;active_drag&quot;:&quot;auto&quot;,&quot;active_inspect&quot;:&quot;auto&quot;,&quot;active_multi&quot;:null,&quot;active_scroll&quot;:&quot;auto&quot;,&quot;active_tap&quot;:&quot;auto&quot;,&quot;tools&quot;:[{&quot;id&quot;:&quot;3113&quot;},{&quot;id&quot;:&quot;3114&quot;},{&quot;id&quot;:&quot;3115&quot;}]},&quot;id&quot;:&quot;3117&quot;,&quot;type&quot;:&quot;Toolbar&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3097&quot;,&quot;type&quot;:&quot;DataRange1d&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3101&quot;,&quot;type&quot;:&quot;LinearScale&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3105&quot;},&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3108&quot;,&quot;type&quot;:&quot;Grid&quot;},{&quot;attributes&quot;:{&quot;overlay&quot;:{&quot;id&quot;:&quot;3116&quot;}},&quot;id&quot;:&quot;3113&quot;,&quot;type&quot;:&quot;BoxZoomTool&quot;},{&quot;attributes&quot;:{&quot;formatter&quot;:{&quot;id&quot;:&quot;3130&quot;},&quot;ticker&quot;:{&quot;id&quot;:&quot;3106&quot;}},&quot;id&quot;:&quot;3105&quot;,&quot;type&quot;:&quot;LinearAxis&quot;},{&quot;attributes&quot;:{&quot;bottom_units&quot;:&quot;screen&quot;,&quot;fill_alpha&quot;:0.5,&quot;fill_color&quot;:&quot;lightgrey&quot;,&quot;left_units&quot;:&quot;screen&quot;,&quot;level&quot;:&quot;overlay&quot;,&quot;line_alpha&quot;:1.0,&quot;line_color&quot;:&quot;black&quot;,&quot;line_dash&quot;:[4,4],&quot;line_width&quot;:2,&quot;right_units&quot;:&quot;screen&quot;,&quot;top_units&quot;:&quot;screen&quot;},&quot;id&quot;:&quot;3116&quot;,&quot;type&quot;:&quot;BoxAnnotation&quot;},{&quot;attributes&quot;:{&quot;source&quot;:{&quot;id&quot;:&quot;3092&quot;}},&quot;id&quot;:&quot;3125&quot;,&quot;type&quot;:&quot;CDSView&quot;},{&quot;attributes&quot;:{},&quot;id&quot;:&quot;3132&quot;,&quot;type&quot;:&quot;Selection&quot;},{&quot;attributes&quot;:{&quot;axis&quot;:{&quot;id&quot;:&quot;3109&quot;},&quot;dimension&quot;:1,&quot;grid_line_color&quot;:null,&quot;ticker&quot;:null},&quot;id&quot;:&quot;3112&quot;,&quot;type&quot;:&quot;Grid&quot;},{&quot;attributes&quot;:{&quot;factors&quot;:[&quot;0&quot;,&quot;1&quot;,&quot;2&quot;],&quot;palette&quot;:[&quot;#1f77b4&quot;,&quot;#ff7f0e&quot;,&quot;#2ca02c&quot;]},&quot;id&quot;:&quot;3093&quot;,&quot;type&quot;:&quot;CategoricalColorMapper&quot;},{&quot;attributes&quot;:{&quot;callback&quot;:null,&quot;tooltips&quot;:[[&quot;Player&quot;,&quot;@players&quot;],[&quot;Best rank&quot;,&quot;@best_rank&quot;],[&quot;Years in Top 10&quot;,&quot;@years_in_top10&quot;],[&quot;Earliest year&quot;,&quot;@earliest_year&quot;]]},&quot;id&quot;:&quot;3114&quot;,&quot;type&quot;:&quot;HoverTool&quot;},{&quot;attributes&quot;:{&quot;fill_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3093&quot;}},&quot;line_color&quot;:{&quot;field&quot;:&quot;clusters&quot;,&quot;transform&quot;:{&quot;id&quot;:&quot;3093&quot;}},&quot;x&quot;:{&quot;field&quot;:&quot;x&quot;},&quot;y&quot;:{&quot;field&quot;:&quot;y&quot;}},&quot;id&quot;:&quot;3122&quot;,&quot;type&quot;:&quot;Scatter&quot;}],&quot;root_ids&quot;:[&quot;3094&quot;]},&quot;title&quot;:&quot;Bokeh Application&quot;,&quot;version&quot;:&quot;2.2.3&quot;}}
        &lt;/script&gt;
        &lt;script type=&quot;text/javascript&quot;&gt;
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('3370').textContent;
                  var render_items = [{&quot;docid&quot;:&quot;6ecdfff2-0dec-4bda-b5d9-aa2a2108e600&quot;,&quot;root_ids&quot;:[&quot;3094&quot;],&quot;roots&quot;:{&quot;3094&quot;:&quot;77dbe8d8-934a-4568-938e-5fd1ff971c0c&quot;}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts &gt; 100) {
                          clearInterval(timer);
                          console.log(&quot;Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing&quot;);
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != &quot;loading&quot;) fn();
            else document.addEventListener(&quot;DOMContentLoaded&quot;, fn);
          })();
        &lt;/script&gt;
    
  &lt;/body&gt;
  
&lt;/html&gt;

&lt;p&gt;So what’s so amazing about these? They look basically the same. The big advantage is in their interactivity! Try hovering your mouse over the points. What happens?&lt;/p&gt;

&lt;p&gt;Cool, right! I can’t stop being amazed at this. It makes the chart so much more informative and greatly aids in data exploration. For example, I can now just hover over the anomalous orange dot to find out what is going on: it is Peter Barker who has had a long successful career like the other orange dots, but has never actually reached the top few spots in the world rankings like the green dots. Another example is that I can understand some of the nuanced structure in the charts and find sub-clusters. For example, in the PCA diagram, the four points that are the highest in the green cluster form a sub-cluster of the players Ali Farag, Karim Abdel Gawad, Tarek Momen and Simon Rosner, who are excellent players who are consistently in the Top 5, but not legendary. (Ali Farag is an exception to this - he will undoubtedly join the orange cluster but his career is too short at the moment to join the cluster of elite players).&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Bokeh is amazing! This is what I managed to do after less than an hour of Googling around and adapting examples. If you look at the documentation, there is a whole load of other things that are possible, e.g. different kinds of interactivity.&lt;/p&gt;

&lt;p&gt;I highly recommend you try using it.&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;Below is a sample of the code to illustrate how to create the Bokeh plots above.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# import packages
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.manifold&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.cluster&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bokeh.plotting&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_notebook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ColumnDataSource&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bokeh.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HoverTool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CategoricalColorMapper&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bokeh.palettes&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d3&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bokeh.transform&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor_cmap&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output_notebook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# use tsne to do dimension reduction
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsne_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perplexity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;male_tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# use kmeans on original dataset to determine clusters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_clusters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create the bokeh plot
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ColumnDataSource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;male_tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;male_tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{i}'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;players&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;best_rank&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;years_in_top10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;years_in_top10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;earliest_year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earliest_year&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Category10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;color_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CategoricalColorMapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{i}'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;TOOLS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;box_zoom,hover,reset&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PCA of Male Squash Player Rankings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TOOLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;background_fill_color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;white&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgrid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_line_color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ygrid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_line_color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'field'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'clusters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'transform'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hover&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HoverTool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hover&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tooltips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Player&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;@players&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Best rank&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;@best_rank&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Years in Top 10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;@years_in_top10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Earliest year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;@earliest_year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'squash3_malepca.html'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series Squash rankings, Part II, dimension reduction and clustering Squash rankings, Part I, Scraping wikipedia and data analysis</summary></entry><entry><title type="html">Visualising L1 and L2 regularisation, Part II, Lessons learnt from an experienced programmer</title><link href="https://lovkush-a.github.io/blog/data%20science/python/2020/10/18/l1l2reg2.html" rel="alternate" type="text/html" title="Visualising L1 and L2 regularisation, Part II, Lessons learnt from an experienced programmer" /><published>2020-10-18T00:00:00-05:00</published><updated>2020-10-18T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/python/2020/10/18/l1l2reg2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/python/2020/10/18/l1l2reg2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/data%20science/python/2020/10/11/l1l2reg.html&quot;&gt;Visualising L1 and L2 regularisation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the first post in this series, I produced various animations to help visualise L1 vs L2 regularisation. However, the way I produced those animations was not 100% programmatic. This is what I did:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Have a for loop which produces each chart then saves it as a png file.&lt;/li&gt;
  &lt;li&gt;Manually use an online gif tool to combine the png files.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, I knew it was possible to create a video programmatically in matplotlib, as I had done it before to &lt;a href=&quot;/blog/data%20science/python/2020/09/10/sgd1.html&quot;&gt;visualise gradient descent&lt;/a&gt;. But I could not work out how to adapt the functions to this case.  Therefore, I decided to ask for help in the Faculty Slack channel. I got two helpful responses.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One by Will Fawcett which told me about the command line tool &lt;code class=&quot;highlighter-rouge&quot;&gt;convert&lt;/code&gt; that can create the gifs&lt;/li&gt;
  &lt;li&gt;Second by Tom Begley who recommended using &lt;code class=&quot;highlighter-rouge&quot;&gt;FFMpegWriter&lt;/code&gt;. Furthermore, he actually created a pull request in which he adapted my code to illustrate how to use it!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was the first time I had asked for help in the general Slack channel, so I was taken aback by the help that was provided.&lt;/p&gt;

&lt;p&gt;Anyway, in the pull request, in addition to illustrating how to use &lt;code class=&quot;highlighter-rouge&quot;&gt;FFMpegWriter&lt;/code&gt;, there were various other little things that were changed and things I could learn from. Therefore, I am writing this blogpost to maximise how much I learn from the experience.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learnt&quot;&gt;Lessons learnt&lt;/h2&gt;
&lt;h3 id=&quot;automatic-code-formatting-for-notebooks&quot;&gt;Automatic code formatting for notebooks&lt;/h3&gt;
&lt;p&gt;A noticeable change in the pull request was that many of the changes concerned code formatting. Below is an example.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_cost_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    returns a convex cost function
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'l1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'l2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'max'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_cost_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    returns a convex cost function
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;l1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;l2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;max&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centre_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I knew there was no way Tom did this manually so surmised he used an automatic code formatter. A quick Google search revealed various options and I will be sure to make use of these in the future.&lt;/p&gt;

&lt;h3 id=&quot;decorators&quot;&gt;Decorators&lt;/h3&gt;
&lt;p&gt;I already knew about decorators, but somehow never thought of making use of them.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_y_l1_coordinate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;create_y_l1_coordinates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectorize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_y_l1_coordinate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectorize&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_y_l1_coordinate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;garbage-collection&quot;&gt;Garbage collection&lt;/h3&gt;
&lt;p&gt;Garbage collection is something I have briefly read about, but have not fully understood. However, a certain aspect of Tom’s example gave me some insight. It is best explained by showing the example. Tom created the &lt;code class=&quot;highlighter-rouge&quot;&gt;update&lt;/code&gt; function within an &lt;code class=&quot;highlighter-rouge&quot;&gt;initialise&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_radius&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;l1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;centres_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;centres_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;x_ball&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_ball&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_ball_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;l1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# comma is needed to pull poly out of list length 1
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ball&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_ball&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;o&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Minimum value of cost within shaded region&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_cost_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centres_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centres_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_inputs_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_inputs_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_cost_inputs_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cont&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_inputs_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_inputs_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;51&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimise_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_ball&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_ball&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ydata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cont&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before seeing this example, I would have said that &lt;code class=&quot;highlighter-rouge&quot;&gt;centres_x&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;centres_y&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;marker&lt;/code&gt; would not be ‘garbage collected’ and the variables would not be preserved. However, the fact the program works means that those variables are preserved by virtue of the fact they are used in the &lt;code class=&quot;highlighter-rouge&quot;&gt;update&lt;/code&gt; function (and the fact that &lt;code class=&quot;highlighter-rouge&quot;&gt;update&lt;/code&gt; is returned by &lt;code class=&quot;highlighter-rouge&quot;&gt;initialise&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Though I cannot say I fully understand what is going, I have a better appreciation for things I have briefly read in the past about garbage collection in python, and how there is a counter that tracks the number of things that are somehow using/referring to a python object.&lt;/p&gt;

&lt;p&gt;Lastly, this example highlights some things I have read about bad programming practice. If something went wrong, the update function would be hard to debug, as it is making to changes to variables that are not parameters to the function.  I do not mind it in this example, as Tom was trying to illustrate how to use FFMpegWriter and it is not worth his time to use optimal programming practice in some little learning project. Furthermore, it has indirectly increased the amount I have learnt from the experience!&lt;/p&gt;

&lt;h3 id=&quot;how-to-use-ffmpegwriter&quot;&gt;How to use &lt;code class=&quot;highlighter-rouge&quot;&gt;FFMpegWriter&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Of course, the main thing I learnt from Tom’s help was how to use &lt;code class=&quot;highlighter-rouge&quot;&gt;FFMpegWriter&lt;/code&gt; and adjust for the different nature of these plots compared to other animation examples I had seen/created previously.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FFMpegWriter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saving&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;l1-cost.mp4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cont&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grab_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;remove_contours&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;how-how-i-might-have-found-the-solution-myself&quot;&gt;How how I might have found the solution myself&lt;/h3&gt;
&lt;p&gt;I asked Tom: ‘How would I have found out about the syntax to remove the contours, given that standard animation examples use ‘updates’ (e.g. you use updates for the red marker).  What would I have googled for, or what documentation would I have read?’&lt;/p&gt;

&lt;p&gt;Their response: ‘Yeah that was the nastiest bit here. Normally I look at the return value of whatever plotting function I used and try to tab-complete &lt;code class=&quot;highlighter-rouge&quot;&gt;.set_&lt;/code&gt; to see what’s available. In the case of the contour there was nothing obvious so I googled something like “update matplotlib contour animation” and got &lt;a href=&quot;https://stackoverflow.com/questions/23250004/updating-contours-for-matplotlib-animation&quot;&gt;this stackoverflow answer&lt;/a&gt; which told me I can’t update contours, I have to remove them instead.’&lt;/p&gt;

&lt;p&gt;Nothing mind-blowing, but I always find it useful to find out how other people solve their problems. I cannot remember what I searched for when I was trying to solve the problem for myself, but I guess I must not have focussed my search on the key aspect of my plots that were causing the problems, namely, the contours.&lt;/p&gt;

&lt;h3 id=&quot;goal-for-the-future&quot;&gt;Goal for the future&lt;/h3&gt;
&lt;p&gt;To guage where I am at, I asked Tom how long it took them to create the pull request. The answer was roughly 30 minutes! For me, that is incredibly fast. It is encouraging to see what I can strive for and what I will be able to achieve with continued practice and experience.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;As you can see, I learnt a great deal from this experience. The main lesson of course is to learn from others. With enough effort, I probably could have arrived at a solution myself, however, it is much faster this way &lt;em&gt;and&lt;/em&gt; I learnt a whole bunch of other little things on the side.&lt;/p&gt;

&lt;h2 id=&quot;github-repository&quot;&gt;Github Repository&lt;/h2&gt;
&lt;p&gt;Here is the link to the &lt;a href=&quot;https://github.com/Lovkush-A/l1l2_regularisation&quot;&gt;Github repository&lt;/a&gt; in case you’re interested in looking at the full code and comparing things for yourself.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Visualising L1 and L2 regularisation</summary></entry><entry><title type="html">Visualising L1 and L2 regularisation</title><link href="https://lovkush-a.github.io/blog/data%20science/python/2020/10/11/l1l2reg.html" rel="alternate" type="text/html" title="Visualising L1 and L2 regularisation" /><published>2020-10-11T00:00:00-05:00</published><updated>2020-10-11T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/python/2020/10/11/l1l2reg</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/python/2020/10/11/l1l2reg.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/data%20science/python/2020/10/18/l1l2reg2.html&quot;&gt;Visualising L1 and L2 regularisation, Part II, Lessons learnt from an experienced programmer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this &lt;a href=&quot;https://medium.com/@davidsotunbo/ridge-and-lasso-regression-an-illustration-and-explanation-using-sklearn-in-python-4853cd543898&quot;&gt;medium post comparing L1 and L2 regularisation&lt;/a&gt; there is an image showing how L1 regularisation is more likely to make one of the parameters equal to zero than L2 regularisation.&lt;/p&gt;

&lt;p&gt;One of my &lt;a href=&quot;https://faculty.ai/fellowship/&quot;&gt;co-fellows at Faculty&lt;/a&gt; pointed out that this image is not convincing, because it could just be a case of a cherry-picked cost function. As I had never made any effort to properly understand L1 versus L2 regularisation previously, this was good motivation for me to better to understand.&lt;/p&gt;

&lt;p&gt;The results are bunch of visuals that are below.&lt;/p&gt;

&lt;h2 id=&quot;varying-cost-function-with-parameters-restricted-to-l1-or-l2-balls&quot;&gt;Varying cost function with parameters restricted to L1 or L2 balls&lt;/h2&gt;

&lt;h3 id=&quot;parameters-restricted-to-l1-ball&quot;&gt;Parameters restricted to L1 ball&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_l11.gif&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;parameters-restricted-to-l2-ball&quot;&gt;Parameters restricted to L2 ball&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_l21.gif&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the plots above:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The circular things that are moving around are contour plots of cost functions. They are all convex.&lt;/li&gt;
  &lt;li&gt;The shaded regions are L1 and L2 balls, i.e. all points where the L1 or L2 norm of the parameters are less than some fixed radius r.&lt;/li&gt;
  &lt;li&gt;The red dot is the parameter which minimizes the cost function, given the restriction of being within the ballh.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What can be seen is that restricting the parameters to an L1-ball results in one of the two paramaters being zero, most of the time.  The L2-ball has no preference for values.&lt;/p&gt;

&lt;p&gt;This matches the general descriptions I have seen of L1 regularisation in various blog posts and articles.&lt;/p&gt;

&lt;h2 id=&quot;varying-cost-functions-with-l1-or-l2-regularisations&quot;&gt;Varying cost functions with L1 or L2 regularisations&lt;/h2&gt;
&lt;p&gt;An issue with the above plots is that I have forced my parameters to be within an L1 or L2 ball. In regularisation, the parameters can have any value, but there is a regularisation term added to incentivise the model to reduce the L1 or L2 norm.&lt;/p&gt;

&lt;p&gt;(Having this forced restriction corresponds to having a regularisation term that is zero if the parameters are inside the ball and infinity if the parameters are outside the ball. So normal regularisation can be thought of as being a smoothed out version of this forced restriction.)&lt;/p&gt;

&lt;p&gt;To check that the insights gained in the above plots do work when we have regularisation I created a couple more plots.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I created a cost function &lt;code class=&quot;highlighter-rouge&quot;&gt;(x-x0)^2 + (y-y0))^2 + r*norm((x,y))&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt; is a regularisation constant.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;norm&lt;/code&gt; is the L1 norm in the first plot and the L2 norm in the second plot.&lt;/li&gt;
  &lt;li&gt;I determined the coordinates &lt;code class=&quot;highlighter-rouge&quot;&gt;(x', y')&lt;/code&gt; that minimised the cost function above.&lt;/li&gt;
  &lt;li&gt;I added those coordinates to a scatterplot.&lt;/li&gt;
  &lt;li&gt;I then varied &lt;code class=&quot;highlighter-rouge&quot;&gt;x0&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;y0&lt;/code&gt;, producing many cost functions, and plotting the resulting &lt;code class=&quot;highlighter-rouge&quot;&gt;(x', y')&lt;/code&gt; coordinates in the scatterplot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;optimal-parameters-with-l1-regularisation&quot;&gt;Optimal parameters with L1 regularisation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_l12.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;optimal-parameters-with-l2-regularisation&quot;&gt;Optimal parameters with L2 regularisation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_l22.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see in the plots above that the pattern continues. L1 regularisation will force parameters to zero, and L2 regularisation does not have any preferred direction - L2 just wants the length of the vector to be smaller.&lt;/p&gt;

&lt;h2 id=&quot;max-norm&quot;&gt;Max norm&lt;/h2&gt;
&lt;p&gt;To check your understanding, imagine how the plots above would look if we replaced the L1 and L2 norms with the max norm, &lt;code class=&quot;highlighter-rouge&quot;&gt;max_norm((x,y)) = max(|x|, |y|)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;No really, take a couple of minutes to think this through. You learn the most by actively engaging with the ideas rather than passively reading somebody else’s thoughts.&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;Well, here are the two plots. Minor note, the plots are for the L10 norm, but it is a good enough approximation to the max-norm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_linf1.gif&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/l1l2reg_linf2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;I am glad I produced these plots. I have read before that L1-regularisation ought to have parameters go to zero, but I never really understood it, but now I have some feel for it.  Also, it was good python practice.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Visualising L1 and L2 regularisation, Part II, Lessons learnt from an experienced programmer</summary></entry><entry><title type="html">Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case</title><link href="https://lovkush-a.github.io/blog/data%20science/python/2020/10/01/sgd4.html" rel="alternate" type="text/html" title="Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case" /><published>2020-10-01T00:00:00-05:00</published><updated>2020-10-01T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/python/2020/10/01/sgd4</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/python/2020/10/01/sgd4.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/17/sgd3.html&quot;&gt;Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and &lt;strong&gt;S&lt;/strong&gt;GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/11/sgd2.html&quot;&gt;Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/09/10/sgd1.html&quot;&gt;Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I will recap my investigations into fitting sinusoidal data using sinusoidal models with SGD.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In Part I, I described my attempt at using GD and my belief that the failure to fit was due to the model getting stuck in a local minimum where the amplitude is small. I hoped that SGD would fix this problem.&lt;/li&gt;
  &lt;li&gt;I tried using SGD but it did not help (described in Part III).&lt;/li&gt;
  &lt;li&gt;I then tried using regularisation to solve the amplitude issue (described below).&lt;/li&gt;
  &lt;li&gt;I had the idea of investigating the loss function in detail. However, I decided it would be better to separate off this detailed investigation into sinusoidal models into a separate post (this one), and have a post discussing only the stochasticity (Part III).&lt;/li&gt;
  &lt;li&gt;While writing up Part III, for the sake of completeness, I investigated the learning rate. This solved the issue!&lt;/li&gt;
  &lt;li&gt;However, even though I solved the issues, I thought it would still be worthwhile to write-up my experiments with regularisation and also to carry out the investigation into the loss function. So here we are!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;regularisation&quot;&gt;Regularisation&lt;/h2&gt;
&lt;p&gt;Based on the examples I had tried, the amplitude would always tend to zero. Hence, I thought it would be worth adding a regularisation term that punishes having small amplitudes.&lt;/p&gt;

&lt;p&gt;The loss function was &lt;code class=&quot;highlighter-rouge&quot;&gt;loss = mse(y_est, y)&lt;/code&gt;. After the regularisation, it became &lt;code class=&quot;highlighter-rouge&quot;&gt;loss = mse(y_est, y) - parameters_est[0]&lt;/code&gt;.  Why did I choose this regularisation?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I believed that the amplitude would naturally tend to small values. Thus, I want to punish small values and encourage large values.&lt;/li&gt;
  &lt;li&gt;Smaller losses should correspond to better models. Therefore, the larger the amplitude, the smaller the loss should be.&lt;/li&gt;
  &lt;li&gt;Subtracting the amplitude from the loss achieves this. (Note that the first element of &lt;code class=&quot;highlighter-rouge&quot;&gt;parameters_est&lt;/code&gt; is the amplitude).&lt;/li&gt;
  &lt;li&gt;By differentiating, this regularisation causes the amplitude to increase by a constant amount each step, so there is a constant upward pressure on the amplitude.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is the first result of introducing this regularisation.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;As you can see, there are moments where the model gets close to the data. This got my hopes up, and made me feel like I was onto something.&lt;/p&gt;

&lt;p&gt;I tried various other things to see if I could make it better. I tried changing the weight of the regularisation term. I tried adding other regularisation terms (because in the experiments, it looked like there was now a tendency for the frequency to keep increasing). I can’t remember if I tried other things or not. Suffice it to say, I made no progress.&lt;/p&gt;

&lt;p&gt;Below is an animation of an experiment which involved changing the weight of the regularisation term. I include it only because I thought it was particularly funky and visually interesting.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;visualising-the-loss-function&quot;&gt;Visualising the loss function&lt;/h2&gt;
&lt;p&gt;After failing to get regularisation to work, I decided I should try to visualise the loss function, and find out exactly where the local minima were, and hopefully better understand why things were not working.&lt;/p&gt;

&lt;p&gt;The process I followed was:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Create data to be fit. That was just &lt;code class=&quot;highlighter-rouge&quot;&gt;y = sin(x)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Create generic sinusoidal models &lt;code class=&quot;highlighter-rouge&quot;&gt;y_est = a*sin(b*x + c) + d&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Vary the parameters &lt;code class=&quot;highlighter-rouge&quot;&gt;a,b,c,d&lt;/code&gt; and calculate the loss, &lt;code class=&quot;highlighter-rouge&quot;&gt;mse(y, y_est)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Plot graphs to visualise the loss function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To begin, I set &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt; and varied &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; is the amplitude and &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; is the frequency (multiplied by &lt;code class=&quot;highlighter-rouge&quot;&gt;2*pi&lt;/code&gt;) or the coefficient of &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;. The reason for fixing &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt; is that it was the amplitude and the frequency which were giving the most trouble.&lt;/p&gt;

&lt;p&gt;The first animation below shows a sequence of charts. Each individual chart shows how the loss varies with frequency, and from chart to chart the amplitude is changing.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_loss_vs_freq.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen from this, there are many local minima, so the model might get stuck in the wrong one. Eye-balling the chart, if the initial frequency is below 0.5 or above 1.7, then gradient descent will push the frequency away from the optimal value of 1. It is now clear why there should be a tendency for the frequency to increase, as we saw in the SGD examples in Part III.&lt;/p&gt;

&lt;p&gt;The next animation is the opposite. For each individual chart, we see how the loss varies with amplitude, and from chart to chart we are modifying the frequency.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_loss_vs_amp.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Fantastic! This I feel like I can understand. For the majority of frequencies, the optimal value for amplitude is zero and the amplitude will just slide its way to that value. Only for a narrow range of frequencies is the optimal value of the amplitude non-zero.&lt;/p&gt;

&lt;p&gt;To summarise, based on these two animations, here is what I would predict:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Regardless of amplitude, there is a narrow band of frequencies which would result in SGD finding the global minimum. Otherwise, you will get stuck in some other local minimum.&lt;/li&gt;
  &lt;li&gt;For ‘small’ and ‘large’ frequencies, the amplitude will want to decay to zero. For a certain range of frequncies, the amplitude will tend towards a sensible value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As I am writing this up and thinking things through, I am starting to wonder about my conclusion in Part III about the sinusoidal model. In Part III, I concluded that the issue all along was having an inappropriate learning rate, but the two animations above suggest there is more to it. Did I just get lucky and stumble upon starting parameters which fit the criteria I described above, and hence that is why I got the sinusoidal model to fit?  There’s only one way to find out, which is to do more experimentation!&lt;/p&gt;

&lt;h2 id=&quot;investigating-parameter-initialisation&quot;&gt;Investigating parameter initialisation&lt;/h2&gt;
&lt;p&gt;The steps for the investigation are as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Create data to be fit and generic model, as above.&lt;/li&gt;
  &lt;li&gt;Initialise the estimated parameters: &lt;code class=&quot;highlighter-rouge&quot;&gt;a=1, b=?, c=0, d=0&lt;/code&gt;. We will be varying the value of initial value of &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Do SGD and visualise the learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I start by trying a large value for the frequency, 5.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f5.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;So, as predicted, the frequency gets stuck in some sub-optimal value and the amplitude tends to zero. It looks like I did just get lucky in Part III.&lt;/p&gt;

&lt;p&gt;Frequency of 2 and 1.5 is similar:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f15.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Frequency of 1.2:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f12.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;We get the model converging to the data! Though this is to be expected, it is still satisfying to see it actually work. With a bit of manual experimentation, the cut-off between these two behaviours is roughly 1.46.&lt;/p&gt;

&lt;p&gt;How about lower frequencies? A frequency of 0.6 converges to the correct model:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f06.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;And a frequency of 0.5 converges to a different minima:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd4_sin_f05.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Again, this is consistent with the frequncy vs loss charts above, where you can see there are local minima to the left of the global minimum.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This has been a bit of a topsy-turvy learning experience. I am still surprised at how much I learnt from this basic example. And having struggled with this simple example, I better appreciate how impressive it is to get complicated neural networks to learn.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and SGD Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data</summary></entry><entry><title type="html">Squash rankings, Part II, dimension reduction and clustering</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/09/28/squash2.html" rel="alternate" type="text/html" title="Squash rankings, Part II, dimension reduction and clustering" /><published>2020-09-28T00:00:00-05:00</published><updated>2020-09-28T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/09/28/squash2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/09/28/squash2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/data%20viz/2020/11/01/squash3.html&quot;&gt;Squash rankings, Part III, All hail Bokeh!&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/scraping/2020/09/17/squash1.html&quot;&gt;Squash rankings, Part I, Scraping wikipedia and data analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous post, I scraped squash ranking data and produced a dataframe out of it. I then simply eye-balled the table to see the patterns. However, doing some kind of visualisation is always better than just listing a table, so that is what I did next.  Furthermore, I decided to finally try out some dimension reduction algorithms and clustering to help with the visualisations and pattern-finding.&lt;/p&gt;

&lt;h2 id=&quot;male-rankings&quot;&gt;Male Rankings&lt;/h2&gt;
&lt;h3 id=&quot;pca&quot;&gt;PCA&lt;/h3&gt;
&lt;p&gt;I first tried using PCA on the data.
&lt;img src=&quot;/blog/images/squash2_malepca1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm.  Not sure what to make of this as it is. To better understand it, I visualised how this plots relates to the various features in the frame created in Part 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_malepca2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From this, I can better understand what is going on. The 1st PCA component is highly correlated with the years that the players played and the 2nd PCE component is correlated with rank.&lt;/p&gt;

&lt;h3 id=&quot;tsne&quot;&gt;tSNE&lt;/h3&gt;
&lt;p&gt;Next I tried tSNE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_maletsne1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm. This does not look good. It does not seem to have spotted any patterns and just created a grid of points.  I suspected that maybe I have to change the parameters of tSNE, so I looked at the documentation. In the documentation, it said that a good choice of perplexity often depends on the size of the dataset, with larger perplexities working better with larger datasets. I had a small dataset so I tried setting  small value of perplexity, 5, in comparison to the default of 30.  The result is this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_maletsne2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hooray! Clearly the algorithm has found three distinct clusters in the dataset.  To understand what these clusters correspond to, I again visualised how this plots relates to the various features in the dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_maletsne3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By looking at these charts, the clusters seem to have these patterns:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The bottom left cluster corresponds to those players who have been in the top 10 longest&lt;/li&gt;
  &lt;li&gt;The top cluster corresponds to those players whose career ended in the 90s or early 2000s&lt;/li&gt;
  &lt;li&gt;The bottom right cluster corresponds to those players whose career has started quite recently&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;umap&quot;&gt;UMAP&lt;/h3&gt;
&lt;p&gt;Finally I tried UMAP.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_maleumap1.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_maleumap2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is incredible! This has captured the same three clusters as tSNE, but has presented them in a more coherent way. Moving from top left to bottom right corresponds to going from younger to older players, with the chunk in the middle being the most successful players with good rankings and many years in the top 10.&lt;/p&gt;

&lt;h3 id=&quot;clustering&quot;&gt;Clustering&lt;/h3&gt;
&lt;p&gt;Based on the above dimension reduction visualisations, the data fits into three clusters. Hence, I tried to identify those clusters by using k-means clustering on the original dataset (i.e. without any dimension reduction). I then visualised how those clusters look in the different dimension reductions:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_malecluster.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Woohoo! This is really pleasing. As my first experience using these tools, I do not know if I should be surprised or not to see that the different tools are overall consistent with each other. There are a couple of interesting subsets of players though.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There are five cluster-0 players who seem to form their own cluster between cluster 0 and cluster 1. Doing a search in the dataframe reveals that these are players who ended their careers in late 90s/early 2000s but have been in top 10 for several years.&lt;/li&gt;
  &lt;li&gt;There is a single purple cluster-1 player who seems better being treated as a cluster between cluster 1 and cluster 2. Again doing a search reveals that this is a player who has many years in the top 10 like the elite cluster-1 players, but who is not actully an elite player themselves (e.g. their top ranking is 5, whereas everybody in cluster 1 has reached world number 1 ranking).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on this single example, it looks like UMAP has the best representation of the data. PCA does not do a great job distinguishing the clusters strongly whereas tSNE forces things into clusters and does not allow for ‘grey’ areas in the space.&lt;/p&gt;

&lt;h2 id=&quot;female-rankings&quot;&gt;Female Rankings&lt;/h2&gt;
&lt;p&gt;Here are the analagous plots for female players.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/squash2_femalepca1.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femalepca2.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femaletsne1.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femaletsne2.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femaleumap1.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femaleumap2.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/squash2_femalecluster.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The patterns here are far less clear as for the mens. I guess I was correct to be surprised at how nicely things worked out earlier! However, the way the algorithms have organised the data is roughly similar: the two important characteristics of a player according to these algorithms are the years they played and their rankings in that time. Also, the clusters have been broken up into similar chunks: players with good rankings, older players and younger players.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Like I said at the start, this is my first experience using these techniques. The main takeaway for me is how cool (and useful) these algorithms are! Up till now I had only done supervised classification or plotted standard charts for EDA. However, having gone through this experience and got a basic feel what the algorithms can achieve, I will be sure to make more use of it in the future.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Squash rankings, Part III, All hail Bokeh! Squash rankings, Part I, Scraping wikipedia and data analysis</summary></entry><entry><title type="html">An intuitive but unknown version of Bayes’ Theorem</title><link href="https://lovkush-a.github.io/blog/maths/tutorial/2020/09/24/bayes.html" rel="alternate" type="text/html" title="An intuitive but unknown version of Bayes' Theorem" /><published>2020-09-24T00:00:00-05:00</published><updated>2020-09-24T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/maths/tutorial/2020/09/24/bayes</id><content type="html" xml:base="https://lovkush-a.github.io/blog/maths/tutorial/2020/09/24/bayes.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;One of the big lessons I have learnt is that no matter how well (you think) you understand something, there is almost always a deeper or clearer level of understanding available. Even for trivially simple things, like addition. Today, I will describe my experience with this phenomena in the context of Baye’s Theorem, by going through four different ways I have of conceptualising it. The final way  is surprisingly simple but largely unknown; I learnt about it from this &lt;a href=&quot;https://80000hours.org/podcast/episodes/spencer-greenberg-bayesian-updating/#bayesian-updating&quot;&gt;80000 Hours’ interview of Spencer Greenberg&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Recall that Bayes Theorem states that:
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(A | B) = \frac{P(A) P(B|A)}{P(B)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.53em;vertical-align:-0.52em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.01em;&quot;&gt;&lt;span style=&quot;top:-2.655em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.485em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.52em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;algebraic&quot;&gt;Algebraic&lt;/h2&gt;
&lt;p&gt;For a long time, the main way I thought about Baye’s Theorem was that it was just a consequence of some algebraic re-arrangement:&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mspace linebreak=&quot;newline&quot;&gt;&lt;/mspace&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mspace linebreak=&quot;newline&quot;&gt;&lt;/mspace&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(B \cap A) = P(A \cap B) \\
P(B) P(A|B) = P(A) P(B|A) \\
P(A|B) = \frac{P(A) P(B|A)}{P(B)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∩&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∩&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace newline&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace newline&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.363em;vertical-align:-0.936em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.427em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.936em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is a derivation of the formula&lt;/li&gt;
  &lt;li&gt;It is easy to follow this argument&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Provides no insight or understanding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unfortunately, this is how I treated a lot of mathematics during my teenage and undergraduate years. The purpose of a proof is to establish the truth of something, and once you know it is true, you are free to use it. Somehow, I never stepped back and asked myself if there was more understanding available.&lt;/p&gt;

&lt;h2 id=&quot;changing-the-universe--some-algebra&quot;&gt;‘Changing the universe’ + some algebra&lt;/h2&gt;
&lt;p&gt;Often when dealing with probabilities, you have to determine all the possibilities of the situation (‘the universe of possibilities’) and then determine which of those corresponds to the event you are interested in.&lt;/p&gt;

&lt;p&gt;For example, to determine the probability of getting two heads when you toss a fair coin twice, you might say that there are four total options (that are all equally likely), and one of those is what we are interested in, so the probability is &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{1}{4}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.190108em;vertical-align:-0.345em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.845108em;&quot;&gt;&lt;span style=&quot;top:-2.6550000000000002em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.394em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.345em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;How does this relate to Bayes? Well, the way I think about conditional probability is that when calculating the probability of A given B, I am changing the universe so that the possibilities are precisely those that correspond to B. Once I am in this restricted universe, I continue reasoning as normal.&lt;/p&gt;

&lt;p&gt;For example, what is the probability of getting two heads given that at least one of them (but we don’t know which) is heads. In this case, the universe of possibilities is reduced to three options (we have ruled out the option of TT), so the probability is now &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{1}{3}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.190108em;vertical-align:-0.345em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.845108em;&quot;&gt;&lt;span style=&quot;top:-2.6550000000000002em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.394em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.345em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Converting this to algebra, we get:
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∩&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A) P(B|A)}{P(B)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.53em;vertical-align:-0.52em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.01em;&quot;&gt;&lt;span style=&quot;top:-2.655em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.485em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;∩&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.52em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.53em;vertical-align:-0.52em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.01em;&quot;&gt;&lt;span style=&quot;top:-2.655em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.485em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.52em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is a derivation of the formula&lt;/li&gt;
  &lt;li&gt;Slightly more insight than the original, e.g. we divide by $P(B)$ because $B$ has become the ‘universe of possibilities’.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Still not particularly insightful&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;adjusting-a-first-estimate&quot;&gt;Adjusting a first estimate&lt;/h2&gt;
&lt;p&gt;A third way I have of thinking about Baye’s Theorem (which if I remember correctly, only arose after being exposed to the fourth way below) starts with the idea that a reasonable default belief or first estimate is:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(A \vert B) = P(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Why is this a reasonable first estimate?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The probability of $A$ happening given some information ought to be related to the probability of $A$ happening without any information.&lt;/li&gt;
  &lt;li&gt;If $B$ has no influence on $A$ whatsoever, then this first estimate &lt;em&gt;is&lt;/em&gt; exactly correct. (And this is the basis of the formal definition of two events being independent.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we have a first estimate, we need adjust it to get the exact probability. This adjustment factor is the role of the term &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{P(B \vert A)}{P(B)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.53em;vertical-align:-0.52em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.01em;&quot;&gt;&lt;span style=&quot;top:-2.655em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.485em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen mtight&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose mtight&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.52em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. Why is this a sensible adjustment factor? Let us see when we increase or decrease our first estimate.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(B \vert A) &amp;gt; P(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, then the adjustment factor is bigger than 1, so we increase our first estimate. This makes sense, or at least feels intuitive: if $B$ is more likely when $A$ occurs than when $A$ does not occur, then we should increase our estimate of $A$ occuring.&lt;/li&gt;
  &lt;li&gt;If &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(B \vert A) &amp;lt; P(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, then the adjustment factor is smaller than 1, so we decrease our first estimate. The makes sense, following similar reasoning to the point above.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope that makes sense - please let me know if it does not, it is somewhat vague and fuzzy. The strange thing about this is that this is the whole point of ‘priors’ and ‘posteriors’ in Bayesian updating. Yet somehow, I never made the intuitive leap that &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(A \vert B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ought to be $P(A)$ with some kind of adjustment. I cannot remember what I thought when I first learnt about Bayesian stats at university, but my guess is that I treated it more mechanically: “If we have these various bits of information, which for formality sake we label with fancy terms like ‘prior distribution’ and ‘likelihood function’, then we can use Baye’s Theorem to calculate this new thing which we label ‘posterior distribution’”.&lt;/p&gt;

&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Provides insight into what Bayes’ Theorem is actually saying&lt;/li&gt;
  &lt;li&gt;Corresponds to Bayesian statistics / Bayesian updating&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Does not provide a derivation of the formula&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayes-via-odds-the-unknown-version-of-bayes-theorem&quot;&gt;Bayes via odds: the unknown version of Bayes’ Theorem&lt;/h2&gt;
&lt;p&gt;There are two main ideas in this version of Bayes’ Theorem.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Replacing probabilities with odds&lt;/li&gt;
  &lt;li&gt;Adjusting Bayes’ Theorem to odds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Instead of giving a general derivation or discussion, I think the easiest way to illustrate and show-off this version of Bayes’ Theorem is by walking through some explicit examples. Before that though, we should first get used to thinking in terms of odds.&lt;/p&gt;

&lt;h3 id=&quot;odds&quot;&gt;Odds&lt;/h3&gt;
&lt;p&gt;When describing uncertainty, the usual way is to list all the possible options along with their probabilities. With odds, we instead assign &lt;em&gt;relative probabilities&lt;/em&gt;, and collectively these relative probabilities are called the odds.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Example. Instead of saying there is a probability of 0.5 of getting H and 0.5 of getting T, we say the odds are 1:1 of getting H and T.&lt;/li&gt;
  &lt;li&gt;Example. Instead of saying the probabilities are 0.25, 0.25 and 0.5 of getting two heads, two tails or one of each, we say the odds are 1:1:2.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(Note, I do not actually know what the official phrasing is. I have just come up with something that feels OK and whose meaning is hopefully clear.)&lt;/p&gt;

&lt;p&gt;As a little exercise to check your understanding, determine how you would convert between probabilities and odds.&lt;/p&gt;

&lt;p&gt;No really, I recommend you do this. The best way to learn is by actively doing something with the ideas, rather than passively reading.&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;Here is how I would describe the conversions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Given some odds, you determine the probabilities by dividing all the relative probabilities by the sum of the relative probabilities. This process is known as &lt;em&gt;normalising&lt;/em&gt; and the sum of the relative probabilities is the &lt;em&gt;normalising factor&lt;/em&gt; or &lt;em&gt;normalising constant&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Given some probabilities, there are infinitely many different odds you could create. Say we had probabilities $p_1, p_2$ and $p_3$, then the odds would be any multiple of these three numbers: $ap_1:ap_2:ap_3$. Of course, you should pick $a$ to create the most intuitive list of relative probabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Do not worry if this feels strange. That is to be expected with a different way of looking at something that we are so used to looking at in a certain way.&lt;/p&gt;

&lt;h3 id=&quot;example-1-disease-given-a-positive-test-result&quot;&gt;Example 1. Disease given a positive test result&lt;/h3&gt;
&lt;p&gt;This is a famous question that demonstrates how bad our intuitions are when it comes to reasoning about uncertainty and probabilities. Here are the assumptions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Without any other information, there is a 1 in a 1000 chance somebody has the disease, independent of everybody else.&lt;/li&gt;
  &lt;li&gt;There is a test for the disease which is 99% effective. Explicitly, 99% of people who have the disease will get a positive test result, and 99% of people who do not have the disease will get a negative test result.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(Do not think about how one could know these facts. E.g. how can you know the effectiveness of a test if there is not already a test which is 100% effective?)&lt;/p&gt;

&lt;p&gt;The question: you take the test and get a positive result. What is the probability that you have the disease?&lt;/p&gt;

&lt;p&gt;The most common instinctive answer is 99%, because we know the test is 99% effective. However, the error here is getting mixed up between the probability of having the disease given that you have a positive test versus the probability of getting a positive test result given that you have the disease.&lt;/p&gt;

&lt;p&gt;Before continuing, try to answer the question using standard tools and Bayes’ Theorem as usual.&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;…&lt;/p&gt;

&lt;p&gt;OK, I assume you have tried it. Or at least, that you have done it before. If it was me, I would draw a probability tree and then do the various calculations.&lt;/p&gt;

&lt;p&gt;Now, here is how to answer this question using the magical alternative: Bayes’ via odds.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Determine the odds without any information, i.e. the prior odds.
    &lt;ul&gt;
      &lt;li&gt;They are 1:999 of having the disease versus not having the disease. (Why is it 999 and not 1000?)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Determine the probabilities of getting a positive test result, conditioned on the possibilities from Step 1.
    &lt;ul&gt;
      &lt;li&gt;If I have the disease, I have 0.99 chance of getting positive result.&lt;/li&gt;
      &lt;li&gt;If I do not have the disease, it is a 0.01 chance.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Multiply the corresponding numbers from Steps 1 and 2 together. Re-scale so numbers are nice.
    &lt;ul&gt;
      &lt;li&gt;From Step 1 we had 1:999. From Step 2 we had 0.99:0.01&lt;/li&gt;
      &lt;li&gt;Multiplying them together gives 0.99:9.99&lt;/li&gt;
      &lt;li&gt;Re-scaling gives 99:999&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Marvel at the fact we’re done. Those final numbers you worked out are the posterior odds!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;!!! This is amazing! I still find it surreal how straightforward the odds perspective makes the whole process. It is basically magic. (Though, if you did do the question using traditional means, you should see how all the numbers and calculations match up).&lt;/p&gt;

&lt;p&gt;Furthermore, this process makes explicit the effect of the new information. The prior belief is that we have the disease with roughly 1:1000 odds, and the posterior belief is that we have the disease with roughly 1:10 odds. The odds have increased by a factor of 100. By looking at the calculations (which is easy to do because they are so short), we see that this factor of 100 arises as the ratio of values in Step 2. I have a 99% chance of a positive result if I have the disease, and a 1% chance if I do not have the disease, so I should put 99 times more weight on having the disease once I know I have a positive test result.&lt;/p&gt;

&lt;h3 id=&quot;example-2-the-monty-hall-problem&quot;&gt;Example 2. The Monty-Hall Problem&lt;/h3&gt;
&lt;p&gt;Another famous question. I assume you know about it, but here is a brief description of the set-up. You are on a game show. There are three doors. Behind two of the doors are goats and behind the third door is a prize (which you value more than a goat). You initially guess that the prize is behind Door 1. The gameshow host is nice, and reveals that Door 3 has a goat behind it. You are then offered to switch your choice from Door 1 to Door 2.&lt;/p&gt;

&lt;p&gt;Question: Should you stay on Door 1, switch to Door 2, or does it make no difference (statistically speaking)?&lt;/p&gt;

&lt;p&gt;This question is a real brain-burner because, counter-intuitively, the answer is that you should switch. The most common thought is that once Door 3 is ruled out, there is a 50:50 chance of the prize being behind Door 1 or Door 2, so it makes no difference if you switch or not.&lt;/p&gt;

&lt;p&gt;Here, I will illustrate how using odds, we can gain some understanding of this situation.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Determine the odds without any information (i.e. before Door 3 was revealed).
    &lt;ul&gt;
      &lt;li&gt;The odds are 1:1:1 for the prize being behind Doors 1, 2 and 3 respectively.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Determine the probabilities of Door 3 being revealed, conditioned on the events in Step 1.
    &lt;ul&gt;
      &lt;li&gt;If the prize is behind Door 1, then there is a 50% chance of Door 3 being opened by the host. (The host picks randomly if they have a choice).&lt;/li&gt;
      &lt;li&gt;If the prize is behind Door 2, then there is a 100% chance of Door 3 being opened by the host. (The host will never open the door you originally guessed.)&lt;/li&gt;
      &lt;li&gt;It the prize is behind Door 3, then there is 0% chance of Door 3 being opened by the host. (The host always reveals a goat)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Multiply the corresponding values to generate the posterior odds.
    &lt;ul&gt;
      &lt;li&gt;0.5:1:0&lt;/li&gt;
      &lt;li&gt;Re-scaling we get, 1:2:0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The prize is twice as likely to behind Door 2 as it is Door 1, so you should switch.&lt;/p&gt;

&lt;p&gt;Note, I do not think this is the most intuitive explanation of the Monty-Hall Problem. But I hope it is an illustration of the incredible ease of this odds-based Bayes’ Theorem.&lt;/p&gt;

&lt;h3 id=&quot;exercises&quot;&gt;Exercises&lt;/h3&gt;
&lt;p&gt;As I said above, the best way to learn is by actively engaging with the ideas, rather than passively reading. Hence, here are some exercises to try out.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Formulate a statement of Bayes’ Theorem in this odds framework. Then prove it.&lt;/li&gt;
  &lt;li&gt;A bag contains 1000 coins - 999 are fair coins but one of them is dodgy and has two heads. You take one out randomly, toss it five times-in-a-row, and get heads each time. What is the probability you have the dodgy coin? How many heads in a row would you have to observe so that you think it is more likely you have a dodgy coin than not?&lt;/li&gt;
  &lt;li&gt;You meet somebody. They tell you they have two kids and that at least one of them is born on a Tuesday. What is the probability the other is born on Friday?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;pros-and-cons&quot;&gt;Pros and Cons&lt;/h3&gt;
&lt;p&gt;Pros&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Easy to use&lt;/li&gt;
  &lt;li&gt;Better matches how Bayesian reasoning is used in real-life. You want to update all probabilities, not just a single one.&lt;/li&gt;
  &lt;li&gt;The ease of use makes explicit exactly how the new information changes the relative probabilities.&lt;/li&gt;
  &lt;li&gt;It reveals that $P(B)$ in the standard formulation has no information, it is just a normalising constant.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is not a derivation.&lt;/li&gt;
  &lt;li&gt;It requires an unfamiliar change in perspective.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;final-remarks&quot;&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;I hope you gained some new insights into Bayes’ Theorem. If you have any other perspectives on it, please let me know! As I said at the start, it is always surprising how things that you feel you understand contain hidden layers and deeper insights.&lt;/p&gt;

&lt;p&gt;Lastly, I recommend you listen to the &lt;a href=&quot;https://80000hours.org/podcast/episodes/spencer-greenberg-bayesian-updating/#bayesian-updating&quot;&gt;80000 Hours’ interview of Spencer Greenberg&lt;/a&gt;. First, you will hear Spencer’s description and perspectives on this odds framework. Second, you will learn a whole bunch of other insightful things: Spencer researches thinking and rationality and tries to develop software tools that take make use of his insights. For example, Spencer discusses their research on when people are over- or under-confident.&lt;/p&gt;</content><author><name></name></author><summary type="html">Introduction One of the big lessons I have learnt is that no matter how well (you think) you understand something, there is almost always a deeper or clearer level of understanding available. Even for trivially simple things, like addition. Today, I will describe my experience with this phenomena in the context of Baye’s Theorem, by going through four different ways I have of conceptualising it. The final way is surprisingly simple but largely unknown; I learnt about it from this 80000 Hours’ interview of Spencer Greenberg.</summary></entry><entry><title type="html">Squash rankings, Part I, Scraping wikipedia and data analysis</title><link href="https://lovkush-a.github.io/blog/python/scraping/2020/09/17/squash1.html" rel="alternate" type="text/html" title="Squash rankings, Part I, Scraping wikipedia and data analysis" /><published>2020-09-17T00:00:00-05:00</published><updated>2020-09-17T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/scraping/2020/09/17/squash1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/scraping/2020/09/17/squash1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/data%20viz/2020/11/01/squash3.html&quot;&gt;Squash rankings, Part III, All hail Bokeh!&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/09/28/squash2.html&quot;&gt;Squash rankings, Part II, dimension reduction and clustering&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I am going through the CS109 Harvard lectures on data science. I just watched a couple of lectures on web-scraping with BeautifulSoup, so I wanted to practice. I decided to scrape squash ranking data from wikipedia, as I am a avid fan of the sport. On wikipedia, the best information I could find was the top 10 players at the end of each year for the past 25 years or so.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;The results of the scraping process are in the following tables, summarising some key stats for the players. The tables are ordered by players’ average rank in the dataset. It is worth emphasising that the data only contains information on Top 10 rankings and only at the end of each year; this will skew the data in various ways.&lt;/p&gt;

&lt;h3 id=&quot;summary-for-female-players&quot;&gt;Summary for female players&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;|                  player | average_rank | years_in_top10 | best_rank | worst_rank | earliest_year | latest_year |
|------------------------:|-------------:|---------------:|----------:|-----------:|--------------:|------------:|
|         Michelle Martin |     1.400000 |              5 |         1 |          2 |          1994 |        1998 |
|       Sarah Fitz-Gerald |     2.333333 |              9 |         1 |          5 |          1994 |        2002 |
|             Nicol David |     2.357143 |             14 |         1 |          6 |          2004 |        2017 |
|       Raneem El Weleily |     2.444444 |              9 |         1 |          7 |          2011 |        2019 |
|          Leilani Rorani |     2.750000 |              4 |         1 |          7 |          1998 |        2001 |
|        Nour El Sherbini |     3.142857 |              7 |         1 |          6 |          2012 |        2019 |
|         Rachael Grinham |     3.909091 |             11 |         1 |          8 |          2001 |        2011 |
|             Carol Owens |     4.100000 |             10 |         1 |          8 |          1994 |        2003 |
|           Laura Massaro |     4.111111 |              9 |         2 |          9 |          2010 |        2018 |
|          Cassie Jackman |     4.545455 |             11 |         2 |          8 |          1994 |        2004 |
|         Natalie Grinham |     4.666667 |              9 |         2 |          9 |          2003 |        2013 |
|        Natalie Grainger |     5.100000 |             10 |         3 |          7 |          1999 |        2009 |
|              Sue Wright |     5.250000 |              4 |         4 |          8 |          1994 |        1998 |
|           Jenny Duncalf |     5.375000 |              8 |         2 |          9 |          2005 |        2013 |
|            Nouran Gohar |     5.400000 |              5 |         3 |          9 |          2015 |        2019 |
|           Linda Elriani |     5.555556 |              9 |         3 |          9 |          1997 |        2005 |
|          Suzanne Horner |     5.625000 |              8 |         2 |          9 |          1994 |        2001 |
|            Tania Bailey |     5.666667 |              6 |         5 |          9 |          1999 |        2007 |
|        Vanessa Atkinson |     5.875000 |              8 |         1 |         10 |          2002 |        2010 |
|           Camille Serme |     5.888889 |              9 |         3 |         10 |          2010 |        2019 |
|           Nour El Tayeb |     6.000000 |              5 |         3 |          8 |          2014 |        2019 |
|             Kasey Brown |     6.000000 |              2 |         5 |          7 |          2010 |        2011 |
|              Liz Irving |     6.200000 |              5 |         3 |         10 |          1994 |        1998 |
|           Alison Waters |     6.400000 |             10 |         3 |         10 |          2008 |        2018 |
|             Joelle King |     6.666667 |              6 |         4 |         10 |          2012 |        2019 |
|         Vicky Botwright |     7.000000 |              4 |         5 |          9 |          2003 |        2007 |
|            Amanda Sobhy |     7.000000 |              2 |         7 |          7 |          2016 |        2019 |
|        Sarah-Jane Perry |     7.000000 |              3 |         6 |          8 |          2017 |        2019 |
|            Low Wee Wern |     7.333333 |              3 |         7 |          8 |          2012 |        2014 |
|          Madeline Perry |     7.428571 |              7 |         4 |         10 |          2006 |        2013 |
|          Sabine Schoene |     7.500000 |              4 |         6 |          9 |          1995 |        1998 |
|       Omneya Abdel Kawy |     7.900000 |             10 |         4 |         10 |          2004 |        2016 |
|            Fiona Geaves |     8.444444 |              9 |         5 |         10 |          1994 |        2004 |
| Laura Lengthorn-Massaro |     8.500000 |              2 |         8 |          9 |          2008 |        2009 |
|                Annie Au |     8.750000 |              4 |         8 |         10 |          2011 |        2015 |
|             Tesni Evans |     9.000000 |              2 |         9 |          9 |          2018 |        2019 |
|          Rebecca Macree |     9.250000 |              4 |         8 |         10 |          2001 |        2004 |
|         Stephanie Brind |     9.250000 |              4 |         7 |         10 |          1999 |        2003 |
|            Claire Nitch |     9.333333 |              3 |         9 |         10 |          1994 |        1996 |
|             Jane Martin |     9.500000 |              2 |         9 |         10 |          1994 |        1995 |
|        Hania El Hammamy |    10.000000 |              1 |        10 |         10 |          2019 |        2019 |
|         Shelley Kitchen |    10.000000 |              2 |        10 |         10 |          2007 |        2008 |
|         Dipika Pallikal |    10.000000 |              1 |        10 |         10 |          2012 |        2012 |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;summary-for-male-players&quot;&gt;Summary for male players&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;|                 player | average_rank | years_in_top10 | best_rank | worst_rank | earliest_year | latest_year |
|-----------------------:|-------------:|---------------:|----------:|-----------:|--------------:|------------:|
|            Peter Nicol |     2.400000 |             10 |         1 |          8 |          1996 |        2005 |
|              Ali Farag |     3.250000 |              4 |         1 |          7 |          2016 |        2019 |
|           Jansher Khan |     3.333333 |              3 |         1 |          8 |          1996 |        1998 |
|         Jonathon Power |     3.666667 |              9 |         1 |          9 |          1997 |        2005 |
|    Mohamed El Shorbagy |     3.700000 |             10 |         1 |         10 |          2010 |        2019 |
|            Ramy Ashour |     3.909091 |             11 |         1 |          7 |          2006 |        2016 |
|       Grégory Gaultier |     4.000000 |             15 |         1 |         10 |          2003 |        2018 |
|           Ahmed Barada |     4.250000 |              4 |         2 |          7 |          1997 |        2000 |
|           Rodney Eyles |     4.333333 |              3 |         2 |          7 |          1996 |        1998 |
|           Nick Matthew |     4.642857 |             14 |         1 |         10 |          2004 |        2017 |
|           David Palmer |     4.727273 |             11 |         1 |          9 |          2000 |        2011 |
|            Amr Shabana |     4.727273 |             11 |         1 |          9 |          2004 |        2014 |
|           Paul Johnson |     5.000000 |              3 |         4 |          7 |          1998 |        2000 |
|        Stewart Boswell |     5.000000 |              2 |         4 |          6 |          2001 |        2002 |
|         Thierry Lincou |     5.200000 |             10 |         1 |          9 |          2001 |        2010 |
|        James Willstrop |     5.272727 |             11 |         1 |         10 |          2005 |        2017 |
|       Anthony Ricketts |     5.500000 |              4 |         3 |          7 |          2002 |        2006 |
|          Karim Darwish |     5.600000 |             10 |         1 |          9 |          2003 |        2013 |
|      Karim Abdel Gawad |     5.666667 |              6 |         2 |          9 |          2015 |        2019 |
|           Martin Heath |     5.666667 |              3 |         5 |          6 |          1998 |        2000 |
|             Del Harris |     6.000000 |              2 |         6 |          6 |          1996 |        1997 |
|             Dan Jenson |     6.000000 |              1 |         6 |          6 |          1998 |        1998 |
|     Marwan El Shorbagy |     6.250000 |              4 |         5 |          9 |          2016 |        2019 |
|             John White |     6.571429 |              7 |         2 |         10 |          1999 |        2007 |
|              Paul Coll |     6.666667 |              3 |         5 |          8 |          2017 |        2019 |
|            Omar Mosaad |     6.666667 |              3 |         4 |          8 |          2012 |        2016 |
|            Tarek Momen |     6.800000 |              5 |         4 |         10 |          2014 |        2019 |
|           Lee Beachill |     6.800000 |              5 |         1 |         10 |          2002 |        2006 |
| Miguel Ángel Rodríguez |     7.000000 |              3 |         5 |         10 |          2015 |        2019 |
|            Diego Elias |     7.000000 |              1 |         7 |          7 |          2019 |        2019 |
|       Stefan Casteleyn |     7.000000 |              1 |         7 |          7 |          1999 |        1999 |
|            David Evans |     7.000000 |              2 |         4 |         10 |          2000 |        2001 |
|            Simon Parke |     7.000000 |              5 |         3 |         10 |          1996 |        2000 |
|          Craig Rowland |     7.000000 |              1 |         7 |          7 |          1996 |        1996 |
|           Chris Walker |     7.000000 |              2 |         4 |         10 |          1996 |        1997 |
|           Brett Martin |     7.000000 |              2 |         5 |          9 |          1996 |        1997 |
|            Borja Golán |     7.000000 |              2 |         7 |          7 |          2013 |        2014 |
|           Peter Barker |     7.142857 |              7 |         5 |          9 |          2008 |        2014 |
|           Anthony Hill |     7.333333 |              3 |         5 |          9 |          1996 |        1999 |
|           Simon Rösner |     7.500000 |              6 |         3 |         10 |          2014 |        2019 |
|           Ong Beng Hee |     7.666667 |              3 |         7 |          8 |          2001 |        2003 |
|          Mark Chaloner |     8.666667 |              3 |         8 |         10 |          1996 |        2002 |
|     Laurens Jan Anjema |     9.000000 |              1 |         9 |          9 |          2010 |        2010 |
|             Alex Gough |     9.000000 |              2 |         9 |          9 |          1999 |        2000 |
|          Wael El Hindi |     9.000000 |              3 |         8 |         10 |          2007 |        2009 |
|      Mathieu Castagnet |     9.000000 |              2 |         9 |          9 |          2015 |        2016 |
|             Paul Price |     9.500000 |              2 |         9 |         10 |          2000 |        2001 |
|             Derek Ryan |    10.000000 |              1 |        10 |         10 |          1998 |        1998 |
|    Mohd Azlan Iskandar |    10.000000 |              1 |        10 |         10 |          2011 |        2011 |
|     Mohamed Abouelghar |    10.000000 |              1 |        10 |         10 |          2018 |        2018 |
|            Daryl Selby |    10.000000 |              2 |        10 |         10 |          2012 |        2013 |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;patterns-and-observations&quot;&gt;Patterns and observations&lt;/h2&gt;
&lt;p&gt;It is satisfying to be able to compare the various big names in squash.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;From this, the most outstanding player is Nicol David. They have the largest number of years in the top 10 of any female player by a big margin, and she has the 3rd best average rating. Only two players have a higher average rating: Sarah Fitz-Gerald’s average is for practical purposes the same (2.33 vs 2.35) and Michelle Martin’s is probably skewed by the fact the data only goes as far back as 1994.&lt;/li&gt;
  &lt;li&gt;A stand-out statistic is that Gaultier has been in the Top 10 for 15 years! Though it is mentioned by commentators frequently, it is only when I compare it to other players’ durations do I fully appreciate how incredible the achievement is. Nick Matthew is not far behind with 14 years.&lt;/li&gt;
  &lt;li&gt;Another surprise for me is how high Ramy Ashour is, compared to other players. It is well-recognised that he is the best player of his generation by a large margin, but he has also been plagued by injury for most of it, too. I would have predicted that it would have had a noticable dent on his stats. It is scary to think how much better his stats would have been if he did not have injuries!&lt;/li&gt;
  &lt;li&gt;Ali Farag’s average is very high. Though I do not want to diminish this achievement, I think this is a reflection of how the modern game has fewer elite players, whereas ten years ago, 7 or 8 of the top 10 players had all achieved a World Ranking of 1.&lt;/li&gt;
  &lt;li&gt;It is interesting to see general patterns. E.g. the players who have spent the most years in the top 10 are also players with higher averages and higher maximum ranks. For the males, this pattern is stark: if they have spent at least 9 years in the Top-10 rankings then they have reached the No. 1 spot.  For the females, the pattern is not as clear. This might suggeset that female squash has had a few players that have dominated the top spot, with the remaining players competiting for the other spots in the top 10.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Like I said earlier, the data is skewed in various ways.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The data only includes rankings at the end of each year. This will hide variations throughout the year. If you use monthly data instead, I expect the patterns will be clearer, and the best players will stand out even more from the good players.&lt;/li&gt;
  &lt;li&gt;The data only includes rankings that are in the top 10. For the absolute best players, this is not a loss of much data, but for the players in the 5-10 range, significant data is missing about their ranking history.&lt;/li&gt;
  &lt;li&gt;The data only goes back to the early 90s. This skews data by missing out the achievements of previous great players. The main one is Jahangir Khan, who had a 500+ match winning streak in the 80s!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;I will see if I can find more detailed ranking information, so I can get a more fine-grained analysis of the players. A project I have in the back of my mind is to create my own ranking system based on match history, and see if I can create a system which is more predictive than the current system. I think this should be possible, but again, I will need to see if I can obtain the relevant data.&lt;/p&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython.core.display&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HTML&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://en.wikipedia.org/wiki/Official_Women&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%27&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s_Squash_World_Ranking'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'https://en.wikipedia.org/wiki/Official_Men&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%27&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s_Squash_World_Ranking'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_not_numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;table_to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'th'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;n_cols&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'td'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;    
    
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
             &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'td'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
             &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_not_numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;url_to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    headers contains id needed to cut html into two pieces
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id=&quot;Year_end_world_top_10_players'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id=&quot;Year-end_number_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tables&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'table'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_stack&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_stack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'player'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_stack&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;player_summaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#     years_in_top10 = df.player.value_counts()
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;players&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'player'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
               &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'count'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                     &lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;players&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'average_rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'years_in_top10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'best_rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'worst_rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;s&quot;&gt;'earliest_year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latest_year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;players&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'average_rank'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;players&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;players_f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;player_summaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;players_m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;player_summaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series Squash rankings, Part III, All hail Bokeh! Squash rankings, Part II, dimension reduction and clustering</summary></entry><entry><title type="html">Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and **S**GD</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/17/sgd3.html" rel="alternate" type="text/html" title="Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and **S**GD" /><published>2020-09-17T00:00:00-05:00</published><updated>2020-09-17T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/17/sgd3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/17/sgd3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/10/01/sgd4.html&quot;&gt;Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/11/sgd2.html&quot;&gt;Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/09/10/sgd1.html&quot;&gt;Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous posts, I used gradient descent to model linear, quadratic and sinusoidal data. In the first post, the linear and quadratic models could be fit, but the sinusoidal data could not be fit.  In the second post, we saw how neural networks kind of fit the data, but not very well.&lt;/p&gt;

&lt;p&gt;This time, I will add the stochasticity by introducing mini-batches. My hope is that I will be able to fit the sinusoidal data that I could not fit in the first post. I will discuss this example at the end, because it is the most interesting&lt;/p&gt;

&lt;h2 id=&quot;models-with-neural-networks&quot;&gt;Models with neural networks&lt;/h2&gt;
&lt;p&gt;Here are animations of a neural network trying to fit using stochastic gradient descent.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_linearnn.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_quadraticnn.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sinnn.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The end results look similar to the end results without using mini-batches. The big difference is that the network converges much faster.&lt;/p&gt;

&lt;h2 id=&quot;fitting-sinusoidal-data-using-a-sinusoidal-model&quot;&gt;Fitting sinusoidal data using a sinusoidal model&lt;/h2&gt;
&lt;p&gt;Here is a representative example of my first attempts using SGD on sinusoidal data. Note that in all of the animations in this section, the same dataset and initial parameters were used, so the comparisons are more rigorous.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sin1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;To my dismay, we seem to have the same problem as with normal gradient descent. The system gets stuck in some local minimum where the amplitude is small. It still continues to ‘learn’ though.&lt;/p&gt;

&lt;p&gt;At this point, I experimented a little (e.g. with some ‘regularisation’), which I plan to describe in a separate post (spoiler alert - they didn’t work). While planning this blogpost, I re-watched the animation above and thought that maybe the learning rate is too big. I presumably tried playing with the learning rate already but for the sake of completeness, I thought it would be good to produce a series of animations to show you that varying the learning rate does not help.&lt;/p&gt;

&lt;p&gt;The learning rate in the animation above was 0.1.  Below is an animation for a learning rate of 0.01.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sin2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;! That was unexpected! It managed to find good parameters, but then jumped to some inferior local minimum. I managed to achieve something similar to this using the regularisation mentioned above (and which I will describe in a later post), but I was not expecting to see this by changing the learning rate. Clearly my memory is off and I had not experimented with the learning rate. I thought I would re-run the calculations to see if the same behaviour would occur again. (Note that the initial parameters are the same in all these animations, but there is still randomness from how the mini-batches are selected.)&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sin2b.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;So we get similar behaviour. For some time it looks like we are getting close to a good model but then it jumps away to some other set of parameters.&lt;/p&gt;

&lt;p&gt;Looks like I should make the learning rate smaller, and see if that prevents jumping away from the correct model. The next animation is for a learning rate of 0.001.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sin3.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;!!! Wow! Given that I had failed after several hours of trying, this was basically magic to me. The model gently and slides its way into position, increases its amplitude, then stays there. Fantastic!&lt;/p&gt;

&lt;p&gt;Now a big question arises. Were the learning rates in the first post of this series too high, and that was the reason for the struggles with sinusoidal models? There’s only one way to find out, and that’s by doing the experiment. Below is the resulting animation.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd3_sin3b.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;!!! All this time, it was as simple as changing the learning rate. How did I miss this?! What is noteworthy is how slow the learning is in gradient descent as compared to stochastic gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;There are two big lessons I learnt from this.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The first is to somehow take good notes of what I have tried and to be systematic. In my previous job teaching maths to STEM Foundation Year students, my colleague who taught Laboratory Skills was trying to explain the purpose of a lab-book to students: it should be a record of what you did, why you did it, what you observed, etc. so that somebody else (in particular, future-you) can read it and re-live your experience. It looks like I have only now learnt this lesson my colleague was trying to teach. Better late than never, I suppose.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The second is that the main benefit of stochastic gradient descent seems to be in efficiency/speed. I have read in places that it can help with preventing local minimums, but I am still unsure of this latter point.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;p&gt;The code for this project is in this &lt;a href=&quot;https://github.com/Lovkush-A/pytorch_sgd&quot;&gt;GitHub repository&lt;/a&gt;. I encourage you to play around and see what you can learn. If there is anything you do not understand in the code, please ask.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data</summary></entry><entry><title type="html">Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/11/sgd2.html" rel="alternate" type="text/html" title="Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD" /><published>2020-09-11T00:00:00-05:00</published><updated>2020-09-11T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/11/sgd2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/11/sgd2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/10/01/sgd4.html&quot;&gt;Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/17/sgd3.html&quot;&gt;Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and &lt;strong&gt;S&lt;/strong&gt;GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/09/10/sgd1.html&quot;&gt;Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous post, I showed my attempts at using gradient descent to fit linear, quadratic and sinusoidal data using (respectively) linear, quadratic and sinusoidal models. However, the universal approximation theorem says that the set of vanilla neural networks with one hidden layer can approximate any function to arbitrary precision. (An excellent and interactive sketch proof of this, where I first learnt about this theorem, is given in &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/chap4.html&quot;&gt;Michael Nielsen’s online book on neural networks&lt;/a&gt;.) Therefore, it should be possible for a neural network to model the datasets I created in the first post, and it should be interesting to see the visualisations of the learning taking place.&lt;/p&gt;

&lt;h2 id=&quot;linear-data&quot;&gt;Linear data&lt;/h2&gt;
&lt;p&gt;I created some linear data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*x + b + noise&lt;/code&gt;, and then tried to fit a neural network to it.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_linearnn_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;This is enchanting. I never thought I’d see something so delicate and graceful from crunching a whole bunch of numbers. I could watch this over and over again.&lt;/p&gt;

&lt;p&gt;You will probably notice that the learning suddenly speeds up at about 17 seconds in the video. This is a result of me increasing the learning rate (from &lt;code class=&quot;highlighter-rouge&quot;&gt;1e-5&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;1e-4&lt;/code&gt;) at a certain cut-off point. It is nice to be able to visually see the effect of changing the learning rate. Regarding the learning itself. it seems that the neural network struggles to fit the line well.&lt;/p&gt;

&lt;p&gt;I next tried increasing the learning rate. This next video is an example when the learning rate was &lt;code class=&quot;highlighter-rouge&quot;&gt;1e-3&lt;/code&gt; throughout.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_linearnn_3.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Changing the learning rate has improved the performance of the neural network considerably. The video is not as calm and satisfying to watch as the first one (though there is something comical about the jerky movements at the start), but it illustrates the value in choosing a good learning rate.&lt;/p&gt;

&lt;p&gt;I next tried introducing a cutoff point where the learning rate increases from &lt;code class=&quot;highlighter-rouge&quot;&gt;1e-3&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;3e-3&lt;/code&gt;. I have two examples of this.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_linearnn_5.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_linearnn_6.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;In both of these videos, there is a moment in the middle where things go a bit wacky for a few iterations and then quickly settle back down. This wacky moment occurs precisely when the increase in the learning rate kicks in. My explanation for this is that we are seeing the algorithm jump away from one local minimum and moving towards another.&lt;/p&gt;

&lt;p&gt;One thing I should have said is that in each of these videos, the training dataset remains the same, but the initialisation of the parameters of the neural network are different. So one other thing we are witnessing from these experiments is how different initialisation results in different models using gradient descent - i.e. there are many local minimums in the parameter space!&lt;/p&gt;

&lt;h2 id=&quot;quadratic-data&quot;&gt;Quadratic data&lt;/h2&gt;
&lt;p&gt;I created some quadratic data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*x*x + b*x + c + noise&lt;/code&gt; and tried to fit a neural network to it. Below are three examples. Note that as above, the dataset is staying the same each time, but the parameters are initialised differently each time and I play with the learning rates a bit, too.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_quadraticnn_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_quadraticnn_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_quadraticnn_4.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;All these examples have similar overall behaviour. It is quick to get close-ish to the quadratic, and then the learning dramatically slows (but there is still learning going on throughout). Again we see how the different initialisations leads to different final models, showing how we are finding different local minimums.&lt;/p&gt;

&lt;h2 id=&quot;sinusoidal-data&quot;&gt;Sinusoidal data&lt;/h2&gt;
&lt;p&gt;I created some sinusoidal data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*sin(b*x+ c) + d&lt;/code&gt; and tried to fit a neural network to it. As before, same dataset but with different starting parameters.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_3.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The first one shows some oscillating behaviour, similar to the first sinusoidal case in the first post of this series. Looks like the behaviour is not as unlikely as I previously thought. The second two produce mediocre results, at best.&lt;/p&gt;

&lt;p&gt;Looking at the graphs, there seem to be ‘too many wiggles’, so I thought I’d try reducing the number of neurons in the hidden layer. The next three videos show what happens with eight neurons.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_4.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_5.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd2_sinnn_6.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;These perform less well than with twenty neurons. The final video is interesting for its crazy behaviour at the start - the function seems to spin around and do all kinds of weird stuff before settling down. I do not know what to make of that.&lt;/p&gt;

&lt;p&gt;There is lots more experimentation that can be done, but I feel this is a good place to stop and move on to other things to investigate.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;There are various things I learnt doing this.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;There is a lot to be learnt by playing around with the ideas. Though (I think) I understand the theory of gradient descent and of vanilla neural networks, it is evident that the whole is greater than the sum of its parts. I under-estimated what I could have learnt by experimenting.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It seems neural networks are only useful for interpolation - i.e. making predictions for data similar to the training data. They are hopeless at extrapolating: I think they necessarily have horizontal asymptotes in both x-directions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The initialisation of parameters matters a lot for neural networks.
    &lt;ul&gt;
      &lt;li&gt;My very first settings were useless, and were seemingly only capable of modelling a sigmoid function. For a while, I thought my code was buggy, but after some experimentation, it turned out the initial parameter settings were inappropriate.&lt;/li&gt;
      &lt;li&gt;Different initialisations resulted in vastly different final models. Presumably this is also the case with more complex tasks, but maybe it does not matter when doing a classification on real data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The range of values in the data impacts the choice of parameters. As I mentioned in the first post, I have read that normalising is important. The fact that the parameter settings are sensitive to the range of values in the dataset could be a big reason why normalising is important.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manually creating a neural network (even with only 1 layer) is a bit of faff; I should learn how to create one using the pytorch library.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;You can create some funky visuals with neural networks! Somebody more creative than I am could add some music to each of these to produce some interesting art. These animations may even be a weird alternative to &lt;a href=&quot;https://en.wikipedia.org/wiki/Rorschach_test&quot;&gt;Rorschach inkblot tests&lt;/a&gt;: ‘How does this video make you feel? What do you see in this video?’&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;p&gt;The code for this project is in this &lt;a href=&quot;https://github.com/Lovkush-A/pytorch_sgd&quot;&gt;GitHub repository&lt;/a&gt;. I encourage you to play around and see what you can learn. If there is anything you do not understand in the code, please ask.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and SGD Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data</summary></entry><entry><title type="html">Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data</title><link href="https://lovkush-a.github.io/blog/data%20science/python/2020/09/10/sgd1.html" rel="alternate" type="text/html" title="Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data" /><published>2020-09-10T00:00:00-05:00</published><updated>2020-09-10T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/python/2020/09/10/sgd1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/python/2020/09/10/sgd1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/python/2020/10/01/sgd4.html&quot;&gt;Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/17/sgd3.html&quot;&gt;Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and &lt;strong&gt;S&lt;/strong&gt;GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/11/sgd2.html&quot;&gt;Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;At the end of &lt;a href=&quot;https://youtu.be/5L3Ao5KuCC4?t=7244&quot;&gt;Lecture 3 of the 2020 FastAI course&lt;/a&gt; and at the end of &lt;a href=&quot;https://youtu.be/ccMHJeQU4Qw?t=6394&quot;&gt;Lecture 2 of the 2018 FastAI course&lt;/a&gt;, there are visualisations of the gradient descent algorithm. I quite liked them, in particular the animation from the 2018 version, and I wanted to re-create them and on more complex examples.&lt;/p&gt;

&lt;p&gt;The animations I created are available below. Note that in all animations, the orange dots represent the training data, and the blue line represents the model’s predictions. I will go through them and give my thoughts. At the end I describe some insights I gained by doing this.&lt;/p&gt;

&lt;h2 id=&quot;linear-data&quot;&gt;Linear data&lt;/h2&gt;
&lt;p&gt;I created some linear data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*x + b + noise&lt;/code&gt;, and then tried to use gradient descent to determine the coefficients.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_linear_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;This animation is representative of the various examples I tried for linear data. Gradient descent is quick to get very close to the data, but then the learning dramatically slows down and it takes many iterations to improve further. (Note, you have to pay close attention to notice that there is still learning going on throughout the whole video).  Clearly, there is some optimisation that can be done with the learning rate; I did try to create a cutoff point where the learning rate gets bigger, but I am sure there are much better ways of doing things.&lt;/p&gt;

&lt;h2 id=&quot;quadratic-data&quot;&gt;Quadratic data&lt;/h2&gt;
&lt;p&gt;Next I created some quadratic data &lt;code class=&quot;highlighter-rouge&quot;&gt;y=a*x*x + b*x + c + noise&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_quadratic_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The pattern here is very similar to the pattern for the linear case: gradient descent quickly reaches a good model, and then the learning dramatically slows down. This is not too surprising, because though the final function is non-linear, this is still a linear-regression problem by treating &lt;code class=&quot;highlighter-rouge&quot;&gt;x*x&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; as separate features.&lt;/p&gt;

&lt;h2 id=&quot;sinusoidal-data&quot;&gt;Sinusoidal data&lt;/h2&gt;
&lt;p&gt;Next I created some sinusoidal data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*(sin(b*x + c)) + d&lt;/code&gt;. Things were more interesting here.&lt;/p&gt;

&lt;p&gt;The first video shows you what happened when I chose a learning rate that was too large (but not so large so as to have everything diverge to infinity):&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_sin_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Crazy, right! The model is oscillating back and forth, with the oscillations slowly getting larger with time. In Lecture 3 of the 2020 course, this behaviour is illustrated with the example of using gradient descent to minimise a quadratic function, but I never thought I would actually encounter this behaviour out in the wild.&lt;/p&gt;

&lt;p&gt;This second video shows what happens when I choose a smaller learning rate:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_sin_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;No craziness here, but it does not converge to an appropriate solution. I think the explanation for this is that the algorithm has found a local-minimum, and so the algorithm gets stuck and cannot improve.  This is qualitatively different to the linear and quadratic cases: since those were both instances of linear regression, it is known from theory that there is only one minimum so gradient descent will reach it. This sinusoidal case cannot be re-written as a linear regression problem, so there is not automatic guarantee of there being only one minimum point; from this experimentation, it looks like there multiple minimum points!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I learnt various things by doing this experiment.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The learning rate is very important! I had to play around with the learning rates to get things to work.&lt;/li&gt;
  &lt;li&gt;The range of values in the training data seemed to have big impact on the which learning rates to use. I am not 100% sure about this, but I have read in places that it is important to normalise your data, and perhaps its effect on learning rates is a big reason.&lt;/li&gt;
  &lt;li&gt;I learnt how to create animations in matplotlib! And also how to include video files in this blog. :D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are various things I would like to try.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The next thing I will try is using the same datasets, but seeing if I can fit a neural network to the data.&lt;/li&gt;
  &lt;li&gt;Stochastic gradient descent. My hope is that it will avoid the local minimum problem in the sinusoidal case.&lt;/li&gt;
  &lt;li&gt;Creating a web-app out of this, so you can easily experiment for yourselves.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;p&gt;The code for this project is in this &lt;a href=&quot;https://github.com/Lovkush-A/pytorch_sgd&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Stochastic Gradient Descent, Part IV, Experimenting with sinusoidal case Stochastic Gradient Descent, Part III, Fitting linear, quadratic and sinusoidal data using a neural network and SGD Stochastic Gradient Descent, Part II, Fitting linear, quadratic and sinusoidal data using a neural network and GD</summary></entry></feed>