<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://lovkush-a.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lovkush-a.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-09-11T15:13:56-05:00</updated><id>https://lovkush-a.github.io/blog/feed.xml</id><title type="html">Lovkush Agarwal</title><subtitle>A blog for my data science learning and projects</subtitle><entry><title type="html">Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/10/sgd1.html" rel="alternate" type="text/html" title="Stochastic Gradient Descent, Part I, Gradient descent on linear, quadratic and sinusoidal data" /><published>2020-09-10T00:00:00-05:00</published><updated>2020-09-10T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/10/sgd1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/10/sgd1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;At the end of &lt;a href=&quot;https://youtu.be/5L3Ao5KuCC4?t=7244&quot;&gt;Lecture 3 of the 2020 FastAI course&lt;/a&gt; and at the end of &lt;a href=&quot;https://youtu.be/ccMHJeQU4Qw?t=6394&quot;&gt;Lecture 2 of the 2018 FastAI course&lt;/a&gt;, there are visualisations of the gradient descent algorithm. I quite liked them, in particular the animation from the 2018 version, and I wanted to re-create them and on more complex examples.&lt;/p&gt;

&lt;p&gt;The animations I created are available below. Note that in all animations, the orange dots represent the training data, and the blue line represents the model’s predictions. I will go through them and give my thoughts. At the end I describe some insights I gained by doing this.&lt;/p&gt;

&lt;h2 id=&quot;linear-data&quot;&gt;Linear data&lt;/h2&gt;
&lt;p&gt;I created some linear data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*x + b + noise&lt;/code&gt;, and then tried to use gradient descent to determine the coefficients.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_linear_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;This animation is representative of the various examples I tried for linear data. Gradient descent is quick to get very close to the data, but then the learning dramatically slows down and it takes many iterations to improve further. (Note, you have to pay close attention to notice that there is still learning going on throughout the whole video).  Clearly, there is some optimisation that can be done with the learning rate; I did try to create a cutoff point where the learning rate gets bigger, but I am sure there are much better ways of doing things.&lt;/p&gt;

&lt;h2 id=&quot;quadratic-data&quot;&gt;Quadratic data&lt;/h2&gt;
&lt;p&gt;Next I created some quadratic data &lt;code class=&quot;highlighter-rouge&quot;&gt;y=a*x*x + b*x + c + noise&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_quadratic_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;The pattern here is very similar to the pattern for the linear case: gradient descent quickly reaches a good model, and then the learning dramatically slows down. This is not too surprising, because though the final function is non-linear, this is still a linear-regression problem by treating &lt;code class=&quot;highlighter-rouge&quot;&gt;x*x&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; as separate features.&lt;/p&gt;

&lt;h2 id=&quot;sinusoidal-data&quot;&gt;Sinusoidal data&lt;/h2&gt;
&lt;p&gt;Next I created some sinusoidal data &lt;code class=&quot;highlighter-rouge&quot;&gt;y = a*(sin(b*x + c)) + d&lt;/code&gt;. Things were more interesting here.&lt;/p&gt;

&lt;p&gt;The first video shows you what happened when I chose a learning rate that was too large (but not so large so as to have everything diverge to infinity):&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_sin_1.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;Crazy, right! The model is oscillating back and forth, with the oscillations slowly getting larger with time. In Lecture 3 of the 2020 course, this behaviour is illustrated with the example of using gradient descent to minimise a quadratic function, but I never thought I would actually encounter this behaviour out in the wild.&lt;/p&gt;

&lt;p&gt;This second video shows what happens when I choose a smaller learning rate:&lt;/p&gt;

&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/blog/images/sgd1_sin_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;

&lt;p&gt;No craziness here, but it does not converge to an appropriate solution. I think the explanation for this is that the algorithm has found a local-minimum, and so the algorithm gets stuck and cannot improve.  This is qualitatively different to the linear and quadratic cases: since those were both instances of linear regression, it is known from theory that there is only one minimum so gradient descent will reach it. This sinusoidal case cannot be re-written as a linear regression problem, so there is not automatic guarantee of there being only one minimum point; from this experimentation, it looks like there multiple minimum points!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I learnt various things by doing this experiment.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Learning rate is very important! I had to play around with the learning rates to get things to work.&lt;/li&gt;
  &lt;li&gt;The range of values in the training data seemed to have big impact on the which learning rates to use. I am not 100% sure about this, but I have read in places that it is important to normalise your data, and perhaps its effect on learning rates is a big reason.&lt;/li&gt;
  &lt;li&gt;I learnt how to create animations in matplotlib! And also how to include video files in this blog. :D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are various things I would like to try.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The next thing I will try is using the same datasets, but seeing if I can fit a neural network to the data.&lt;/li&gt;
  &lt;li&gt;Stochastic gradient descent. My hope is that it will avoid the local minimum problem in the sinusoidal case.&lt;/li&gt;
  &lt;li&gt;Creating a web-app out of this, so you can easily experiment for yourselves.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;p&gt;The code for this project is in this &lt;a href=&quot;https://github.com/Lovkush-A/production/tree/master/pytorch_gd&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series</summary></entry><entry><title type="html">FastAI Course, Part III, Frustrations with creating an image classifier</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/08/fastai3.html" rel="alternate" type="text/html" title="FastAI Course, Part III, Frustrations with creating an image classifier" /><published>2020-09-08T00:00:00-05:00</published><updated>2020-09-08T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/08/fastai3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/09/08/fastai3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/08/30/fastai2.html&quot;&gt;FastAI Course, Part II, Lesson 1 and sentiment analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/08/09/fastai1.html&quot;&gt;FastAI Course, Part I, Lessons 1 and 2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;After reading through Chapter 2 of the Fast AI course/book, it was time I tried putting the ideas into practice. I decided to create a classifier that distinguishes between squash, tennis and badminton rackets. Then using voila and binder, I created a little web app for it: check it out &lt;a href=&quot;https://mybinder.org/v2/gh/Lovkush-A/production/master?urlpath=%2Fvoila%2Frender%2Ffastai_rackets%2Frackets.ipynb&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;

&lt;h2 id=&quot;a-comedy-of-errors&quot;&gt;A comedy of errors&lt;/h2&gt;
&lt;p&gt;This project was frustrating for me. I somehow managed to make numerous errors at every step which could not be straightforwardly de-bugged. I try to describe them here, but I have undoubtedly forgotten many of them.&lt;/p&gt;

&lt;h3 id=&quot;the-bing-api&quot;&gt;The Bing API&lt;/h3&gt;
&lt;p&gt;The instructions from the notes: “To download images with Bing Image Search, sign up at Microsoft for a free account. You will be given a key, which you can copy and enter in a cell as follows.” Sounds simple. I went to the Microsoft website and logged on. This is what I saw:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/fastai3_microsoft.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, there’s nothing obvious here regarding Bing or APIs. I spent a whole bunch of time looking through all the menus, but to no avail. The instructions made it sound simple, and yet I couldn’t manage. I searched in the FastAI forums and a relevant &lt;a href=&quot;https://forums.fast.ai/t/getting-the-bing-image-search-key/67417&quot;&gt;post&lt;/a&gt; was easy to find. It explained the (non-trivial) steps needed. A big non-triviality is that you should be using a Microsoft &lt;em&gt;Azure&lt;/em&gt; account, not a Microsoft account. I think the book should make this clearer. It would have saved me (and presumably many others) a bunch of time.&lt;/p&gt;

&lt;h3 id=&quot;padding&quot;&gt;Padding&lt;/h3&gt;
&lt;p&gt;I downloaded the datasets, viewed some of the images, and deleted the files which were erroneous. Next up was to create a &lt;code class=&quot;highlighter-rouge&quot;&gt;DataBlock&lt;/code&gt; with the appropriate transforms/data augmentation. To ensure the images have the correct aspect ratio, I decided that padding is the best option. I tried it, using &lt;code class=&quot;highlighter-rouge&quot;&gt;pad_mode = 'zeros'&lt;/code&gt;. It looked alright, but most of the images have white backgrounds, so I thought maybe it would be better for the images to be padded with white space. I guessed that &lt;code class=&quot;highlighter-rouge&quot;&gt;pad_mode = 'ones'&lt;/code&gt; would work, but alas it did not. So, I did what has been recommended numerous times, and went to the docs.&lt;/p&gt;

&lt;p&gt;This is what I found:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/fastai3_pad.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Maybe I am in the minority, but I do not find this helpful. Here are some things that frustrate me about this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What are the possibilities for &lt;code class=&quot;highlighter-rouge&quot;&gt;*args&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;** kwargs&lt;/code&gt;? How would I find out?&lt;/li&gt;
  &lt;li&gt;What does ‘All possible mode as attributes to get tab-completion and typo-proofing’ mean?!  What does it have to do with padding images?&lt;/li&gt;
  &lt;li&gt;What is &lt;code class=&quot;highlighter-rouge&quot;&gt;TensorBBox&lt;/code&gt;? Or &lt;code class=&quot;highlighter-rouge&quot;&gt;TensorPoint&lt;/code&gt;?&lt;/li&gt;
  &lt;li&gt;What’s the relevance of the change in font in the headings? Is it self-evident? Looking at it more closely, you have one font for classes and one font for methods. But do we need a different font for that? Changing heading formats usually indicates a change in the level of headings, but I don’t think that is what is happening here.&lt;/li&gt;
  &lt;li&gt;Most importantly, what are the different options for &lt;code class=&quot;highlighter-rouge&quot;&gt;pad_mode&lt;/code&gt;? If you scroll further down, three examples are provided (zeros, reflection and border), but it is not clear if these are all the options. Maybe they are, maybe they aren’t. I don’t know.&lt;/li&gt;
  &lt;li&gt;Really, what does ‘All possible mode as attributes to get tab-completion and typo-proofing’ actually mean??&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Perhaps I could find out more by looking at the source code. After all, as is emphasised several times in the lectures, most of the source code is only a few lines and thus easy to understand.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CropPad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RandTransform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Center crop or pad an image to `size`&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PadMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_process_sz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;store_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorBBox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorPoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;orig_sz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_get_sz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crop_pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orig_sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_sz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Yes, there are only several lines of code here. However, they are not helpful, at least not for me. In order to understand any of this, I need to go searching through the rest of the code base, which I am not inclined to do. I should not have to do this to find out if I can create white padding instead of black padding (or maybe I should?).&lt;/p&gt;

&lt;p&gt;Anyway, I stopped here with the presumption that it is not possible to get white padding.&lt;/p&gt;

&lt;h3 id=&quot;runtimeerror-dataloader-worker-pid-19862-is-killed-by-signal-killed&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RuntimeError: DataLoader worker (pid 19862) is killed by signal: Killed.&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;I made various other decisions for the DataBlock and created the DataLoaders. Now it was time to do the modelling! I ran the cell, and to my dismay, I got the error message shown in the heading. I didn’t understand it. I checked all my code carefully and did not spot anything wrong. Next I tried to run the examples from the book as is. The same error came up. This was bizarre!&lt;/p&gt;

&lt;p&gt;It was time for some Googling. I searched around, saw people with similar error messages, and tried their suggestions. None of them solved the problem. It was time to get to bed at this stage, so I decided I will ask about this in the forum, and have another stab the next day.&lt;/p&gt;

&lt;p&gt;Next day, I got ready to tackle the problem and opened up Gradient. But something was a little off:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/fastai3_gradient.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The machine type was set to CPU! I did not remember selecting this, so was a bit confused. Anyway, I tried starting up the notebook, and the pop-up comes up to select the options. The default selection is the CPU. Hmm, that is odd. I tried to change it to GPU, and then I discovered the problem: there was no Free GPU available. It looks like the day before, I just assumed the settings would be the same as previous runs, so I did not check the machine type, and I must have been using the CPU option. This is almost certainly the cause of the &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader worker&lt;/code&gt; error. At least I now know the issue.&lt;/p&gt;

&lt;p&gt;Time to move to Colab.&lt;/p&gt;

&lt;h3 id=&quot;google-colab&quot;&gt;Google Colab&lt;/h3&gt;
&lt;p&gt;This is just me, but I dislike the Colab interface. It is similar to Jupyter Notebook, but different in little ways that my brain finds off-putting. One example is that in Colab, the shortcut &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; to insert a new cell automatically enters the cell; this is not what I want, as I often want to create a bunch of cells at once, and then move into them.&lt;/p&gt;

&lt;p&gt;These are minor issues, but I thought I may as well include them, in case anybody else out there gets some comfort knowing they are not alone.&lt;/p&gt;

&lt;h3 id=&quot;re-training-model-post-cleaning&quot;&gt;Re-training model post cleaning&lt;/h3&gt;
&lt;p&gt;I continued with the project, and managed to get the classifier to work. I then cleaned the data using the easy-to-use widget created by FastAI. I then tried to do some further fine tuning, but I got an error message saying that a certain image file, &lt;code class=&quot;highlighter-rouge&quot;&gt;00000149.png&lt;/code&gt;, cannot be found.&lt;/p&gt;

&lt;p&gt;I had a little look at the code, and realised my error. I deleted some images while cleaning (including image &lt;code class=&quot;highlighter-rouge&quot;&gt;00000149.png&lt;/code&gt;), but did not re-run the cell that defines the dataloaders &lt;code class=&quot;highlighter-rouge&quot;&gt;dls&lt;/code&gt; variable, where the information on the dataset is stored. So I re-ran the cell, and tried again. But I still got the error message.&lt;/p&gt;

&lt;p&gt;I wanted to investigate the &lt;code class=&quot;highlighter-rouge&quot;&gt;dls&lt;/code&gt; variable to find out what is going on; specifically, I wanted to see which filenames are stored in the variable and check whether &lt;code class=&quot;highlighter-rouge&quot;&gt;00000149.png&lt;/code&gt; is listed there. Similar to the issues I had with the padding above, I did not find the documentation helpful. However, using &lt;code class=&quot;highlighter-rouge&quot;&gt;dir&lt;/code&gt; (a super handy function, by the way. It lists &lt;em&gt;all&lt;/em&gt; the properties and methods that an object has) and playing a bit, I was able to find the list of filenames stored in &lt;code class=&quot;highlighter-rouge&quot;&gt;dls&lt;/code&gt;; &lt;code class=&quot;highlighter-rouge&quot;&gt;00000149.png&lt;/code&gt; was not there!&lt;/p&gt;

&lt;p&gt;This left only one possibility: that filenames are stored in the &lt;code class=&quot;highlighter-rouge&quot;&gt;learn&lt;/code&gt; variable. Based on my experience with other ML tools (e.g. scikitlearn), this is counter-intuitive to me. At this stage, I just wanted to get a working example as quickly as possible, so I did not investigate how I can do additional fine-tuning cycles on new datasets. Instead, I just created a fresh learner object, and trained that.&lt;/p&gt;

&lt;p&gt;I am not sure anybody can do anything about this kind of problem, as it stems from using tools as black-boxes, without understanding how they work. Another example of this I have had is in using conda: I am comfortable creating new environments, but I do not know how to rename a directory or move directories around, because that information is stored somewhere for conda to function, and I do not know how to change that information.&lt;/p&gt;

&lt;p&gt;Unfortunately, it does not change that the experience is frustrating - there is a simple task that I want to do, my naive approach does not work, and in order to learn how do it properly, I have to get a fairly comprehensive understanding of the tool. If anybody has any advice or suggestions, do please let me know!&lt;/p&gt;

&lt;h3 id=&quot;binder&quot;&gt;Binder&lt;/h3&gt;
&lt;p&gt;The next bunch of tasks went well, as far as I can remember. Exporting the learner, creating a local environment where I can create the jupyter notebook that will be turned into the web app, installing all the packages, creating the notebook, getting voila to work locally, and pushing it to github. I was literally one step away: get binder to work. The finish line was literally right in front of me.&lt;/p&gt;

&lt;p&gt;Oh boy was I wrong. I do not know how I managed to make such a mess of this step. From what I remember, I encountered two main problems, but my ineptitude dragged out the process far longer than it ought to have.&lt;/p&gt;

&lt;p&gt;The first mistake was not to change the &lt;code class=&quot;highlighter-rouge&quot;&gt;File&lt;/code&gt; setting to &lt;code class=&quot;highlighter-rouge&quot;&gt;URL&lt;/code&gt;, when you enter the path to the file in Binder. This setting was in my blindspot; I never even noticed that box. This is made worse because the voila documentation clearly states that you should do this; in fact, this is how I found the error, because I chose to re-read the instructions carefully, after my various other attempts failed.&lt;/p&gt;

&lt;p&gt;The second issue I had was with the requirements file that should be provided. I first tried using the file created by using &lt;code class=&quot;highlighter-rouge&quot;&gt;conda env export&lt;/code&gt;, but that did not work. Googling the error messages revealed that conda lists many device specific requirements, which will not work with the Linux machines that binder uses. Googling also showed the two-step process to get around this issue: create a modified version of the requirements by adding some tags to the &lt;code class=&quot;highlighter-rouge&quot;&gt;conda env export&lt;/code&gt; command, and then manually remove any requirements that still cause an error on Binder.&lt;/p&gt;

&lt;p&gt;This was it: I fixed the two problems and was minutes away from completion. I got binder going, and as it does, it was taking a few minutes to things set-up.  But things were taking very long. Something was not right. I just kept waiting, but eventually, the process quit with some other error message.&lt;/p&gt;

&lt;p&gt;I was so close, yet so far. I tried searching around on the forums, to see if anybody else had any issues on binder. I ended up finding a blog post and example github repo, so I tried to imitate that. The main takeaway was that they manually constructed a requirements file with 4 or 5 requirements, rather than using an automatically generated file from conda with many more requirements.&lt;/p&gt;

&lt;p&gt;After a few more attempts and ironing out several little mistakes (e.g. they used &lt;code class=&quot;highlighter-rouge&quot;&gt;fastai2&lt;/code&gt; in their requirements, which is now out-of-date), it finally worked.&lt;/p&gt;

&lt;h2 id=&quot;final-remarks&quot;&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;This has been a stressful but enlightening experience. Just writing this blog made me re-live the emotions: the frustration when things seemed unnecessarily complicated, and the sense of achievement and relief when I finally reached the end.&lt;/p&gt;

&lt;p&gt;It may sound like I dislike FastAI and the course, but the opposite is true. Like I said in my first post on the FastAI course, I am impressed with the teaching and all the thought that has gone into it. I would strongly recommend this course to anybody interested in AI or Machine Learning. However, I think this may also be why I experience more frustration with it. I have such a high opinion of the course, that any negative stands out; I am holding the team to particularly high standards.&lt;/p&gt;

&lt;p&gt;To end, I hope this blog entry has been useful for you in some way. I welcome any comments or thoughts or disagreements; please feel free to let me know.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series FastAI Course, Part II, Lesson 1 and sentiment analysis FastAI Course, Part I, Lessons 1 and 2</summary></entry><entry><title type="html">Analysing the movies I’ve watched, Part V, Data visualisation II</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/09/02/mymovies5.html" rel="alternate" type="text/html" title="Analysing the movies I've watched, Part V, Data visualisation II" /><published>2020-09-02T00:00:00-05:00</published><updated>2020-09-02T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/09/02/mymovies5</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/09/02/mymovies5.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/24/mymovies4.html&quot;&gt;Analysing the movies I’ve watched, Part IV, Data visualisation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/19/mymovies3.html&quot;&gt;Analysing the movies I’ve watched, Part III, Joining the tables&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/03/mymovies2.html&quot;&gt;Analysing the movies I’ve watched, Part II, Data cleaning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/02/mymovies1.html&quot;&gt;Analysing the movies I’ve watched, Part I, Data collection&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In a previous post, I described how the joining missed out half the data. After making various plots, is turns out the joining was sometimes erroneous too. Hence, I bit the bullet and decided I to manually do the joining, and get a complete and clean dataset. Learning the lessons from past attempts at manual processing, it was a fairly smooth process. (Furthermore, things were significantly sped up by using Selenium - which allowed me to automate the process of searching for a movie on imdb). In the end, it took roughly 3 hours to tidy the dataset and have the official imdb id attached to each entry in my database. And now for the charts!&lt;/p&gt;

&lt;h2 id=&quot;year-of-release&quot;&gt;Year of release&lt;/h2&gt;
&lt;p&gt;Below are charts showing information about the year of release for the movies I have watched. The first one is just a histogram, and the second shows a scatter-chart showing the year I watched the movie against the year the movie released.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies5_releaseyear.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;/blog/images/mymovies5_releaseyear2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Not sure if there is anything surprising about any of these charts. One neat thing is that one could probably get an idea of my age based on the first chart. The second chart seems to show that the majority of movies I watch are relatively new.&lt;/p&gt;

&lt;h2 id=&quot;ratings&quot;&gt;Ratings&lt;/h2&gt;
&lt;p&gt;Below is a chart showing the average ratings (by users of imdb) for the movies I have watched, along with the distribution of ratings for all the movies in imdb.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies5_ratings1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is clear from this chart that I tend to watch ‘decent’ movies, as judged by the movies, and that I avoid ‘bad’ movies, but I also seem to avoid the ‘best’ movies.&lt;/p&gt;

&lt;p&gt;Below is a chart comparing the ratings for all the movies I have watched with the ratings of the movie I would recommend.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies5_ratings2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is reassuring to see that, overall, the movies I recommend are generally better regarded than the movies I do not recommend.&lt;/p&gt;

&lt;p&gt;Lastly, here is a chart showing the variation in ratings by the year I watched the movie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies5_ratings3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I cannot really discern any patterns here, that aren’t revealed by other charts. Patterns that I can see are that I watched a lot more movies (and greater variety of quality of  movies) in 2008 and 2009, and that the movies I recommend tend to have higher ratings than those I don’t.&lt;/p&gt;

&lt;p&gt;To end this section, here is a list of the most and least popular movies I have watched.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Movie&lt;/th&gt;
      &lt;th&gt;Rating on imdb&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;the shawshank redemption&lt;/td&gt;
      &lt;td&gt;9.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the dark knight&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12 angry men&lt;/td&gt;
      &lt;td&gt;8.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the lord of the rings: the return of the king&lt;/td&gt;
      &lt;td&gt;8.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pulp fiction&lt;/td&gt;
      &lt;td&gt;8.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fight club&lt;/td&gt;
      &lt;td&gt;8.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the lord of the rings: the fellowship of the ring&lt;/td&gt;
      &lt;td&gt;8.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;forrest gump&lt;/td&gt;
      &lt;td&gt;8.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;inception&lt;/td&gt;
      &lt;td&gt;8.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the matrix&lt;/td&gt;
      &lt;td&gt;8.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the lord of the rings: the two towers&lt;/td&gt;
      &lt;td&gt;8.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;goodfellas&lt;/td&gt;
      &lt;td&gt;8.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;star wars: episode v - the empire strikes back&lt;/td&gt;
      &lt;td&gt;8.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;se7en&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;city of god&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;interstellar&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;saving private ryan&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the silence of the lambs&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;star wars: episode iv - a new hope&lt;/td&gt;
      &lt;td&gt;8.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;gladiator&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the departed&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;casablanca&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the usual suspects&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;dear zachary: a letter to a son about his father&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;whiplash&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;joker&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;psycho&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;senna&lt;/td&gt;
      &lt;td&gt;8.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Movie&lt;/th&gt;
      &lt;th&gt;Rating on imdb&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;steel&lt;/td&gt;
      &lt;td&gt;2.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;troll 2&lt;/td&gt;
      &lt;td&gt;2.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the foreigner&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;batman &amp;amp; robin&lt;/td&gt;
      &lt;td&gt;3.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;half a person&lt;/td&gt;
      &lt;td&gt;3.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;friday the 13th part viii: jason takes manhattan&lt;/td&gt;
      &lt;td&gt;4.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;barely legal&lt;/td&gt;
      &lt;td&gt;4.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;elektra&lt;/td&gt;
      &lt;td&gt;4.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;doe: dead or alive&lt;/td&gt;
      &lt;td&gt;4.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;friday the 13th: a new beginning&lt;/td&gt;
      &lt;td&gt;4.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;uncut gem&lt;/td&gt;
      &lt;td&gt;4.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;blair witch&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;a teacher’s crime&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tekken: the motion picture&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;in their skin&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;daredevil&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;scary movie 2&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;the circle&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;friday the 13th part vii: the new blood&lt;/td&gt;
      &lt;td&gt;5.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;little&lt;/td&gt;
      &lt;td&gt;5.4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The one thing I feel slightly ashamed of is that I watched so many of the Friday the 13th movies. I think my reasoning was that if a series has that many movies, there must be something good about it. I kept going on, even though I thought the movies were bad, in the hope that there is a moment in the series where the movies become good. I did finally stop watching the series - it just took eight movies to make that decision…&lt;/p&gt;

&lt;h2 id=&quot;genres&quot;&gt;Genres&lt;/h2&gt;
&lt;p&gt;Below is a table showing a breakdown of the genres of movie I watched, ordered by which genre has the highest odds of me recommending it. Note that most movies had multiple genres.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Genre&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Frequency&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Frequency Recommended&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Percent recommended&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;thriller&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;126&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;37&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;war&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;sport&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.28&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;drama&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;319&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;87&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.27&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;sci-fi&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;86&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;22&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;crime&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;146&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.25&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;biography&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;47&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.23&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;music&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;romance&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;56&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;comedy&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;210&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;mystery&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;animation&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;51&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;family&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;history&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;fantasy&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;70&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;documentary&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;adventure&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;188&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;horror&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;66&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;action&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;227&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;musical&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;news&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;western&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The entries that stand out to me are those with the largest frequencies. There is strong evidence that I am more likely to recommend a thriller or a drama than a comedy, and that I am unlikely to recommend adventure or action movies.&lt;/p&gt;

&lt;h2 id=&quot;directors&quot;&gt;Directors&lt;/h2&gt;
&lt;p&gt;Below is a list of the directors, along with the movies, whose movies I have most watched.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Steven Spielberg
 a.i. artificial intelligence
          catch me if you can
                         jaws
                jurassic park
              minority report
      raiders of the lost ark
          saving private ryan
     the adventures of tintin

Peter Jackson
                                         king kong
                 the hobbit: an unexpected journey
         the hobbit: the battle of the five armies
 the lord of the rings: the fellowship of the ring
     the lord of the rings: the return of the king
             the lord of the rings: the two towers

Christopher Nolan
               dunkirk
             inception
          interstellar
               memento
       the dark knight
 the dark knight rises

Guy Ritchie
 lock, stock and two smoking barrels
                          rocknrolla
                     sherlock holmes
  sherlock holmes: a game of shadows
                              snatch
             the man from u.n.c.l.e.

Martin Scorsese
               cape fear
              goodfellas
                 silence
             taxi driver
            the departed
 the wolf of wall street

Quentin Tarantino
             inglourious basterds
                kill bill: vol. 1
 once upon a time... in hollywood
                     pulp fiction
                   reservoir dogs
                the hateful eight

Danny Boyle
    28 days later
       steve jobs
 t2 trainspotting
    trainspotting
        yesterday

Matthew Vaughn
                     kick-ass
 kingsman: the secret service
                   layer cake
                     stardust
           x-men: first class

David Fincher
                          fight club
                           gone girl
                               se7en
 the curious case of benjamin button
                  the social network

M. Night Shyamalan
             glass
 lady in the water
             split
   the sixth sense
       unbreakable

Darren Aronofsky
          black swan
             mother!
                noah
 requiem for a dream
        the wrestler
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tend not to pay any attention to who the director is, so for me, the interesting thing here is to see how movies that I would have said had no connection in fact have the same director. E.g. I did not realise I had watched that many movies by Spielberg. The other thing that stands out here is that all the directors are male.&lt;/p&gt;

&lt;h2 id=&quot;actors&quot;&gt;Actors&lt;/h2&gt;
&lt;p&gt;Below is a list of actors, along with the movies, that I have most watched.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Brad Pitt
                    12 years a slave
                              allied
                  burn after reading
                          fight club
                inglourious basterds
                 killing them softly
                            megamind
                           moneyball
    once upon a time... in hollywood
                               se7en
                              snatch
                       the big short
 the curious case of benjamin button
                                troy
                         war machine

Bruce Willis
                 alpha dog
                  die hard
                die hard 2
              die hard 4.0
 die hard with a vengeance
          fast food nation
                     glass
                    looper
          moonrise kingdom
              pulp fiction
                  sin city
           the sixth sense
               unbreakable

Samuel L. Jackson
                    die hard with a vengeance
                                        glass
                                       jumper
                 kingsman: the secret service
                                 pulp fiction
 star wars: episode iii - revenge of the sith
                            the hateful eight
                       the hitman's bodyguard
                              the incredibles
                               the negotiator
                                  unbreakable
                                unicorn store

Matt Damon
          adjustment bureau
                  contagion
          good will hunting
               jason bourne
                      ponyo
        saving private ryan
        the bourne identity
       the bourne ultimatum
               the departed
 the legend of bagger vance
                the martian
    the talented mr. ripley

Tom Hanks
     angels &amp;amp; demons
 catch me if you can
        forrest gump
 saving private ryan
          the circle
           toy story
         toy story 2
 toy story of terror
     you've got mail

Robert De Niro
     analyze this
        cape fear
    dirty grandpa
       goodfellas
    hide and seek
            joker
 meet the parents
   righteous kill
      taxi driver

Rachel McAdams
                         about time
                              aloha
                     doctor strange
                         mean girls
                            red eye
                    sherlock holmes
 sherlock holmes: a game of shadows
                      state of play
                   wedding crashers

Natalie Portman
                                 annihilation
                                   black swan
                                       closer
    star wars: episode i - the phantom menace
 star wars: episode ii - attack of the clones
 star wars: episode iii - revenge of the sith
                        the other boleyn girl
                                         thor
                               v for vendetta

Leonardo DiCaprio
                    blood diamond
              catch me if you can
                        inception
 once upon a time... in hollywood
                     the departed
         the man in the iron mask
                     the revenant
          the wolf of wall street

Ben Affleck
                               argo
 batman v superman: dawn of justice
                          daredevil
                          gone girl
                  good will hunting
                           paycheck
                      state of play
                     the accountant

Jake Gyllenhaal
      donnie darko
           jarhead
      nightcrawler
 nocturnal animals
         prisoners
             proof
       source code
    velvet buzzsaw

Ian McKellen
                                          stardust
                 the hobbit: an unexpected journey
         the hobbit: the battle of the five armies
 the lord of the rings: the fellowship of the ring
     the lord of the rings: the return of the king
             the lord of the rings: the two towers
                                             x-men
                                  x2: x-men united

Christian Bale
          3:10 to yuma
       american psycho
        public enemies
  terminator salvation
         the big short
       the dark knight
 the dark knight rises
         the machinist

Morgan Freeman
      along came a spider
              deep impact
                     lucy
      million dollar baby
                    se7en
          the bucket list
 the shawshank redemption
                   wanted

Tom Cruise
          collateral
    edge of tomorrow
     minority report
 mission: impossible
            rain man
    the last samurai
            valkyrie
         vanilla sky

Johnny Depp
                   a nightmare on elm street
 fantastic beasts: the crimes of grindelwald
              fear and loathing in las vegas
     pirate of the caribbean: at world's end
  pirates of the caribbean: dead man's chest
                              public enemies
                                 the tourist

Ewan McGregor
                              angels &amp;amp; demons
                              black hawk down
    star wars: episode i - the phantom menace
 star wars: episode ii - attack of the clones
 star wars: episode iii - revenge of the sith
                             t2 trainspotting
                                trainspotting

Laurence Fishburne
 john wick: chapter 3 - parabellum
                        passengers
                         predators
                        the matrix
               the matrix reloaded
            the matrix revolutions
                        the signal

Robert Downey Jr.
             avengers: infinity war
                         iron man 2
                         iron man 3
                    sherlock holmes
 sherlock holmes: a game of shadows
             spider-man: homecoming
                       the avengers

Jude Law
       a.i. artificial intelligence
                             closer
                          contagion
                            gattaca
                    sherlock holmes
 sherlock holmes: a game of shadows
            the talented mr. ripley

Kevin Spacey
       a bug's life
    american beauty
        margin call
               moon
              se7en
     the negotiator
 the usual suspects

Orlando Bloom
                                       good doctor
           pirate of the caribbean: at world's end
        pirates of the caribbean: dead man's chest
 the lord of the rings: the fellowship of the ring
     the lord of the rings: the return of the king
             the lord of the rings: the two towers
                                              troy

Scarlett Johansson
                   her
           jojo rabbit
   lost in translation
                  lucy
        marriage story
          the avengers
 the other boleyn girl

Angelina Jolie
         alexander
 girl, interrupted
     kung fu panda
   kung fu panda 2
       the tourist
            wanted

Paul Giamatti
         duplicity
 lady in the water
      private life
          sideways
   the illusionist
           win win

Joaquin Phoenix
                  gladiator
                        her
               hotel rwanda
                      joker
                     quills
 you were never really here

Jim Carrey
            ace ventura: pet detective
                       dumb and dumber
 eternal sunshine of the spotless mind
                              the mask
                       the truman show
                               yes man

Anthony Hopkins
                alexander
                     noah
                    proof
               red dragon
 the silence of the lambs
                     thor

Tom Hardy
               dunkirk
            layer cake
                 locke
    mad max: fury road
 the dark knight rises
          the revenant

Keanu Reeves
                         john wick
              john wick: chapter 2
 john wick: chapter 3 - parabellum
                        the matrix
               the matrix reloaded
            the matrix revolutions

Emma Watson
                         beauty and the beast
 harry potter and the deathly hallows: part 1
          harry potter and the goblet of fire
       harry potter and the half-blood prince
                                         noah
                                   the circle

Clive Owen
     children of men
              closer
           duplicity
          inside man
            sin city
 the bourne identity

Ethan Hawke
               boyhood
               gattaca
           lord of war
        predestination
 the magnificent seven
             the purge

John Malkovich
     being john malkovich
       burn after reading
           johnny english
            ripley's game
 the man in the iron mask
              warm bodies

Elijah Wood
                                       deep impact
                                        happy feet
                                            maniac
 the lord of the rings: the fellowship of the ring
     the lord of the rings: the return of the king
             the lord of the rings: the two towers

Cameron Diaz
  being john malkovich
   shrek forever after
       shrek the third
              the mask
           vanilla sky
 what happens in vegas
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Nice list of some of the more famous actors in the industry. One thing that surprised is how many movies I have watched that starred Brad Pitt - I did not realise it was that many! Once again, it is worth noting that females are under-represented here.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This project has probably been the one that I spent the most time on so far. I have learnt a whole bunch and managed to produce some nice visuals and summaries. Hopefully it was interesting to read!&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Analysing the movies I’ve watched, Part IV, Data visualisation Analysing the movies I’ve watched, Part III, Joining the tables Analysing the movies I’ve watched, Part II, Data cleaning Analysing the movies I’ve watched, Part I, Data collection</summary></entry><entry><title type="html">FastAI Course, Part II, Lesson 1 and sentiment analysis</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/30/fastai2.html" rel="alternate" type="text/html" title="FastAI Course, Part II, Lesson 1 and sentiment analysis" /><published>2020-08-30T00:00:00-05:00</published><updated>2020-08-30T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/30/fastai2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/30/fastai2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/08/fastai3.html&quot;&gt;FastAI Course, Part III, Frustrations with creating an image classifier&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/08/09/fastai1.html&quot;&gt;FastAI Course, Part I, Lessons 1 and 2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Recently, FastAI launched a new version of their course, using their revamped FastAI version 2 packages. As I had only completed the first two lessons of the previous version of the course, I thought I’d restart.  It is good I did re-start, because they have made big changes to how the course is organised and also to the syntax (e.g. in the old version, there was significant discussion about setting the learning rate using their ‘learning rate finder’, but so far, there has been no mention of this and it looks like that has been automated).  Towards the end of the first lesson, Jeremy showcases the different domains in which one can use Deep Learning. One of those was NLP. I have not yet done any NLP, so I thought this is a good chance to play around a little, without having to delve into any of the technical details.&lt;/p&gt;

&lt;p&gt;In this particular example, the NLP consists of sentiment analysis of movie reviews. Looking at the code, they use AWD LSTM architecture. A quick google search reveals that this is a fairly new algorithm, combining various ideas and tools into one. I am not yet at the stage to understand this though, but hopefully it will be discussed later in the course.&lt;/p&gt;

&lt;h2 id=&quot;experimentation&quot;&gt;Experimentation&lt;/h2&gt;
&lt;p&gt;The input to the model is a string containing a movie review. The output is a probability/score between 0 and 1 indicating how much the model thinks the review is positive. My initial thought was to to see if the model had learnt about numbers, by seeing how it rates reviews of the form ‘x out of y’.&lt;/p&gt;

&lt;h3 id=&quot;x-out-of-5&quot;&gt;‘x out of 5’&lt;/h3&gt;
&lt;p&gt;The results of this experimentation:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 out of 5: 0.5570
1 out of 5: 0.4760
2 out of 5: 0.3281
3 out of 5: 0.4038
4 out of 5: 0.4073
5 out of 5: 0.8569
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was surprising to me:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The model thinks that the review ‘0 out of 5’ is likely a positive review&lt;/li&gt;
  &lt;li&gt;The model is roughly undecided about ‘1 out of 5’&lt;/li&gt;
  &lt;li&gt;The model thinks 2,3 or 4 out of 5 is negative&lt;/li&gt;
  &lt;li&gt;The model thinksthat ‘5 out of 5’ is positive.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As with most of these ML models, this must be a reflection of the underlying dataset. I imagine very few people actually give a movie 0 or 1 out of 5, so the model doesn’t really know what to do with it, whereas ‘2 out of 5’ probably is more common and basically says the movie is bad, and ‘3 out of 5’ and ‘4 out of 5’ are more average-y ratings.&lt;/p&gt;

&lt;h3 id=&quot;x-out-of-10&quot;&gt;‘x out of 10’&lt;/h3&gt;
&lt;p&gt;The results of this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 out of 10: 0.5402
1 out of 10: 0.4478
2 out of 10: 0.2972
3 out of 10: 0.3741
4 out of 10: 0.3798
5 out of 10: 0.8475
6 out of 10: 0.9897
7 out of 10: 0.99996
8 out of 10: 0.99991
9 out of 10: 0.9998
10 out of 10:0.99996
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Again the model is confused with the worst reviews, presumably because they just don’t occur in the training data. Then the model seems to deal with 2,3 and 4 out of 10 sensibly. But then it has big jump and thinks the rest are definitely positive, with anything above 7 out of 10 being considered positive with high confidence. Again, the explanation for these unusual evaluations of the reviews must be that they are uncommon in the dataset.&lt;/p&gt;

&lt;h3 id=&quot;variations-on-x-out-of-5&quot;&gt;Variations on ‘x out of 5’&lt;/h3&gt;
&lt;p&gt;I tried a few little variations on ‘x out of 5’ to see if it would make any impact: adding an exclamation mark at the end, adding the word ‘stars’ at the end, and adding the word ‘Only’ at the start.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;x&lt;/th&gt;
      &lt;th&gt;‘x out of 5’&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;‘x out of 5!’&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;‘x out of 5 stars’&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;‘Only x out of 5’&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;0.5570&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.7436&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.7247&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.0240&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;0.4760&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.6756&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.6538&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.0247&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td&gt;0.3281&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.4901&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.4884&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.0196&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td&gt;0.4038&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5670&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5634&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.0189&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td&gt;0.4073&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5634&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5589&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.0179&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td&gt;0.8569&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.9051&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.8969&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5464&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Adding an exclamation mark makes the model think the reviews are more positive, which in my opinion is sensible.&lt;/li&gt;
  &lt;li&gt;Adding the word ‘stars’ seems to have very similar effect to adding an exclamation mark. I do not know if this is just a coincidence - I do not have intuition for this. I guess it must mean that if the word ‘star’ appeared in the training data, then it mostly meant it was a positive review.&lt;/li&gt;
  &lt;li&gt;Adding the word ‘only’ dramatically reduced the positivity score, which makes sense.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;miscellaneous-statements&quot;&gt;Miscellaneous statements&lt;/h3&gt;
&lt;p&gt;Lastly, I tried a variety of miscellaneous statements:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;I liked some bits and I disliked other bits
0.9345

I disliked some bits and I liked other bits
0.8857

I liked most of it, but not all of it
0.9906

I disliked most of it, but not all of it
0.9782

I hated most of it, but not all of it
0.9486

I disliked the movie
0.7621

I hated the movie
0.6873

I cannot believe how bad the movie is
0.5535
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The model is comically bad at judging whether the statement is positive. I started by trying a neutral statement, but the model thought it was great.  I then tried the favourable statement ‘I liked most of it…’ and the model thought it was positive (sensible), but still thought the statement was positive when I switched liked and disliked. Using the word ‘hated’ instead reduced it a bit.&lt;/p&gt;

&lt;p&gt;Maybe the model hasn’t even learnt the word ‘disliked’ and ‘hated’. So I just tried the simple statements ‘I dislike/hated the movie’, and the model does reduce its score, but still thinks these are overall positive. I end with a particularly strong negative review, which the model perceives as slightly positive.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;It is nice to play around with a model without any expectation to understand the inner-intricacies or working. My main takeaways are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The model has learnt some sensible patterns, e.g. adding ‘only’ indicates a negative review, adding an exclamation mark indicates a positive review, etc.&lt;/li&gt;
  &lt;li&gt;The model fails spectacularly badly on several examples, which do not feel contrived to me. This makes me question the reliability of sentiment analysis. Maybe the examples I created are not representative of real-world examples.&lt;/li&gt;
  &lt;li&gt;If I were a decision-maker in some business, I would definitely be using manual analysis until I see better evidence.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Other posts in series FastAI Course, Part III, Frustrations with creating an image classifier FastAI Course, Part I, Lessons 1 and 2</summary></entry><entry><title type="html">Increasing the resolution of an image using an SRGAN</title><link href="https://lovkush-a.github.io/blog/python/neural%20network/2020/08/28/srgan1.html" rel="alternate" type="text/html" title="Increasing the resolution of an image using an SRGAN" /><published>2020-08-28T00:00:00-05:00</published><updated>2020-08-28T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/neural%20network/2020/08/28/srgan1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/neural%20network/2020/08/28/srgan1.html">&lt;!---
## Other posts in series














































* [Investigating Credit Card Fraud, Part VI, Summary and Lessons from Kaggle](/blog/python/data%20science/2020/06/25/creditcard6.html)















* [Investigating Credit Card Fraud, Part V, Final Models](/blog/python/data%20science/2020/05/30/creditcard5.html)



* [Investigating Credit Card Fraud, Part IV, `n_estimators`](/blog/python/data%20science/2020/05/29/creditcard4.html)







* [Investigating Credit Card Fraud, Part III, Handmade Model](/blog/python/data%20science/2020/05/19/creditcard3.html)



* [Investigating Credit Card Fraud, Part II, Removing data](/blog/python/data%20science/2020/05/16/creditcard2.html)





* [Investigating Credit Card Fraud, Part I, First Models](/blog/python/data%20science/2020/05/14/creditcard1.html)










--&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I wanted to print out an image for a friend, and I wanted to first crop the image to only include a relatively small part of the photo (namely, the individuals in the photo. The original photo was 90% scenary).  However, after the cropping, the image became too small and would have been pixelated when printed.  I thought that a neural network ought to be able to solve this problem, because it could be trained on a manually created dataset (just take a bunch of images and use these as the &lt;em&gt;outputs&lt;/em&gt;, then reduce the quality of these images to create the &lt;em&gt;inputs&lt;/em&gt;). I decided to Google around to see what already had been done, and I found out about SRGANs.  At my current level of knowledge, I cannot understand the details of the architecture, so for now, my aim was just to see if I could use a pre-trained network to achieve my goal. After a bit more searching, I found &lt;a href=&quot;https://github.com/HasnainRaz/Fast-SRGAN&quot;&gt;this Github repo&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;steps-taken&quot;&gt;Steps taken&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Create a new directory and environment.&lt;/li&gt;
  &lt;li&gt;Download the github repo.&lt;/li&gt;
  &lt;li&gt;Install the requirements.&lt;/li&gt;
  &lt;li&gt;Create a directory &lt;code class=&quot;highlighter-rouge&quot;&gt;inputs&lt;/code&gt; for input images, and folder &lt;code class=&quot;highlighter-rouge&quot;&gt;outputs&lt;/code&gt; for where the output images will go.&lt;/li&gt;
  &lt;li&gt;Add images to the inputs directory.&lt;/li&gt;
  &lt;li&gt;Run the command `python infer.py –image_dir ‘inputs’ –output_dir ‘outputs’&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;Below are samples of the images, comparing before and after applying the neural network.&lt;/p&gt;

&lt;h3 id=&quot;example-1&quot;&gt;Example 1&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/images/srgan1_1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;example-2&quot;&gt;Example 2&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/images/srgan1_2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;example-3&quot;&gt;Example 3&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/images/srgan1_3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is amazing! This feels like magic to me.&lt;/p&gt;

&lt;h2 id=&quot;limits&quot;&gt;Limits&lt;/h2&gt;
&lt;p&gt;I tried applying this to blurry images, expecting it to make the images less blurry. This did not happen:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/srgan1_4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This reveals how limited my understanding is! After thinking and googling a bit, I think the issue is that resolution and blurriness/sharpness are two separate issues. Previously, I just lumped them together as ‘reasons an image can look bad’. After a bit more searching, it seems I might learn about anti-blurring / sharpening in the FastAI course that I am doing, so that is something to look forward to.&lt;/p&gt;

&lt;p&gt;Finally, I hope I will soon be at at stage where I can understand these intricate architectures, and be able to train my own cutting edge neural networks.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Analysing the movies I’ve watched, Part IV, Data visualisation</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/08/24/mymovies4.html" rel="alternate" type="text/html" title="Analysing the movies I've watched, Part IV, Data visualisation" /><published>2020-08-24T00:00:00-05:00</published><updated>2020-08-24T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/08/24/mymovies4</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/08/24/mymovies4.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/09/02/mymovies5.html&quot;&gt;Analysing the movies I’ve watched, Part V, Data visualisation II&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/19/mymovies3.html&quot;&gt;Analysing the movies I’ve watched, Part III, Joining the tables&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/03/mymovies2.html&quot;&gt;Analysing the movies I’ve watched, Part II, Data cleaning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/02/mymovies1.html&quot;&gt;Analysing the movies I’ve watched, Part I, Data collection&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;movies-per-year&quot;&gt;Movies per year&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_year.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The most striking thing is how many movies I watched in 2008 and 2009! More than an average of 2 per week. The uptick in 2016 and 2017 can be explained by my mum buying me an Odeon Unlimited card in September 2016. The slight rise in 2018 and 2019 compared to mid 2010s I think is explained by moving into a house where watching movies was a common social activity for the housemates. And 2020 is significantly above average (given it is not complete), and this is explained by the covid-19 pandemic.&lt;/p&gt;

&lt;h2 id=&quot;movies-by-source&quot;&gt;Movies by source&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_source.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The majority of my movie-watching experience is done on Netflix. To help see any other patterns, I tried grouping them together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_source2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Not sure if there is anything noteworthy to say about this. Note that the category ‘internet’ may or may not refer to streaming from dodgy websites.&lt;/p&gt;

&lt;h2 id=&quot;movies-by-source-and-year&quot;&gt;Movies by source and year&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_sourceyear.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Stackplots are awesome! Visually striking, and provides an overall sense of how my movie watching habits changed. Some patterns which are clear from this diagram:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There is a clear decline in the use of ‘the internet’ to watch movies in 2017.&lt;/li&gt;
  &lt;li&gt;There is a clear rise in the use of Netflix, starting from around 2014.&lt;/li&gt;
  &lt;li&gt;There is a big bulge in cinema viewings in 2016 and 2017, corresponding to when I had an Odeon Unlimited card.&lt;/li&gt;
  &lt;li&gt;There is a big pink bulge, for a surge in ‘other online’ activity. A quick search in the dataframe shows this corresponds to me making a full use of free trials of NowTV.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;movies-by-month&quot;&gt;Movies by month&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_month.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Again, there are some patterns visible in this plot:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There are generally peaks in December, the holiday period! Looks like I enjoy watching movies when I am back home during the Christmas break.&lt;/li&gt;
  &lt;li&gt;There are smaller peaks in several summer times, also likely due to me watching movies while at home.&lt;/li&gt;
  &lt;li&gt;You can see some peaks at the end of 2016 and start of 2017, corresponding to the odeon unlimited card.&lt;/li&gt;
  &lt;li&gt;You can see the increase in movie watching from March 2020, corresponding to covid-19.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I recently contributed to an open source project Darts, which does Time Series predictions. I was curious to see what patterns it would find. The following is obtained via an exponential smoothing:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/mymovies4_month2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The clearest pattern in the model’s prediction is that it predicts peaks in December. Given how small and error-filled the dataset is, I do not think there is much to read in the smaller peaks at other times of the year.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Even with a dataset as noisy as this one, it is still possible to obtain some nice visuals and uncover some overall patterns. My favourite chart is the stackplot showing how the source used to watch movies has changed over the years.&lt;/p&gt;

&lt;p&gt;Another nice thing about this project has been that it included various firsts for me: first stackplot, first time series model (admittedly basic), first pivotting in pandas (to create stack chart), first time grappling with Time formats to create precisely the plot I want (for the plot by month).&lt;/p&gt;

&lt;p&gt;Next time, I will see what patterns there in the subset of data for which I could join it with imdb data.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Analysing the movies I’ve watched, Part V, Data visualisation II Analysing the movies I’ve watched, Part III, Joining the tables Analysing the movies I’ve watched, Part II, Data cleaning Analysing the movies I’ve watched, Part I, Data collection</summary></entry><entry><title type="html">Analysing the movies I’ve watched, Part III, Joining the tables</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/08/19/mymovies3.html" rel="alternate" type="text/html" title="Analysing the movies I've watched, Part III, Joining the tables" /><published>2020-08-19T00:00:00-05:00</published><updated>2020-08-19T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/08/19/mymovies3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/08/19/mymovies3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/09/02/mymovies5.html&quot;&gt;Analysing the movies I’ve watched, Part V, Data visualisation II&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/24/mymovies4.html&quot;&gt;Analysing the movies I’ve watched, Part IV, Data visualisation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/03/mymovies2.html&quot;&gt;Analysing the movies I’ve watched, Part II, Data cleaning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/08/02/mymovies1.html&quot;&gt;Analysing the movies I’ve watched, Part I, Data collection&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the last post, I described the cleaning that I did, In particular, I had to manually correct over 140 titles in my data that did not occur in the imdb dataset. So I should be ready to join, right? No, of course not, why would things be so simple.&lt;/p&gt;

&lt;h2 id=&quot;the-main-problem&quot;&gt;The main problem&lt;/h2&gt;
&lt;p&gt;Many movie titles occur multiple times in the imdb database, and as far as I know, there is not an automated way to deal with this. To measure the extend of the problem, I added a column to count how many matches there are in the imdb database:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;num_rows_in_imdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    returns the number of rows in the imdb dataset that have primaryTitle equal to movie_title.
    if print_rows is True, then also print the rows
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;primaryTitle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_rows&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;rows_in_imdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nan&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rows_in_imdb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_rows_in_imdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing this revealed that most of the entries had multiple occuences in the imdb database! This was not good. I looked into a couple of examples by searching on the imdb website. It looked like many of the repetitions were from matches with TV episodes.  So I repeated the above process but with only the movies from the imdb dataset:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'title.basics.tsv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;na_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;N'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;usecols&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tconst'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'primaryTitle'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'startYear'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'titleType'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titleType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'short'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'movie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tvMovie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By removing all the TV episodes, the number of matches decreased, but we still have a large problem. Only 351 of my entries have precisely one match. That is a low number indeed.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I have decided to leave the dataset in the mess that it is and move onto the analysis stage. I will look for patterns within my dataframe first, and then look at those 351 entries which should be able to join with the imdb dataset for any patterns there.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Analysing the movies I’ve watched, Part V, Data visualisation II Analysing the movies I’ve watched, Part IV, Data visualisation Analysing the movies I’ve watched, Part II, Data cleaning Analysing the movies I’ve watched, Part I, Data collection</summary></entry><entry><title type="html">DynamoDB Part I, the CAP Theorem’s never ending rabbit hole</title><link href="https://lovkush-a.github.io/blog/data%20science/data%20engineering/2020/08/14/dynamodb1.html" rel="alternate" type="text/html" title="DynamoDB Part I, the CAP Theorem's never ending rabbit hole" /><published>2020-08-14T00:00:00-05:00</published><updated>2020-08-14T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/data%20engineering/2020/08/14/dynamodb1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/data%20engineering/2020/08/14/dynamodb1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I recently started this &lt;a href=&quot;https://courses.edx.org/courses/course-v1:AWS+OTP-AWS-D6+2T2019/course/&quot;&gt;EdEx course&lt;/a&gt; on Amazon’s DynamoDB service. Within one of the first few videos, the CAP Theorem was
discussed. As someone with a pure maths background, theorems are irresistable bait, so I wanted to find out more about it.&lt;/p&gt;

&lt;h2 id=&quot;my-journey&quot;&gt;My journey&lt;/h2&gt;
&lt;p&gt;I cannot remember all the details, but here are some of the things I have found and thought in my trip down the rabbit hole.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The wikipedia page was the starting point, of course. I couldn’t say it really helped me, as most of the terms described were not helpful.&lt;/li&gt;
  &lt;li&gt;However, when looking at the references, something stood out. One of my friend’s brothers, Martin Kleppmann, has written a bunch of stuff on this!&lt;/li&gt;
  &lt;li&gt;This &lt;a href=&quot;https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html&quot;&gt;blogpost&lt;/a&gt; on why the CAP framework is practically unhelpful, was helpful. It gave an intuitive proof of the theorem.  However, the proof is so simple that I wonder what the big deal is. There is clearly something I am missing.&lt;/li&gt;
  &lt;li&gt;The blogpost contained various links. At this stage, I lose track of things and which links came from where.&lt;/li&gt;
  &lt;li&gt;A couple of other helpful blogposts were &lt;a href=&quot;https://www.the-paper-trail.org/page/cap-faq/&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;http://www.julianbrowne.com/article/brewers-cap-theorem&quot;&gt;this&lt;/a&gt;. I gained a better sense of why this is an important issue, and what underlying problems are that people are thinking about.&lt;/li&gt;
  &lt;li&gt;One thing that is frustrating is how many terms people take for granted. E.g. the concepts of &lt;em&gt;nodes&lt;/em&gt; and &lt;em&gt;network&lt;/em&gt; are taken as self-evident, yet they are fundamental to the statement of the theorem. They cannot just be the same thing as nodes and networks from Graph Theory, because stuff is actually happening within the nodes, but none of the blog posts I found actually explain these concepts.&lt;/li&gt;
  &lt;li&gt;There is whole bunch of things I found in this journey that look interesting and I intend to read at some point:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf&quot;&gt;This&lt;/a&gt; paper on how certain multiprocessors do not provide sequentially consistent memory, and their proposed solution.&lt;/li&gt;
      &lt;li&gt;These &lt;a href=&quot;http://www.cs.cmu.edu/~harchol/ISCA15show.pdf&quot;&gt;lecture notes&lt;/a&gt; on queueing theory and its application to computer systems.&lt;/li&gt;
      &lt;li&gt;This &lt;a href=&quot;https://www.microsoft.com/en-us/research/wp-content/uploads/2011/10/ConsistencyAndBaseballReport.pdf&quot;&gt;article&lt;/a&gt; by Microsoft explaining data consistency in databases using baseball.&lt;/li&gt;
      &lt;li&gt;This &lt;a href=&quot;http://dataintensive.net/&quot;&gt;book&lt;/a&gt; on ‘The big ideas behind reliable, scalable, maintainable data-intensive systems’. Seems to be well-regarded by many people.&lt;/li&gt;
      &lt;li&gt;This &lt;a href=&quot;https://www.benkuhn.net/progessays/&quot;&gt;blogpost&lt;/a&gt; containing a list of highly recommended essays on programming.&lt;/li&gt;
      &lt;li&gt;This &lt;a href=&quot;https://smile.amazon.com/Explain-Cloud-Like-Im-10-ebook/dp/B0765C4SNR&quot;&gt;book&lt;/a&gt; ‘Explain the Cloud Like I’m 10’ looks like an easy to read book where I will learn a lot about what really goes on behind the scenes.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;There is too much to learn! One thing I still need to improve in myself is my ability to prioritise all these difference things.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series</summary></entry><entry><title type="html">FastAI Course, Part I, Lessons 1 and 2</title><link href="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/09/fastai1.html" rel="alternate" type="text/html" title="FastAI Course, Part I, Lessons 1 and 2" /><published>2020-08-09T00:00:00-05:00</published><updated>2020-08-09T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/09/fastai1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/data%20science/neural%20network/python/2020/08/09/fastai1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/09/08/fastai3.html&quot;&gt;FastAI Course, Part III, Frustrations with creating an image classifier&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/data%20science/neural%20network/python/2020/08/30/fastai2.html&quot;&gt;FastAI Course, Part II, Lesson 1 and sentiment analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;first-impressions&quot;&gt;First impressions&lt;/h2&gt;
&lt;p&gt;I recently started this &lt;a href=&quot;https://course.fast.ai/&quot;&gt;FastAI Deep Learning course&lt;/a&gt; and done a couple of little projects. Below I summarise some of what I did and my thoughts.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I am impressed by how the course is taught. It is clear a lot of thought has been put into how to teach the course, which examples to use, what messages/advice to give to students, what documentation to provide, etc.&lt;/li&gt;
  &lt;li&gt;I quite like how they have a system for the live audience to submit questions, which the lecturer Jeremy Howard then answers during the lecture.&lt;/li&gt;
  &lt;li&gt;I like how Jeremy showcases various examples of what students have done. It is surprising to see how many state-of-the-art things can be done with just the knowledge given in the first couple of lectures. The FastAI team should be chuffed with themselves for creating such a course, tool and community.&lt;/li&gt;
  &lt;li&gt;I tried a couple of image classification tasks. The first was to distinguish between the Dragonball Z characters Goku and Vegeta. The second was to distinguish between squash and tennis rackets. I got ok results. At this stage, the main way to improve the algorithm is to improve the image set (I just downloaded the first bunch of images from Google Image Search).&lt;/li&gt;
  &lt;li&gt;This was slowed down a bit, because the first online GPU provider I used was &lt;a href=&quot;https://www.paperspace.com/&quot;&gt;paperspace&lt;/a&gt;, but there was some bug which meant I could not re-open a notebook after using it once. I then tried Google Colab, which took a bit more time to learn, and got things working there. In the meantime, the bug in paperspace was fixed, so I will use that again.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Other posts in series FastAI Course, Part III, Frustrations with creating an image classifier FastAI Course, Part II, Lesson 1 and sentiment analysis</summary></entry><entry><title type="html">Web Scraping for STEP past papers and solutions, Part II, a bug</title><link href="https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2.html" rel="alternate" type="text/html" title="Web Scraping for STEP past papers and solutions, Part II, a bug" /><published>2020-08-06T00:00:00-05:00</published><updated>2020-08-06T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/python/2020/07/27/downloadstep.html&quot;&gt;Web Scraping for STEP past papers and solutions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-bug&quot;&gt;A bug&lt;/h2&gt;
&lt;p&gt;Earlier this week, I tried to open one of the files containing a solution to a past STEP paper. To my surprise, it did not open. I tried several other files, and none of them opened. A big lesson here is to actually check the files have properly downloaded! I just assumed that the files successfully downloaded because I saw the correct filenames appear in the directory. (This is somewhat ironic because one of my takeaways at the end of the previous post was to not make assumptions…)&lt;/p&gt;

&lt;p&gt;So I had to go back to my previous attempt and try to work out what went wrong. I compared my code to various other examples online, and I could not see the error. I then tried several other variations that I found while searching, and none of them worked.&lt;/p&gt;

&lt;p&gt;Next I tried to look at the object obtained after running &lt;code class=&quot;highlighter-rouge&quot;&gt;r = requests.get(url)&lt;/code&gt;. I first ran &lt;code class=&quot;highlighter-rouge&quot;&gt;print(r.content)&lt;/code&gt; to actually see what I was writing to the files. The output was html for a webpage - that made no sense, since the url directly goes to a jpg file. I was feeling a bit clueless here. I used &lt;code class=&quot;highlighter-rouge&quot;&gt;dir(r)&lt;/code&gt; to see if there were any functions that might help me, but none stood out. One of the methods was &lt;code class=&quot;highlighter-rouge&quot;&gt;url&lt;/code&gt; and in desperation I decided to do run &lt;code class=&quot;highlighter-rouge&quot;&gt;print(r.url)&lt;/code&gt;, expecting just to the url that was inputted into the &lt;code class=&quot;highlighter-rouge&quot;&gt;.get&lt;/code&gt; method. However, the output was:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;https://2017.integralmaths.org/login/index.php&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Bingo! The problem was now clear. The &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt; function is distinct from the selenium objects, so you have to separately log-in to the website for &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt;. After some Googling, I found out how you can enter log-in credentials using requests, and it worked! What a relief. The new bits of code are given at the end.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learnt&quot;&gt;Lessons learnt&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;As mentioned above, I really need to absorb the lesson that one should not make assumptions.&lt;/li&gt;
  &lt;li&gt;If you’re completely stuck, it might be worthwhile to go through all the methods of the object, to see what can be uncovered.&lt;/li&gt;
  &lt;li&gt;There is a limit to my understanding of the code and the modules. Stitching together code from random blogs and stackoverflow works, but I have no real understanding. I did try looking at the documentation for some of the modules I was using, but they are incomprehensibly dense. I am not sure what best practice is here.&lt;/li&gt;
  &lt;li&gt;Try to have as much of your work saved, so if there is a bug, you do not need to repeat everything. In this case, I should have saved a list of the urls during my first attempt, so that for any potential future attempts, all I would have to do is loop through these urls and download the images, rather than having to navigate via a browser to find all the urls again.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;Below is the new bits of code I had to add into the original code. It may be incomprehensible without the context, but I think the syntax is mostly self-explanatory.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;login_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://2017.integralmaths.org/login/index.php&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'username'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'mei-step'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'password'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Stepaea1'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allow_redirects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series Web Scraping for STEP past papers and solutions</summary></entry></feed>