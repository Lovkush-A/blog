<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://lovkush-a.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lovkush-a.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-08-06T15:14:20-05:00</updated><id>https://lovkush-a.github.io/blog/feed.xml</id><title type="html">Lovkush Agarwal</title><subtitle>A blog for my data science learning and projects</subtitle><entry><title type="html">Web Scraping for STEP past papers and solutions, Part II, a bug</title><link href="https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2.html" rel="alternate" type="text/html" title="Web Scraping for STEP past papers and solutions, Part II, a bug" /><published>2020-08-06T00:00:00-05:00</published><updated>2020-08-06T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/2020/08/06/downloadstep2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/python/2020/07/27/downloadstep.html&quot;&gt;Web Scraping for STEP past papers and solutions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-bug&quot;&gt;A bug&lt;/h2&gt;
&lt;p&gt;Earlier this week, I tried to open one of the files containing a solution to a past STEP paper. To my surprise, it did not open. I tried several other files, and none of them opened.&lt;/p&gt;

&lt;p&gt;The big lesson here is to make sure I try to open a file, instead of just assuming that the image was successfully downloaded. I just assumed that because files with the correct names appeared in the directory, it was all fine. (This is somewhat ironic, because one of my takeaways at the end of the previous post was to not making assumptions…)&lt;/p&gt;

&lt;p&gt;So I had to go back to my previous attempt and try to work out what went wrong. I compared my code to various other examples online, and I could not see the error. I then tried several other variations, that I found while searching, for downloading images and none of them worked.&lt;/p&gt;

&lt;p&gt;Next I tried to look at the object obtained after running &lt;code class=&quot;highlighter-rouge&quot;&gt;r = requests.get(url)&lt;/code&gt;. I first ran &lt;code class=&quot;highlighter-rouge&quot;&gt;print(r.content)&lt;/code&gt; to actually see what I was writing to the files. The output was html for a webpage - that made no sense, since the url directly goes to a jpg file. I was feeling a bit clueless here. I used &lt;code class=&quot;highlighter-rouge&quot;&gt;dir(r)&lt;/code&gt; to see if there were any functions that might help me, but none stood out. One of the methods was &lt;code class=&quot;highlighter-rouge&quot;&gt;url&lt;/code&gt; and in desperation I decided to do run &lt;code class=&quot;highlighter-rouge&quot;&gt;print(r.url)&lt;/code&gt;, expecting just to the url it had inputted. However, the output was:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;https://2017.integralmaths.org/login/index.php&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Bingo! The problem became clear to me. The &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt; function is distinct from the selenium functions I was using, so has not actually logged into the website. After some Googling, I found out how you can enter log-in credentials using requests, and it worked! What a relief. The new bits of code are given at the end.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learnt&quot;&gt;Lessons learnt&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;As mentioned above, I really need to absorb the lesson that one should not make assumptions.&lt;/li&gt;
  &lt;li&gt;If you’re completely stuck, it might be worthwhile to go through all the methods of the object, to see what can be uncovered.&lt;/li&gt;
  &lt;li&gt;There is a limit to my understanding of the code and the modules. Stitching together code from random blogs and stackoverflow works, but I have no deep understanding. I did try looking at the documentation for some of the modules I was using, but they are incomprehensibly dense. I am not sure what best practice is here.&lt;/li&gt;
  &lt;li&gt;Try to have as much of your work saved, so if there is a bug, you do not need to repeat everything. In this case, I should have saved a list of the urls during my first attempt, so that for any potential future attempts, all I would have to do is loop through these urls and download the images, rather than having to navigate via a browser to find all the urls again.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;Below is the new bits of code I had to add into the original code. It may be incomprehensible out of context, but I think it should be clear what is going on.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;login_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://2017.integralmaths.org/login/index.php&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'username'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'mei-step'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'password'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Stepaea1'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allow_redirects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series Web Scraping for STEP past papers and solutions</summary></entry><entry><title type="html">Analysing the movies I’ve watched, Part I, Data collection</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/08/02/mymovies1.html" rel="alternate" type="text/html" title="Analysing the movies I've watched, Part I, Data collection" /><published>2020-08-02T00:00:00-05:00</published><updated>2020-08-02T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/08/02/mymovies1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/08/02/mymovies1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Since 2008, I have been maintaining a record of all the movies I have watched. It started because I borrowed a CD stack (see &lt;a href=&quot;https://www.stockfreeimages.com/2328098/Stack-of-blank-CD-DVDs.html&quot;&gt;here&lt;/a&gt; if you are too young to not know what a CD stack is) of movies from a friend, and the easiest way of keeping track of which movies I had watched was to create a list.  Once I finished the movies on the CD stack, I thought I may as well continue adding to the list, and it has been going ever since.  Now I figured this could be a fun data set to analyse.&lt;/p&gt;

&lt;h2 id=&quot;the-dataset&quot;&gt;The dataset&lt;/h2&gt;
&lt;p&gt;The list started out as a notepad &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; file, then I moved it into a Google spreadsheet, and it now resides in &lt;a href=&quot;www.dynalist.com&quot;&gt;Dynalist&lt;/a&gt;.
The format of the entries in the list has changed over time.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The earliest entries in the list have the format &lt;code class=&quot;highlighter-rouge&quot;&gt;movie_title, i&lt;/code&gt;, where &lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt; is an index to keep track of how many films are in the list.&lt;/li&gt;
  &lt;li&gt;In Easter 2009, I started including the date, so the standard format is &lt;code class=&quot;highlighter-rouge&quot;&gt;movie_title, date, i&lt;/code&gt;. The date is the day of the month and the month.&lt;/li&gt;
  &lt;li&gt;In September 2009, I started including the source / location of the movie, e.g. a cinema, or a DVD, or a friend, etc. The standard format is &lt;code class=&quot;highlighter-rouge&quot;&gt;movie_title, date, source, i&lt;/code&gt;. This has been the format ever since.&lt;/li&gt;
  &lt;li&gt;I keep track of movies I would recommend. This is recorded by including &lt;code class=&quot;highlighter-rouge&quot;&gt;#recc&lt;/code&gt; between &lt;code class=&quot;highlighter-rouge&quot;&gt;movie_title&lt;/code&gt; and whatever the second item of the entry is.&lt;/li&gt;
  &lt;li&gt;I keep track of year by having an entry like this: &lt;code class=&quot;highlighter-rouge&quot;&gt;---2020 above, 2019 below---&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first task was to get this dataset into a pandas dataframe. It should not be too difficult - I have a few formats that can be easily identified, and I can create a new row as appropriate.&lt;/p&gt;

&lt;h2 id=&quot;collecting-the-data&quot;&gt;Collecting the data&lt;/h2&gt;
&lt;p&gt;What I was not conscious of was how many entries did not fit into the formats described above, roughly 150 or so. To my frustration, there is no simple pattern to them either so I had to manually sort these out. To illustrate, here are just a small sample of the exceptions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Having &lt;code class=&quot;highlighter-rouge&quot;&gt;??&lt;/code&gt; for the date, or just leaving out the date altogether&lt;/li&gt;
  &lt;li&gt;Including extra details, e.g. whether I had watched the whole movie or not, or a description of the movie to help me remember what the movie is, or, inclusion of which city I was in. These extra details were not in consistent locations within the entry.&lt;/li&gt;
  &lt;li&gt;Sometimes the movie title contained a comma in them, which messed things up because I was using splitting each entry by a comma.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The result is that the process took much longer than I anticipated. I can better understand now how data processing can be the biggest part of a data scientist’s role! One thing I am curious about is whether there are better alternatives to doing manual work. If there were millions of entries, what could I do?&lt;/p&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;p&gt;Here is the code. Many details will not make sense without knowing exactly how the data is stored in dynalist. Hopefully the flow of the process is clear.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# read text file from dynalist
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Regular.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# extract relevant rows from lines, by finding the start and end indices
# store these rows into variable movies, separated by commas
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;movies'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t\t\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s*,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# add the year to end of each entry in movies
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2020&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'---'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'---'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# delete year separator entries, those with ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'---'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# define date regex pattern
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;r&quot;\d{1,2} \w+&quot;&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# define function to determine the format of the row
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;recc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'#recc'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isdigit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     
    &lt;span class=&quot;c1&quot;&gt;# first format is movie_title, date, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
 
    &lt;span class=&quot;c1&quot;&gt;# second format is movie_title, date, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        
    &lt;span class=&quot;c1&quot;&gt;# third format is movie_title, recc, date, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
        
    &lt;span class=&quot;c1&quot;&gt;# fourth format is movie_title, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# fifth format is movie_title, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# sixth format is movie_title, recc, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# define function to obtain manual inputs from me, for those entries that do not match
# the standard format
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isdigit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# create list of column names
# create variable df_rows that will contain data that will be turned into frame
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'my_index'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'movie_title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'year'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'date'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'source'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'recommended'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'other'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# loop through entries in movies, and create appropriate row data
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# first format is movie_title, date, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        
    &lt;span class=&quot;c1&quot;&gt;# second format is movie_title, date, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    
    &lt;span class=&quot;c1&quot;&gt;# third format is movie_title, recc, date, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        
    &lt;span class=&quot;c1&quot;&gt;# fourth format is movie_title, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    
    &lt;span class=&quot;c1&quot;&gt;# fifth format is movie_title, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    
    &lt;span class=&quot;c1&quot;&gt;# sixth format is movie_title, recc, source, my_index, year
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row_format&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{i}: {item}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'movie_title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'date'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'source'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'my_index'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'recommended'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'other'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;df_rows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# create dataframe from data, and save as csv file
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mymovies1.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series</summary></entry><entry><title type="html">Web Scraping for STEP past papers and solutions</title><link href="https://lovkush-a.github.io/blog/python/2020/07/27/downloadstep.html" rel="alternate" type="text/html" title="Web Scraping for STEP past papers and solutions" /><published>2020-07-27T00:00:00-05:00</published><updated>2020-07-27T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/2020/07/27/downloadstep</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/2020/07/27/downloadstep.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Though I am transitioning from teaching to data science, I still continue to teach via private tuition. I am currently helping somebody prepare for the &lt;a href=&quot;https://www.admissionstesting.org/for-test-takers/step/about-step/&quot;&gt;STEP&lt;/a&gt;, so I wanted to obtain as many past papers and solutions as I could. To do this manually would have required hours of clicking on links and ‘Saving as…’, so I decided to automate it with python.&lt;/p&gt;

&lt;h2 id=&quot;downloading-the-step-papers&quot;&gt;Downloading the step papers&lt;/h2&gt;
&lt;p&gt;This was straightforward. The website &lt;a href=&quot;https://stepdatabase.maths.org&quot;&gt;stepdatabase.com&lt;/a&gt; has past papers on them, and the urls and naming system they use is systematic and 100% consistent. I was able to download the papers using a simple loop with a &lt;code class=&quot;highlighter-rouge&quot;&gt;wget&lt;/code&gt; command.  See the code below.&lt;/p&gt;

&lt;h2 id=&quot;downloading-the-answers&quot;&gt;Downloading the answers&lt;/h2&gt;
&lt;p&gt;This was less straightforward. &lt;a href=&quot;https://mei.org.uk/step-aea-solutions&quot;&gt;This website&lt;/a&gt; provides answers to the STEP papers but the urls did not have a consistent format, so I could not just use wget again. Therefore, I used some web-scraping tools to help me.&lt;/p&gt;

&lt;p&gt;There was a considerable learning curve, as I had not done any web scraping before. There were actually a couple of moments where I was going to give up. However, I persisted in the knowledge that if I want to be successful in a tech role, I will encounter such difficulties, and the only way to improve is to perservere.&lt;/p&gt;

&lt;p&gt;In the end, I succeeded and the final code is given below. I will not go through the full process of trying things out, failing, tweaking, de-bugging, etc., but I will provide some of the key learning points for me.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BeautifulSoup is only suitable for statically generated pages. For dynamic ones, you can use Selenium.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;dir&lt;/code&gt; function in python is extremely handy. I have to thank this &lt;a href=&quot;https://www.kaggle.com/colinmorris/working-with-external-libraries&quot;&gt;Kaggle tutorial&lt;/a&gt; for introducing me to this function. On two or three occasions, I wanted to do something, and by looking at the list of methods, I was able to find one which worked. The example I remember is &lt;code class=&quot;highlighter-rouge&quot;&gt;find_elements_by_partial_link_text&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;StackOverFlow is extremely handy. I am not sure what I would have done without it.&lt;/li&gt;
  &lt;li&gt;Don’t make assumptions. I assumed that the answers would all have different file names, but that was not always the case. This meant that previously downloaded were sometimes over-written by later answers. Fortunately, the was apparent in the first few minutes of running the program, so I could stop the program, and quickly modify it to add my own naming convention.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;
&lt;p&gt;The code to download the past papers is:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;subprocess&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;87&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;119&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://stepdatabase.maths.org/database/db/{i:02}/{i:02}-S{j}.pdf&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;subprocess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wget&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;87&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;119&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://stepdatabase.maths.org/database/db/{i:02}/{i:02}-S{j}.tex&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;subprocess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wget&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The (ugly) code I created to download the solutions is:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# open browser and go to the url
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webdriver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chrome&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'https://mei.org.uk/step-aea-solutions'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# click button, which opens new tab, so move to new tab
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_xpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'//button[text()=&quot;STEP Solutions&quot;]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;click&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;switch_to_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_handles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# click on link to go to next page
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_element_by_link_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'STEP past paper worked solutions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;click&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# obtain list of links in this page
# each of these refers to a group of step papers, e.g. STEP I, 2016-2019
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_elements_by_partial_link_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'STEP solutions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;href&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define regex pattern to help identify correct links
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;r&quot;STEP (1|I)+: \d\d\d\d&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# loop through links in groups
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_group&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# open the link
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# obtain list of links and names of papers in this group.
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# this requires the regex pattern from above
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;papers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paper&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_elements_by_partial_link_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'STEP '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'textContent'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;papers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;href&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'textContent'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# loop through the list of papers
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_paper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paper_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;papers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# open link for an individual paper
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_paper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# obtain list of links for answers to individual questions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;questions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_elements_by_partial_link_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Question '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# loop through the questions
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;questions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# open link to answer for individual question
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;click&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;switch_to_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_handles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# download image
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# note that the url you end on is different to the url you use to get to this page
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_url&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paper_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allow_redirects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# close browser and switch back to page with list of questions
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;switch_to_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;browser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_handles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Introduction Though I am transitioning from teaching to data science, I still continue to teach via private tuition. I am currently helping somebody prepare for the STEP, so I wanted to obtain as many past papers and solutions as I could. To do this manually would have required hours of clicking on links and ‘Saving as…’, so I decided to automate it with python.</summary></entry><entry><title type="html">EuroPython Conference 2020, Summary</title><link href="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/26/europython3.html" rel="alternate" type="text/html" title="EuroPython Conference 2020, Summary" /><published>2020-07-26T00:00:00-05:00</published><updated>2020-07-26T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/26/europython3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/26/europython3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/24/europython2.html&quot;&gt;EuroPython Conference 2020, Day 2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/23/europython1.html&quot;&gt;EuroPython Conference 2020, Day 1&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I attended the online conference &lt;a href=&quot;https://ep2020.europython.eu/&quot;&gt;EuroPython 2020&lt;/a&gt; and recorded notes while watching the talks. Today, I reviewed the notes with the aim of consolidating the main lessons, grouping together similar talks, and recording key lessons.&lt;/p&gt;

&lt;h2 id=&quot;workflows&quot;&gt;Workflows&lt;/h2&gt;
&lt;p&gt;This seems to be a big theme, and sounds like the next big challenge for the data scientist profession.&lt;/p&gt;

&lt;h3 id=&quot;gitlab-tools-william-arias&quot;&gt;GitLab Tools, William Arias&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;I found this talk hard to follow, so my notes are not great.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;parallel-stream-processing-alejandro-saucedo&quot;&gt;Parallel stream processing, Alejandro Saucedo&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;I found this talk hard to follow, but notes are bit better than the example above&lt;/li&gt;
  &lt;li&gt;Faust - stream processor&lt;/li&gt;
  &lt;li&gt;Kafka - ?&lt;/li&gt;
  &lt;li&gt;Seldon - deployment&lt;/li&gt;
  &lt;li&gt;Example of developing workflow to use ML to help moderate reddit comments.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-workflow-for-translation-shreya-khurana&quot;&gt;Example workflow for Translation, Shreya Khurana&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;I found this talk hard to follow, but still managed to take some notes.&lt;/li&gt;
  &lt;li&gt;Tools used include: seq2seq, Fairseq, Flask, uwsgi, nginx, supervisord, Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-from-teikametrics-chase-stevens&quot;&gt;Example from teikametrics, Chase Stevens&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Significant time spent emphasising need for good systems and workflows. Make the effort to automate!&lt;/li&gt;
  &lt;li&gt;My notes are not great when it comes to actually describing the tools or workflow they used. Watch the video to find out.&lt;/li&gt;
  &lt;li&gt;Interesting example at end: they automated task of choosing which AWS instance to use.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dvc-hongjoo-lee&quot;&gt;DVC, Hongjoo Lee&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Software development has following standard workflow and tools (I don’t know what most of these things mean…):
    &lt;ul&gt;
      &lt;li&gt;Coding management: git&lt;/li&gt;
      &lt;li&gt;Build: sbt maven&lt;/li&gt;
      &lt;li&gt;Test: jUnit&lt;/li&gt;
      &lt;li&gt;Release: Jenkins&lt;/li&gt;
      &lt;li&gt;Deploy: Docker, AWS&lt;/li&gt;
      &lt;li&gt;Operate: Kubernetes&lt;/li&gt;
      &lt;li&gt;Monitor: ELK stack&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hongjoo goes through live example of using DVC on simple model&lt;/li&gt;
  &lt;li&gt;Some alternatives to DVC: git-LFS, MLflow, Apache Airflow&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-pipelines-robson-junior&quot;&gt;Data pipelines, Robson Junior&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;I found the speaker particularly hard to follow. Despite this, it looks like I got some decent notes.&lt;/li&gt;
  &lt;li&gt;List of tools for different tasks&lt;/li&gt;
  &lt;li&gt;ELT: Apache Spark, dash, luigi, mrjob, ray&lt;/li&gt;
  &lt;li&gt;Streaming: faust and kafka, streamparse and Apache Storm&lt;/li&gt;
  &lt;li&gt;Analysis: Pandas, Blaze, Open Mining, Orange, Optimus&lt;/li&gt;
  &lt;li&gt;Management and scheduling: Apache Airflow&lt;/li&gt;
  &lt;li&gt;Testing: pytest, mimesis (to create fake data), fake2db, spark-test-base&lt;/li&gt;
  &lt;li&gt;Validation: Cerberus, schema, voluptuous&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-from-deepar-talk-nicola-kuhaupt&quot;&gt;Example from DeepAR talk, Nicola Kuhaupt&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Workflow was not focus of talk, but talk contained information on workflows anyway&lt;/li&gt;
  &lt;li&gt;Integrated into Sagemaker, which has many in built tools
    &lt;ul&gt;
      &lt;li&gt;Ground Truth. Use mechanical turk to build data sets&lt;/li&gt;
      &lt;li&gt;Studio. An IDA&lt;/li&gt;
      &lt;li&gt;Autopilot. For training models&lt;/li&gt;
      &lt;li&gt;Neo. For deployment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;boto3, to access aws&lt;/li&gt;
  &lt;li&gt;s3fs, file storage&lt;/li&gt;
  &lt;li&gt;Others were also mentioned. Re-watch talk to find them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nlpeasy-philipp-thomann&quot;&gt;NLPeasy, Philipp Thomann&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;NLPeasy is intended to make NLP easy&lt;/li&gt;
  &lt;li&gt;Has lots of built in tools, e.g. spaCy, Vader, BeautifulSoup&lt;/li&gt;
  &lt;li&gt;The talk presented example of analysing EuroPython abtracts&lt;/li&gt;
  &lt;li&gt;Had nice dashboard to visualise lots of outputs of models&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kedro-tam-sanh-nguyen&quot;&gt;Kedro, Tam-Sanh Nguyen&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Open source complete workflow package by QuantumBlack&lt;/li&gt;
  &lt;li&gt;Talk rushed through features of Kedro, but from the brief glimpse, it looks easy to use and has a nice UI.&lt;/li&gt;
  &lt;li&gt;See examples on GitHub or Tam-Sanh’s YouTube series DataEngineerOne&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recommended-packages--tools&quot;&gt;Recommended packages / tools&lt;/h2&gt;
&lt;h3 id=&quot;spacy-alexander-hendorf&quot;&gt;spaCy, Alexander Hendorf&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Open source library for NLP&lt;/li&gt;
  &lt;li&gt;Has many state-of-the-art algorithms built-in&lt;/li&gt;
  &lt;li&gt;Highly recommended by the speaker&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;diffprivlib-naoise-holohan&quot;&gt;diffprivlib, Naoise Holohan&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Open source library for differential privacy&lt;/li&gt;
  &lt;li&gt;(For background theory on differential privacy, I recommended &lt;a href=&quot;https://www.youtube.com/watch?v=bScJdHX0Hac&quot;&gt;this talk&lt;/a&gt; from &lt;a href=&quot;https://faculty.ai/&quot;&gt;FacultyAI&lt;/a&gt;.)&lt;/li&gt;
  &lt;li&gt;If you want to work with sensitive data, this is a good open source library to consider&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;googles-ml-apis-and-automl-laurent-picard&quot;&gt;Google’s ML APIs and AutoML, Laurent Picard&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Google has a lot of ML tools available&lt;/li&gt;
  &lt;li&gt;Looks nicely packaged and looks very user-friendly.&lt;/li&gt;
  &lt;li&gt;Is there even any point in me learning data science?!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;simpy-eran-friedman&quot;&gt;SimPy, Eran Friedman&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SimPy can be used to do discrete event simulation&lt;/li&gt;
  &lt;li&gt;E.g. for robotics training&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-visualisation-landscape-bence-arato&quot;&gt;Data Visualisation Landscape, Bence Arato&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;See notes or the talk for brief descriptions of the different tools.&lt;/li&gt;
  &lt;li&gt;Tools discussed are in image from this slide:
&lt;img src=&quot;/blog/images/europython_4.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;binder-sarah-gibson&quot;&gt;Binder, Sarah Gibson&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;For repeatable research (and for teaching/workshops), use Binder&lt;/li&gt;
  &lt;li&gt;Just have to give Binder link to your GitHub repo which contains a jupyter notebook and a standard requirements configuration file, and then Binder will create link.&lt;/li&gt;
  &lt;li&gt;You give link to somebody, they go to it, and they can run the jupyter notebook from their browser. Super easy&lt;/li&gt;
  &lt;li&gt;Binder is open source, so can be configured for your own needs. E.g. can make it so only certain individuals can access the link (or something like that).&lt;/li&gt;
  &lt;li&gt;Talk contained details of how Binder works, and the tools and infrastructure they use&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ipython-miki-tebeka&quot;&gt;IPython, Miki Tebeka&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Did live example of using IPython to do some initial experimentation of data and pre-processing style stuff&lt;/li&gt;
  &lt;li&gt;Magic commands with &lt;code class=&quot;highlighter-rouge&quot;&gt;%&lt;/code&gt;, comand line with &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;pprint&lt;/code&gt; for pretty printing, &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; for help, &lt;code class=&quot;highlighter-rouge&quot;&gt;??&lt;/code&gt; for source code, &lt;code class=&quot;highlighter-rouge&quot;&gt;%timeit&lt;/code&gt; for time analysis, can do sql with extension, &lt;code class=&quot;highlighter-rouge&quot;&gt;%cow&lt;/code&gt; for ascii art.&lt;/li&gt;
  &lt;li&gt;See talk for more examples not listed here&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;analytical-functions-in-sql-brendan-tierney&quot;&gt;Analytical Functions in SQL, Brendan Tierney&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Talk was cancelled, but their slides are available&lt;/li&gt;
  &lt;li&gt;Looks like SQL can do a lot more than what most of us know&lt;/li&gt;
  &lt;li&gt;Something worth researching&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tricks-and-tools-for-efficiencyspeed-gains&quot;&gt;Tricks and tools for efficiency/speed gains&lt;/h2&gt;
&lt;p&gt;Several talks were about this, so I thought it was worth grouping them together&lt;/p&gt;

&lt;h3 id=&quot;concurrentfutures-chin-hwee-ong&quot;&gt;concurrent.futures, Chin Hwee Ong&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Built in package in Python for parallel / asynchronous computing&lt;/li&gt;
  &lt;li&gt;For big data, can use tools like Spark.&lt;/li&gt;
  &lt;li&gt;For small big data, overhead cost is too large&lt;/li&gt;
  &lt;li&gt;Using concurrent.futures module can speed things up&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;daal4py-and-sdc-by-intel-fedotova-and-schlimbach&quot;&gt;daal4py and SDC by Intel, Fedotova and Schlimbach&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;These are open source tools that can drastically speed things up.&lt;/li&gt;
  &lt;li&gt;daal4py gives optimised versions of scikitlearn functions. But still in production. Some functions do not give identical output to their scikitlearn counterparts.&lt;/li&gt;
  &lt;li&gt;SDC. A just-in-time compiler. Extension of Numba.
    &lt;ul&gt;
      &lt;li&gt;Easy to use; just add decorate &lt;code class=&quot;highlighter-rouge&quot;&gt;@numba.jit&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Only works for statically compilable code&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Examples of speed ups provided in the talk&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tips-and-tricks-for-efficiency-gains-in-pandas-ian-ozsvald&quot;&gt;Tips and tricks for efficiency gains in Pandas, Ian Ozsvald&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;RAM considerations.
    &lt;ul&gt;
      &lt;li&gt;Use category instead of strings, for low cardinality data&lt;/li&gt;
      &lt;li&gt;Use float32 or float16 instead of float64&lt;/li&gt;
      &lt;li&gt;Has tool &lt;code class=&quot;highlighter-rouge&quot;&gt;dtype_diet&lt;/code&gt; to automate optimisation of a dataframe&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dropping to NumPy
    &lt;ul&gt;
      &lt;li&gt;E.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;df.sum()&lt;/code&gt; versus &lt;code class=&quot;highlighter-rouge&quot;&gt;df.values.sum()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some tools
    &lt;ul&gt;
      &lt;li&gt;bottleneck. See talk for example&lt;/li&gt;
      &lt;li&gt;dtype_diet&lt;/li&gt;
      &lt;li&gt;ipython_memory_usage&lt;/li&gt;
      &lt;li&gt;numba, njit wrapper.&lt;/li&gt;
      &lt;li&gt;Parallelise with Dask. Use profiling to check if benefit outweighs overhead&lt;/li&gt;
      &lt;li&gt;Vaex and modin.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Our own habits
    &lt;ul&gt;
      &lt;li&gt;Write tests!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lots of other examples in their blog and book&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;30-rules-for-deep-learning-performance-siddha-ganju&quot;&gt;30 Rules for Deep Learning Performance, Siddha Ganju&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;30 tips and tricks for deep learning in TensforFlow&lt;/li&gt;
  &lt;li&gt;No point repeating them all here. See notes from talk, or watch talk (or buy their book Practical Deep Learning)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;miscellaneous&quot;&gt;Miscellaneous&lt;/h2&gt;
&lt;h3 id=&quot;tips-for-docker-tania-allard&quot;&gt;Tips for Docker, Tania Allard.&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Expect things to be tricky and frustrating. There are many bad tutorials online&lt;/li&gt;
  &lt;li&gt;Do not re-invent the wheel: use cookie-cutter, repo2docker&lt;/li&gt;
  &lt;li&gt;Many other useful tips in the talk&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-cleaning-checklist-hui-zhang-chua&quot;&gt;Data Cleaning Checklist, Hui Zhang Chua&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Hui provided a checklist of tasks you should do when cleaning data.&lt;/li&gt;
  &lt;li&gt;Refer to the notes from the talk for the list&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;history-of-jupyter-notebooks-william-horton&quot;&gt;History of Jupyter Notebooks, William Horton&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Does what it says on the tin. I stopped taking notes because I do not anticipate learning the history. Watch the talk if you want to know more.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;neural-style-transfer-and-gans-anmol-krishan-sachdeva&quot;&gt;Neural Style Transfer and GANs, Anmol Krishan Sachdeva&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Anmol described the algorithm for GANs and for neural style transfer&lt;/li&gt;
  &lt;li&gt;Showed example code in the talk&lt;/li&gt;
  &lt;li&gt;See notes for the details. It’s pretty clever stuff!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;probabilistic-forecasting-with-deepar-nicolas-kuhaupt&quot;&gt;Probabilistic forecasting with DeepAR, Nicolas Kuhaupt&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;DeepAR is an algorithm to produce probabilistic time series predictions, by Amazon&lt;/li&gt;
  &lt;li&gt;One interesting feature is it deals with multiple time series simultaneously&lt;/li&gt;
  &lt;li&gt;I did not understand details. Would have to read paper to understand&lt;/li&gt;
  &lt;li&gt;Example uses cases
    &lt;ul&gt;
      &lt;li&gt;Sales at amazon. Each product has its own time series&lt;/li&gt;
      &lt;li&gt;Sales of magazines in different stores. Each store has its own time series.&lt;/li&gt;
      &lt;li&gt;Loads on servers in data centers&lt;/li&gt;
      &lt;li&gt;Car traffic. Separate time series for each lane&lt;/li&gt;
      &lt;li&gt;Energy consumption by household.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Goes through an example in the talk&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Other posts in series EuroPython Conference 2020, Day 2 EuroPython Conference 2020, Day 1</summary></entry><entry><title type="html">EuroPython Conference 2020, Day 2</title><link href="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/24/europython2.html" rel="alternate" type="text/html" title="EuroPython Conference 2020, Day 2" /><published>2020-07-24T00:00:00-05:00</published><updated>2020-07-24T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/24/europython2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/24/europython2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/26/europython3.html&quot;&gt;EuroPython Conference 2020, Summary&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/23/europython1.html&quot;&gt;EuroPython Conference 2020, Day 1&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I am attending the online conference &lt;a href=&quot;https://ep2020.europython.eu/&quot;&gt;EuroPython 2020&lt;/a&gt;, and I thought it would be good to record what my thoughts and the things I learn from the talks.&lt;/p&gt;

&lt;h2 id=&quot;700-automating-machine-learning-workflow-with-dvc-hongjoo-lee&quot;&gt;7:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/CXG7TcM-automating-machine-learning-workflow-with-dvc/&quot;&gt;Automating machine learning workflow with DVC&lt;/a&gt;, Hongjoo Lee&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Works for SK hynix, a memory chip maker in South Korea.&lt;/li&gt;
  &lt;li&gt;Waterfall vs agile production. Waterfall = design, then build, then release, then done. Agile, more iterative approach.&lt;/li&gt;
  &lt;li&gt;Software dev/dev ops: code git, build sbt maven, test jUnit, release Jenkins, deploy Docker aws, operate Kubernetes, monitor ELK stack&lt;/li&gt;
  &lt;li&gt;ML dev lifecycle: get data, preprocess, build model, optimise model, deployment.
    &lt;ul&gt;
      &lt;li&gt;Often getting data requires domain expertise&lt;/li&gt;
      &lt;li&gt;Often software engineers are needed for deployment&lt;/li&gt;
      &lt;li&gt;Still improvement and modification needed for ML dev workflow. In early stages.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data versioning.
    &lt;ul&gt;
      &lt;li&gt;Can be terrible, with names like &lt;code class=&quot;highlighter-rouge&quot;&gt;raw_data&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cleaned_data&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cleaned_data_final&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;Need to have system where any change in data will trigger pipeline&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ML is metric driven. Software engineering is feature driven.
    &lt;ul&gt;
      &lt;li&gt;ML Models version should be tracked.&lt;/li&gt;
      &lt;li&gt;Metrics should be versioned/tracked&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DVC helps. Some laternatives: git-LFS, MLflow, Apache Airflow
    &lt;ul&gt;
      &lt;li&gt;Easy to use&lt;/li&gt;
      &lt;li&gt;Language independent&lt;/li&gt;
      &lt;li&gt;Useful for individuals and for large teams&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Example code: &lt;a href=&quot;https://github.com/midnightradio/handson-dvc&quot;&gt;on github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Hongjoo works through a cats vs dogs example in talk
    &lt;ul&gt;
      &lt;li&gt;Download template directory&lt;/li&gt;
      &lt;li&gt;Use git to keep track of changes&lt;/li&gt;
      &lt;li&gt;Use dvc command-line commands to define each of the steps in ml pipeline&lt;/li&gt;
      &lt;li&gt;dvc dag command - shows ascii diagram of pipeline&lt;/li&gt;
      &lt;li&gt;dvc repro - checks if there are changes, and if so, re-runs pipeline. E.g. change model by adding a layer, then dvc repro does everything. you have to manually to git commit command and naming of versions&lt;/li&gt;
      &lt;li&gt;dvc metric show. shows metrics of all versions done.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Looks simple enough! I could follow the talk. :D It is clear that finding a good ML workflow is a big theme. At the end of the conference, I will have to go through these notes and collate the various tools and workflows people use, so I have a reference for when I need to use it.&lt;/p&gt;

&lt;h2 id=&quot;730-tips-for-data-cleaning-hui-ziang-chua&quot;&gt;7:30, &lt;a href=&quot;https://ep2020.europython.eu/talks/CivrR5y-top-15-python-tips-for-data-cleaning-understanding/&quot;&gt;Tips for Data Cleaning&lt;/a&gt;, Hui Ziang Chua&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-1&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background. Singaporean. Works at essence. Blog data double confirm.&lt;/li&gt;
  &lt;li&gt;Will try to give business centred context - very different from academic/research/learning contetx&lt;/li&gt;
  &lt;li&gt;Tasks
    &lt;ul&gt;
      &lt;li&gt;Get column names&lt;/li&gt;
      &lt;li&gt;Get size of dataset. Make sure all data has been loaded.&lt;/li&gt;
      &lt;li&gt;Check datatypes. Sometimes goes wrong. Sign for data-cleaning.&lt;/li&gt;
      &lt;li&gt;Get unique values. Some cases, need to combine different values into one. E.g. ‘Male’ and ‘M’&lt;/li&gt;
      &lt;li&gt;Get range of values&lt;/li&gt;
      &lt;li&gt;Get count of values. Group-by various columns as appropriate.&lt;/li&gt;
      &lt;li&gt;Rename column names. E.g. for merging&lt;/li&gt;
      &lt;li&gt;Remove symbols in values. E.g. currency signs&lt;/li&gt;
      &lt;li&gt;Convert strings to numeric or to dates&lt;/li&gt;
      &lt;li&gt;Replace values with more sensible values. E.g. ‘Male’ vs ‘M’&lt;/li&gt;
      &lt;li&gt;Identify variables/columns similar or different across datasets&lt;/li&gt;
      &lt;li&gt;Concatenate data. Data from different quarters added to single table.&lt;/li&gt;
      &lt;li&gt;Deduplication. Remove duplicate data.&lt;/li&gt;
      &lt;li&gt;Merge&lt;/li&gt;
      &lt;li&gt;Recoding. Feature engineering&lt;/li&gt;
      &lt;li&gt;Data profiling (optional)&lt;/li&gt;
      &lt;li&gt;Input missing values (optional)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Common issues
    &lt;ul&gt;
      &lt;li&gt;inconsistent naming of variables&lt;/li&gt;
      &lt;li&gt;bad data formats&lt;/li&gt;
      &lt;li&gt;invalid,missing values&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Resources: tinyurl.com/y5b3y7to&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-1&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;It is useful to have a checklist of tasks one should do when they have to clean data. Interesting that they considered the input of missing values as a bonus task - the impression I got from the Kaggle tutorials is that one ought to do some imputation.&lt;/p&gt;

&lt;h2 id=&quot;900-neural-style-transfer-and-gans-anmol-krishan-sachdeva&quot;&gt;9:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/BSeL2FG-painting-with-gans-challenges-and-technicalities-of-neural-style-transfer/&quot;&gt;Neural Style Transfer and GANs&lt;/a&gt;, Anmol Krishan Sachdeva&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-2&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Recap of GANs
    &lt;ul&gt;
      &lt;li&gt;Discriminative model. Supervised classification model. Fed in data.&lt;/li&gt;
      &lt;li&gt;Generative model. Mostly unsupervised. Generates new data by underlying underlying data distribution. Generates near-real looking data. (Conditional generators have some element of supervised learning included). Learning of distribution called implicit density estimation.&lt;/li&gt;
      &lt;li&gt;In end, have GAN which takes random input and creates an output that has similar distribution it was trained on.&lt;/li&gt;
      &lt;li&gt;Training. Dicriminator gets true entry x and fake input from generator network x*. Generator tries to classify. Compute error and backpropogate. Generator then trained. Similar.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Book: &lt;a href=&quot;https://www.manning.com/books/gans-in-action#toc&quot;&gt;GANs in Action by Langr and Bok&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GANs have been successful in creating near-real images.&lt;/li&gt;
  &lt;li&gt;Style Transfer: Content image + style image gives new image with content from first in style of second image.&lt;/li&gt;
  &lt;li&gt;Aim of Style Transfer Networks
    &lt;ul&gt;
      &lt;li&gt;Not to learn underlying distrbution.&lt;/li&gt;
      &lt;li&gt;Somehow learn style from style image and embed it into content cimage&lt;/li&gt;
      &lt;li&gt;Interpolation is bad&lt;/li&gt;
      &lt;li&gt;Used in gaming industry, mobile applications, fashion/design&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Popular networks: Pix2Pix, CycleGAN, Neural Style Transfer&lt;/li&gt;
  &lt;li&gt;Neural Style Transfer.
    &lt;ul&gt;
      &lt;li&gt;No training set! Just take as input the two images.&lt;/li&gt;
      &lt;li&gt;Example from Neural Algorithm of Artistic Style. Photo turned into painting of certain artist&lt;/li&gt;
      &lt;li&gt;Content loss - measure of content between new image and content image&lt;/li&gt;
      &lt;li&gt;Style loss - measure of style between new image and style image.&lt;/li&gt;
      &lt;li&gt;total variation loss. Check for blurriness, distortions, pixelations&lt;/li&gt;
      &lt;li&gt;How is learning done? No trianing set, no back prop?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Shows example notebook, using TensorFlow and Keras. Imports pre-trained model.&lt;/li&gt;
  &lt;li&gt;Content loss.
    &lt;ul&gt;
      &lt;li&gt;Pixel by pixel comparison not done.&lt;/li&gt;
      &lt;li&gt;Compare higher level features, obtained from pre-trained model. E.g. VGG19 is 19 layered CNN, which classifies images into 1000 categories. Trained on million images.&lt;/li&gt;
      &lt;li&gt;VGG architecture. See &lt;a href=&quot;https://www.amazon.co.uk/Generative-Deep-Learning-Teaching-Machines/dp/1492041947&quot;&gt;Generative Deep Learning by David Foster&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;Keras repo. Neural style transfer.&lt;/li&gt;
      &lt;li&gt;Take 3rd layer of block 5 from VGG19 model as measure of higher level features.&lt;/li&gt;
      &lt;li&gt;Content loss = mean squared error between this vector encoding of high level features from VGG19 for content image and generated image.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Style loss
    &lt;ul&gt;
      &lt;li&gt;Take dot product of ‘flattened feature maps’&lt;/li&gt;
      &lt;li&gt;Lower level layers represent style.&lt;/li&gt;
      &lt;li&gt;GRAM matrix. Dot product of ‘flattened features’ of image with itself.&lt;/li&gt;
      &lt;li&gt;Didn’t understand this.&lt;/li&gt;
      &lt;li&gt;Loss = MSE (gram matrix(style image), gram matrix(generated image))&lt;/li&gt;
      &lt;li&gt;Then take weighted sum over different sets of layers&lt;/li&gt;
      &lt;li&gt;Shows example code.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;features = K.batch_flatten(K.permute...)&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Take first layer in each block&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Total variation loss
    &lt;ul&gt;
      &lt;li&gt;sum of squared difference between image and image shifted on pixel down, and of shifted one pixel right&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Training
    &lt;ul&gt;
      &lt;li&gt;Add up all the loss&lt;/li&gt;
      &lt;li&gt;Use L-BFGS optimisation. Essentially just gradient descent on individual pixel values.&lt;/li&gt;
      &lt;li&gt;Example code shown in talk.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pix2Pix
    &lt;ul&gt;
      &lt;li&gt;Various cool things you can do. E.g. aerial image to a map. Sketch to full image.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CycleGAN
    &lt;ul&gt;
      &lt;li&gt;E.g. convert image of apples to oranges. Or horses to zebras!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-2&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Excellent talk! I had seen some of the neural style transfer images before, and now I have some understanding of how they are created!&lt;/p&gt;

&lt;h2 id=&quot;1000-data-visualisation-landscape-bence-arato&quot;&gt;10:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/B5Vff6U-the-python-data-visualization-landscape-in-2020/&quot;&gt;Data Visualisation Landscape&lt;/a&gt;, Bence Arato&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-3&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;There are lots of libraries out there.&lt;/li&gt;
  &lt;li&gt;Imperative vs declarative. Imperative: specify how something should be done. Declarative: specify what should be done.&lt;/li&gt;
  &lt;li&gt;Matplotlib. Biggest example. Has gallery + code examples
    &lt;ul&gt;
      &lt;li&gt;Background in MATLAB&lt;/li&gt;
      &lt;li&gt;Challenge: imperative&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Seaborn. Aim to provide higher level package on top of matplotlib. Good defaults for charts that look good.
    &lt;ul&gt;
      &lt;li&gt;Example scatterplot much easier in seaborn than in matplotlib&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;plotnine. Aim to higher-level. Based on ggplot2 in R.
    &lt;ul&gt;
      &lt;li&gt;Syntax is basically same as ggplot syntax!&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;aes&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;geom_point&lt;/code&gt; etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;bokeh. 2nd most widely known tool.
    &lt;ul&gt;
      &lt;li&gt;Big thing is interactivity, like sliders, checkboxes, etc.&lt;/li&gt;
      &lt;li&gt;Example scatterplot. Quite long and low-level&lt;/li&gt;
      &lt;li&gt;Based on web/javascript background&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HoloViews
    &lt;ul&gt;
      &lt;li&gt;Higher level language for bokeh, matplotlib, plotly&lt;/li&gt;
      &lt;li&gt;Just have to change one line code to switch between bokeh or matplotlib output&lt;/li&gt;
      &lt;li&gt;Scatterplot example. Short code.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hvPlot. built on top of holoviews&lt;/li&gt;
  &lt;li&gt;pandas bokeh. add plot_bokeh() method in pandas.&lt;/li&gt;
  &lt;li&gt;Chartify. From spotify. Built on top of bokeh.&lt;/li&gt;
  &lt;li&gt;Plotly.
    &lt;ul&gt;
      &lt;li&gt;Might be only one to do 3d charts well&lt;/li&gt;
      &lt;li&gt;Low level charts&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Plotly express
    &lt;ul&gt;
      &lt;li&gt;Higher level version of plotly.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Vega, vega-lite
    &lt;ul&gt;
      &lt;li&gt;Visualisation ‘grammar’.&lt;/li&gt;
      &lt;li&gt;JSON based way of describing charts&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Altair
    &lt;ul&gt;
      &lt;li&gt;High level version of vega&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dashboards.
    &lt;ul&gt;
      &lt;li&gt;Plotly Dash&lt;/li&gt;
      &lt;li&gt;Panel. Anaconda related. Built on top of four big charting libaries above&lt;/li&gt;
      &lt;li&gt;Voila. Looks cool - can visualise ML things. Need to check out!&lt;/li&gt;
      &lt;li&gt;Streamlit. Datascience specific tools. Example of GAN Image generator with sliders. Change slider will re-run model and create new image.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PyViz. Thorough list of all visualisation libraries.&lt;/li&gt;
  &lt;li&gt;Python Data Visualisation, at AnacondaCON 2020&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-3&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Excellent talk. Well structured, good examples, good summary of key things I should know about.&lt;/p&gt;

&lt;h2 id=&quot;1030-binder-sarah-gibson&quot;&gt;10:30, &lt;a href=&quot;https://ep2020.europython.eu/talks/BqQBN6J-sharing-reproducible-python-environments-with-binder/&quot;&gt;Binder&lt;/a&gt;, Sarah Gibson&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-4&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Table of levels of reproducibility&lt;/li&gt;
  &lt;li&gt;Same or different data or analysis.
    &lt;ul&gt;
      &lt;li&gt;Rep = same, same&lt;/li&gt;
      &lt;li&gt;Replicable = different data&lt;/li&gt;
      &lt;li&gt;Robust = different analysis&lt;/li&gt;
      &lt;li&gt;Generalisable = diff, diff.&lt;/li&gt;
      &lt;li&gt;Repeatable is subset of reproducible. Literally same programs running same data and analysis to get same result.&lt;/li&gt;
      &lt;li&gt;Reproducible means getting same result using same data and method - but maybe implemented in different language or program or …&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CI/CD = continous integration / development&lt;/li&gt;
  &lt;li&gt;Two big tools needed for repeatable research: dockers and version control. But requires learning. Not for everyone.&lt;/li&gt;
  &lt;li&gt;Shows example from ligo about gravitational waves.&lt;/li&gt;
  &lt;li&gt;Steps
    &lt;ul&gt;
      &lt;li&gt;Use jupyter notebook&lt;/li&gt;
      &lt;li&gt;Upload on public repositiy, e.g. GitHub.&lt;/li&gt;
      &lt;li&gt;Describe software needed to run notebook. Binder automatically identifies common configuration files&lt;/li&gt;
      &lt;li&gt;Done!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Brief history of Binder. Now 140,000 sessions per week!&lt;/li&gt;
  &lt;li&gt;Binder is open source, can adapt to your own needs. E.g. share only with specific people in your institution.&lt;/li&gt;
  &lt;li&gt;Technologies
    &lt;ul&gt;
      &lt;li&gt;Github, clone reposity&lt;/li&gt;
      &lt;li&gt;repo2docker. Build docker image based on standard configuration files. Don’t need docker file!&lt;/li&gt;
      &lt;li&gt;Docker. Execute docker image&lt;/li&gt;
      &lt;li&gt;Jupyter Hub. Allocate resources, make image accessible at url&lt;/li&gt;
      &lt;li&gt;Binder, redirect user to the url&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scaling up
    &lt;ul&gt;
      &lt;li&gt;Created federation&lt;/li&gt;
      &lt;li&gt;Highly stable. Uses different kubernetes implementations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;User surveys
    &lt;ul&gt;
      &lt;li&gt;Around 80% of respondants would recommend service&lt;/li&gt;
      &lt;li&gt;Most common use case is teaching related. Examples, workings, uni teaching, demos, etc.&lt;/li&gt;
      &lt;li&gt;Biggest complaint: needs to be faster to load&lt;/li&gt;
      &lt;li&gt;Hard to speed up. But fully explained on jupyter hub blog. Why it is slow but also tips to speed things up.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-4&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;I had already heard of Binder - because I am friends with the spaker Sarah Gibson! However, the talk was still good, and I learnt more than I already knew. In particular, I liked the classification of different levels of reproducibility.&lt;/p&gt;

&lt;h2 id=&quot;1100-data-pipelines-with-python-robson-junior&quot;&gt;11:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/4bNvaVk-mastering-a-data-pipeline-with-python-6-years-of-learned-lessons-from-mistakes/&quot;&gt;Data pipelines with Python&lt;/a&gt;, Robson Junior&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-5&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Agenda: Not about code. Anatomy of data product, different architectures, qualities of data pipelines, how python matters.&lt;/li&gt;
  &lt;li&gt;Anatomy of data product.
    &lt;ul&gt;
      &lt;li&gt;Ingress. Logs, databases, etc. Volume and variety are important.&lt;/li&gt;
      &lt;li&gt;Processes. Processing both input and output data.  Veracity and velocity are important here. E.g bank processing payment may have to run fraud detection - has to be very quick!&lt;/li&gt;
      &lt;li&gt;Egress. Apis or databases. Veracity is important.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lambda and Kappa Architeture
    &lt;ul&gt;
      &lt;li&gt;Above anatomy of data product is same as computer program: input is files and memory, processes in ram, output to screen.&lt;/li&gt;
      &lt;li&gt;Lambda. Input data. Processing split into two layers. Speed layer for stream data, real time view. Batch layer, all data, batch views, usually processed periodically. Then output via query. See talk for diagram. Some pros and cons given in talk&lt;/li&gt;
      &lt;li&gt;Kappa. Only have a speed layer - no batch layer. Pros and cons given in talk.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Qualities of a pipeline
    &lt;ul&gt;
      &lt;li&gt;Should be secure. Who has access to which data levels, use common format for data storage, be conscious of who has access to which parts of data and why.&lt;/li&gt;
      &lt;li&gt;Should be automated. Use good tools. Versioning, ci/cd, code review.&lt;/li&gt;
      &lt;li&gt;Monitoring. ??&lt;/li&gt;
      &lt;li&gt;Testable and tracable. Test all parts of the pipeline. Try to containerise tools.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Python tools
    &lt;ul&gt;
      &lt;li&gt;ELT. Apache Spark, dash, luigi, mrjob, ray&lt;/li&gt;
      &lt;li&gt;Streaming. faust based on Kafka streams, streamparse via Apache Storm&lt;/li&gt;
      &lt;li&gt;Analysis. Pandas, Blaze, Open Mining, Orange, Optimus&lt;/li&gt;
      &lt;li&gt;Mangaement and scheduling. Apache Airflow. Programmatically create workflow&lt;/li&gt;
      &lt;li&gt;Testing. pytest, mimesis (create fake data), fake2db, spark-test-base&lt;/li&gt;
      &lt;li&gt;Validation. Cerberus, schema, voluptuous&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-5&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Unfortunately, I found the talk/speaker hard to follow. But I still got a list of tools that I can use as a reference.&lt;/p&gt;

&lt;h2 id=&quot;1215-probabilistic-forecasting-with-deepar-nicolas-kuhaupt&quot;&gt;12:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/ANSma2D-probabilistic-forecasting-with-deepar-and-aws-sagemaker/&quot;&gt;Probabilistic Forecasting with DeepAR&lt;/a&gt;, Nicolas Kuhaupt&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-6&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Freelance data scientist. German.&lt;/li&gt;
  &lt;li&gt;DeepAR published by Amazon Research&lt;/li&gt;
  &lt;li&gt;It is probabilistic, like ARIMA and regression models, but not like Plain LSTMs&lt;/li&gt;
  &lt;li&gt;Automatic Feature Engineering. Key point of neural networks! Like Plain LSTMs but unlike ARIMA and regression models.&lt;/li&gt;
  &lt;li&gt;One algorithm for multiple timeseries. Seems unlike other algorithms.  Like meta learning? Transfer learning??&lt;/li&gt;
  &lt;li&gt;Disadvantages: time and resource intensive to train, difficult to set hyperparameters (like most neural networks).&lt;/li&gt;
  &lt;li&gt;How it works: inputs time series x. At time t, outputs &lt;code class=&quot;highlighter-rouge&quot;&gt;z_t&lt;/code&gt;, which are parameters for a probability distribution to predict. Then &lt;code class=&quot;highlighter-rouge&quot;&gt;z_t&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;x_t+1&lt;/code&gt; are inputted into next stage.&lt;/li&gt;
  &lt;li&gt;Example datasets. Sales at amazons - one time series for each product, sales of magazines in different stores, forecast loads of servers in datacenters, car traffic - each lane has its own time series, energy consumption in households - each household has its own time series.&lt;/li&gt;
  &lt;li&gt;Integrated into Sagemaker.
    &lt;ul&gt;
      &lt;li&gt;Provides notebook&lt;/li&gt;
      &lt;li&gt;Lots of different tools for different stages of data science workflow. e.g. Ground Truth to use mechanical turk to build data sets. Studio is IDE. Autopilot for training models, Neo for deployment, etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;boto3 - access services in aws. s3fs - file storage stuff. various other details in talk&lt;/li&gt;
  &lt;li&gt;data inform of json lines, (not pandas)
    &lt;ul&gt;
      &lt;li&gt;start - start time, target - the time series, cat - some categories that timeseries belongs to, dynamic_feat - extra time series (of same length as target).  note that different json lines can have time series of different lengths&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hyperparameters. standard stuff, with few extras for deepar.&lt;/li&gt;
  &lt;li&gt;code to set up model and train it&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-6&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Looks like a powerful algorithm. Probabilistic algorithms are definitely the way to go - how else can you manage and predict risk?&lt;/p&gt;

&lt;h2 id=&quot;1315-fast-and-scalable-ml-in-python-victoriya-fedotova-and-frank-schlimbach&quot;&gt;13:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/CR4ben4-the-painless-route-in-python-to-fast-and-scalable-machine-learning/&quot;&gt;Fast and Scalable ML in Python&lt;/a&gt;, Victoriya Fedotova and Frank Schlimbach&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-7&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Python is useful but slow. So often companies hire engineers to translate python to faster languages like C++.&lt;/li&gt;
  &lt;li&gt;Intel made a python distribution. No code changes required. * Just-in-time computation. JIT gives big speed boost.&lt;/li&gt;
  &lt;li&gt;ML workflow: input and preprocessing via pandas, spark, SDC. model creation and prediction: scikit learn, spark, dl frameworks, daal4py.&lt;/li&gt;
  &lt;li&gt;In this talk, talk about SDC, sckit learn, daal4py&lt;/li&gt;
  &lt;li&gt;Intel Daal. Data analytics acceleration library. Linear Algebra already sped up (e.g. with MKL from intel), but this new library helps in situations whcih do not use linear algebra - e.g. tree based algorithms.&lt;/li&gt;
  &lt;li&gt;Talk gives details on how to install packages and use it.&lt;/li&gt;
  &lt;li&gt;Many algorithms have equivalent output to scikit learn algorithms. But not all - e.g. randomforest does not have 100% same output.&lt;/li&gt;
  &lt;li&gt;Example of k-means in scikit-learn versus daal4py. Similar structure. Slightly different syntax. e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;n_clusters&lt;/code&gt; versus &lt;code class=&quot;highlighter-rouge&quot;&gt;nClusters&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Scalable dataframe compiler SDC. a just in time compiler. Extension of Numba - made by anaconda.&lt;/li&gt;
  &lt;li&gt;Easy to use. Just add decorator &lt;code class=&quot;highlighter-rouge&quot;&gt;@numba.jit&lt;/code&gt; to function that you want to be compiled.&lt;/li&gt;
  &lt;li&gt;Explanation of compiler pipeline.&lt;/li&gt;
  &lt;li&gt;Talks through basic example of reading file, storing in frame, calculating mean, ordering a column. E.g. reading of file is parallelised, whereas pandas just reads data in single line.&lt;/li&gt;
  &lt;li&gt;SDC requires code to be statically compilable - i.e. type stable. Examples where this wouldn’t work.&lt;/li&gt;
  &lt;li&gt;Charts showing speed-ups of different operations, as you increase the number of threads. Some operations get good speeds up, and some get mega speeds ups. Most was &lt;code class=&quot;highlighter-rouge&quot;&gt;apply(lambda x:x)&lt;/code&gt; with 400x speed up. Something to do with lambda function being compiled too, not just apply function.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-7&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Looks easy to use and can give big speed boosts. Is there a catch?&lt;/p&gt;

&lt;h2 id=&quot;1415--small-big-data-in-pandas-dask-and-vaex-ian-ozsvald&quot;&gt;14:15 , &lt;a href=&quot;https://ep2020.europython.eu/talks/A7TniMV-making-pandas-fly/&quot;&gt;Small Big Data in Pandas, Dask and Vaex&lt;/a&gt;, Ian Ozsvald&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-8&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Discuss how to speed things up in pandas. Why when there are tools out there? Ought to increase our knowledge and push our speed in current tools.&lt;/li&gt;
  &lt;li&gt;Example of company registration data in uk&lt;/li&gt;
  &lt;li&gt;Ram considerations
    &lt;ul&gt;
      &lt;li&gt;Strings are slow. Takes up lots of ram.&lt;/li&gt;
      &lt;li&gt;In example of company category taking up 300MB. Convert to category type and it takes 4.5 MB. Numeric code stored instead of strings.&lt;/li&gt;
      &lt;li&gt;Get speed up on value_counts. 0.485s vs 0.028s.&lt;/li&gt;
      &lt;li&gt;Example of settign this column to index and then creating mask based on index. 281ms vs 569 microseconds.&lt;/li&gt;
      &lt;li&gt;Try using category for low cardinality data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;float64 is default and expansive.
    &lt;ul&gt;
      &lt;li&gt;Example of age of company, up to 190 years.&lt;/li&gt;
      &lt;li&gt;Use float32 or float16 instead.&lt;/li&gt;
      &lt;li&gt;Less RAM. Small time saving. (float16 might actually be slower!)&lt;/li&gt;
      &lt;li&gt;Might have loss in precision in data. Depends on data and usage&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Has a tool &lt;code class=&quot;highlighter-rouge&quot;&gt;dtype_diet&lt;/code&gt; to automate process of optimising dataframe.
    &lt;ul&gt;
      &lt;li&gt;Produces table showing how different things can improve RAM usage.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Saving RAM is good. Can process more data. Speeds things up.&lt;/li&gt;
  &lt;li&gt;Dropping to NumPy.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;df.sum()&lt;/code&gt; versus &lt;code class=&quot;highlighter-rouge&quot;&gt;df.values.sum()&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;In example, 19.1ms to 2ms.&lt;/li&gt;
      &lt;li&gt;Somethings to watch out for, e.g. NaN.&lt;/li&gt;
      &lt;li&gt;James Powell produced diagram showing all files and functions called when doing sum in pandas versus in numpy. (Doing this using &lt;code class=&quot;highlighter-rouge&quot;&gt;ser.sum()&lt;/code&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Is pandas just super slow.
    &lt;ul&gt;
      &lt;li&gt;Can get big boost just by using bottleneck. see code in example.&lt;/li&gt;
      &lt;li&gt;just instal bottleneck, numexpr&lt;/li&gt;
      &lt;li&gt;Investigate dtype_diet&lt;/li&gt;
      &lt;li&gt;ipython_memory_usage&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pure python is slow
    &lt;ul&gt;
      &lt;li&gt;Use numba, njit wrapper. See Intel talk above for newer extensions to numba.&lt;/li&gt;
      &lt;li&gt;Parallelise with Dask. Overhead may overwhelm benefit. USe profiling and timing tools to check.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Big time savings come from our own habits
    &lt;ul&gt;
      &lt;li&gt;Reduce mistakes. Try nullable Int64, boolean&lt;/li&gt;
      &lt;li&gt;Write tests, unit and end-to-end&lt;/li&gt;
      &lt;li&gt;Lots of other examples from blog&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Vaex and Modin. Two other tools.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-8&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Excellent talk! Ian clearly knows his stuff. Lots of insights. These are things I should start to implement to get some easy time savings.&lt;/p&gt;

&lt;h2 id=&quot;1445-ipython-miki-tebeka&quot;&gt;14:45, &lt;a href=&quot;https://ep2020.europython.eu/talks/5LGWwvT-ipython-the-productivity-booster/&quot;&gt;IPython&lt;/a&gt;, Miki Tebeka&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-9&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Programmer for 30 years.&lt;/li&gt;
  &lt;li&gt;Wrote book, Python Brain Teasers&lt;/li&gt;
  &lt;li&gt;Likes ipython. It is a REPL: Real, Eval, Prompt Loop&lt;/li&gt;
  &lt;li&gt;Magic commands, via &lt;code class=&quot;highlighter-rouge&quot;&gt;%&lt;/code&gt;. E.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;%pwd&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Can refer to outputs like variables. &lt;code class=&quot;highlighter-rouge&quot;&gt;logs_dir = Out[4]&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Command line. &lt;code class=&quot;highlighter-rouge&quot;&gt;!ls $logs_dir&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Auto-complete features&lt;/li&gt;
  &lt;li&gt;He uses Vim! Woo!&lt;/li&gt;
  &lt;li&gt;pprint for pretty printing.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; for help. &lt;code class=&quot;highlighter-rouge&quot;&gt;??&lt;/code&gt; for source code&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;%timeit function&lt;/code&gt; to give time analysis&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;%%timeit&lt;/code&gt;` for multiline stuff&lt;/li&gt;
  &lt;li&gt;Can do sql stuff. have to install extension. see video for example.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;%cow IPython Rocks!&lt;/code&gt; Produces ascii art of cow!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-9&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Always good to see a live demo to see exactly how somebody does things. I learnt some neat little features. Also, cool to see someone using Vim!&lt;/p&gt;

&lt;h2 id=&quot;1515-nlpeasy-philipp-thomann&quot;&gt;15:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/6x7ezDb-nlpeasy-a-workflow-to-analyse-enrich-and-explore-textual-data/&quot;&gt;NLPeasy&lt;/a&gt;, Philipp Thomann&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-10&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Co-creator of liquidSVM, Nabu, NLPeasy, PlotVR&lt;/li&gt;
  &lt;li&gt;Works at D One. ML consultancy&lt;/li&gt;
  &lt;li&gt;NLP. Big progress recently. Word2Vec, Deep learning and many good pre-trained models. Lots of data, many use cases&lt;/li&gt;
  &lt;li&gt;Challenges for data scientists.
    &lt;ul&gt;
      &lt;li&gt;NLP is generally harder - high dimensions, specialised pre-processing required, nlp experts/researchers focus only on text but there is usually other data in business.&lt;/li&gt;
      &lt;li&gt;Methods have repuation of being hard to use&lt;/li&gt;
      &lt;li&gt;standard tools not good for text. e.g. seaborn, tableau&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;NLPeasy to the rescue!&lt;/li&gt;
  &lt;li&gt;Pandas based pipeline, built in Regex based tagging, spaCy based NLP methods, Vader, scraping with beautiful soup, …&lt;/li&gt;
  &lt;li&gt;ElasticSearch. ??&lt;/li&gt;
  &lt;li&gt;See Github repo for code, ntoebook example, etc.&lt;/li&gt;
  &lt;li&gt;Talk through example, of looking at abstracts from some conference.&lt;/li&gt;
  &lt;li&gt;Live demo!
    &lt;ul&gt;
      &lt;li&gt;Scraping EP 2020 data.&lt;/li&gt;
      &lt;li&gt;Doing NLPeasy stuff&lt;/li&gt;
      &lt;li&gt;Go to Elastic dashboard&lt;/li&gt;
      &lt;li&gt;Lots of things shown, possible. E.g. entity extraction, tSNE&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;REstaurant similarity using clustering algorithms. based only on reviews! can detect similarities&lt;/li&gt;
  &lt;li&gt;Kibana (I think) can produce geoview / heatmap&lt;/li&gt;
  &lt;li&gt;Can create networks using entity recognition&lt;/li&gt;
  &lt;li&gt;Can try examples in different setups, e.g. Binder, or do it all yourself.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-10&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Not much to say. Another tool that I now know about.&lt;/p&gt;

&lt;h2 id=&quot;1745-30-golden-rules-for-deep-learning-performance-siddha-ganju&quot;&gt;17:45, &lt;a href=&quot;https://ep2020.europython.eu/talks/30-golden-rules-deep-learning-performance/&quot;&gt;30 Golden Rules for Deep Learning Performance&lt;/a&gt;, Siddha Ganju&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-11&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Forbes 30 under 30!&lt;/li&gt;
  &lt;li&gt;Recommended &lt;a href=&quot;https://www.PracticalDeepLearning.ai&quot;&gt;book&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;95% of all AI Training is Transfer Learning
    &lt;ul&gt;
      &lt;li&gt;Playing melodica much easier if you already know how to play the piano&lt;/li&gt;
      &lt;li&gt;In Neural Network, earlier layers contains generic knowledge, and later layers contain task specific knowledge - at least in CNNs&lt;/li&gt;
      &lt;li&gt;So remove last ‘classifier layers’, and classify on new task, keeping first layers as is.&lt;/li&gt;
      &lt;li&gt;See github PracticalDL for examples and runnable scripts* Optimising hardware use.&lt;/li&gt;
      &lt;li&gt;In standard process, CPU and GPU switch between being idle or active.&lt;/li&gt;
      &lt;li&gt;Use a profiler. E.g. TensorFlow Profiler + TensorBoard&lt;/li&gt;
      &lt;li&gt;Example code shown to use profiler.&lt;/li&gt;
      &lt;li&gt;Simpler: nvidia-smi.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We have thing we want to optimise and metric. So how can we optimise. Here comes the 30 rules.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;DATA PROCESSING&lt;/li&gt;
  &lt;li&gt;Use TFRecords
    &lt;ul&gt;
      &lt;li&gt;Anti-pattern: thousands of tiny files/gigantic file.&lt;/li&gt;
      &lt;li&gt;Better to have handful for large files.&lt;/li&gt;
      &lt;li&gt;Sweet spot: 100MB TFRecord files&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reduce size of input data
    &lt;ul&gt;
      &lt;li&gt;Bad: read image, rezie, train. Then iterate&lt;/li&gt;
      &lt;li&gt;Good: read all images, resizes, save as TFRecord. Then read and train - iterating as appropriate.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use TensorFlow Datasets
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;import tensorflow_datasets as tfds&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;If you have new datasets, publish your data on TensorFlow datasets, so people can build on your research.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use tf.data pipeline
    &lt;ul&gt;
      &lt;li&gt;Example code given&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Prefetch data
    &lt;ul&gt;
      &lt;li&gt;Somehow breaks circular dependency, where CPU has to wait for GPU and vice versa.&lt;/li&gt;
      &lt;li&gt;Does asynchronous stuff&lt;/li&gt;
      &lt;li&gt;Code given in talk&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Parallelize CPU processing.
    &lt;ul&gt;
      &lt;li&gt;same as number of cpu cores&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Paralleize input and output. interleaving.&lt;/li&gt;
  &lt;li&gt;Non-deterministic ordering. If randomising, forget ordering.
    &lt;ul&gt;
      &lt;li&gt;Somehow, not reading files ‘in order’ avoids potential bottlenecks.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cache data
    &lt;ul&gt;
      &lt;li&gt;Avoid repeated reading from disk after first epoch&lt;/li&gt;
      &lt;li&gt;Avoid repeatedly resizing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Turn on experimental optimisations&lt;/li&gt;
  &lt;li&gt;Autotune parameter values. code given in talk. Seems to refer to hardware based parameters&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Slide showing it all combined.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;DATA AUGMENTATION&lt;/li&gt;
  &lt;li&gt;Use GPU for augmentation, with tf.image
    &lt;ul&gt;
      &lt;li&gt;Still work in progress. Limited functionality. Only rotate by 90 degrees as of now.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use GPU with NVIDIA DALI&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;TRAINING&lt;/li&gt;
  &lt;li&gt;Use automatic mixed precision.
    &lt;ul&gt;
      &lt;li&gt;Using 8-bit or 16-bit encodings rather than 32 or 64-bit.&lt;/li&gt;
      &lt;li&gt;Caveat - fp.16 can cause drop in accuracy, and even loss of convergence. E.g. if gradient is tiny, fp.16 will treat it as zero.&lt;/li&gt;
      &lt;li&gt;auto mixed precision somehow deals with this issue&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use larger batch size.
    &lt;ul&gt;
      &lt;li&gt;Larger batch size leads to smaller time per epoch (but less steps per epoch too, no?)&lt;/li&gt;
      &lt;li&gt;Larger batch size leads to greater GPU utilization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use batch szies that are multiples of eight. Big jump in performance from 4095 to 4096!
    &lt;ul&gt;
      &lt;li&gt;Video describes other restrictions/options&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Finding optimal learning rate
    &lt;ul&gt;
      &lt;li&gt;Use keras_lr_finder&lt;/li&gt;
      &lt;li&gt;‘point of greatest decrease in loss’ corresponds to best learning rate, somehow. Leslie N Smith paper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use tf.function
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@tf.function&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Overtrain, then generalise. STart from from dataset and increase.&lt;/li&gt;
  &lt;li&gt;Install optimised stack&lt;/li&gt;
  &lt;li&gt;Optimise number of parallel threads&lt;/li&gt;
  &lt;li&gt;Use better hardware.&lt;/li&gt;
  &lt;li&gt;Distribute training. MirroredStrat vs Multiworker…&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look at industiral benchmarks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;INFERENCE
    &lt;ul&gt;
      &lt;li&gt;Use an efficient model. Fewer weights.&lt;/li&gt;
      &lt;li&gt;Quantize. 16 to 8bit.&lt;/li&gt;
      &lt;li&gt;Prune model, remove weights close to zero&lt;/li&gt;
      &lt;li&gt;Used fused operations&lt;/li&gt;
      &lt;li&gt;Enable GPU persistence&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-11&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Very handy list of tips and tricks. Sevreal of them go beyond my understanding, but does not mean I can not benefit from using them!&lt;/p&gt;

&lt;h2 id=&quot;1900-analytical-functions-in-sql-brendan-tierney&quot;&gt;19:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/AWFiM7F-sql-for-data-science-using-analytical-function/&quot;&gt;Analytical Functions in SQL&lt;/a&gt;, Brendan Tierney&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-12&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TALK CANCELLED&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-12&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Not applicable&lt;/p&gt;

&lt;h2 id=&quot;1930-collaborative-data-pipelines-with-kedro-tam-sanh-nguyen&quot;&gt;19:30, &lt;a href=&quot;https://ep2020.europython.eu/talks/45GhXwE-writing-and-scaling-collaborative-data-pipelines-with-kedro/&quot;&gt;Collaborative data pipelines with Kedro&lt;/a&gt;, Tam-Sanh Nguyen&lt;/h2&gt;

&lt;h3 id=&quot;notes-from-talk-13&quot;&gt;Notes from talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Apparently 40% of Vietnamese have surname Nguyen.&lt;/li&gt;
  &lt;li&gt;Data engineering is relatively new discipline, so there aren’t established practices.&lt;/li&gt;
  &lt;li&gt;QuantumBlack addressed this issue with Kedro.&lt;/li&gt;
  &lt;li&gt;Pipelines.
    &lt;ul&gt;
      &lt;li&gt;Kedro viz used to visualise messy data pipeline.&lt;/li&gt;
      &lt;li&gt;But how does it get there?&lt;/li&gt;
      &lt;li&gt;Starts off simple. Iris data -&amp;gt; cleaning function, cleaned data, analyze function, analyzed data.&lt;/li&gt;
      &lt;li&gt;But then splitting data to test/train, gets messy.&lt;/li&gt;
      &lt;li&gt;Then have multiple data sources, each which needs to be split, and then all jumbled up&lt;/li&gt;
      &lt;li&gt;Without any tools, hard to grow larger and more complex than this.&lt;/li&gt;
      &lt;li&gt;But Kedro can allow you to deal with more complex pipelines.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One source of tension is difference between data engineer and data science
    &lt;ul&gt;
      &lt;li&gt;Data science usually have strong engineering skills. More data modelling skills&lt;/li&gt;
      &lt;li&gt;Data science has more research bent / experimental bent / want to be close to data and have many iterations&lt;/li&gt;
      &lt;li&gt;Data engineers more like engineers. Focus is on making things tidy, rather than experimentation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Two other challenges
    &lt;ul&gt;
      &lt;li&gt;Being ready for production quickly, for business use&lt;/li&gt;
      &lt;li&gt;Is it easy to pass the pipeline to future users - which may even be the future you!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;QuantumBlack startup from London, famous for doing work on F1. Got bought by McKinsey&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kedro made by QuantumBlack. Big focus on standardisation, and making it as easy as possible for long-term use.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;How does Kedro work&lt;/li&gt;
  &lt;li&gt;Analogy - audio world has standardised:
    &lt;ul&gt;
      &lt;li&gt;Input and output tools. Microphones, speakers, etc.&lt;/li&gt;
      &lt;li&gt;Functional transformers. Filters, etc.&lt;/li&gt;
      &lt;li&gt;Redirecting components. Make it easy for output from one tool easy to input into others.&lt;/li&gt;
      &lt;li&gt;Standard organisational conventions. Mic, audio mixer, computer.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Standard is to use jupyter notebook. Some conventions (e.g. inputs and outputs via &lt;code class=&quot;highlighter-rouge&quot;&gt;pd.read_csv&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pd.to_csv&lt;/code&gt;), but mostly hard to follow. E.g. many many parameters is hard-coded, e.g. names of files being saved, parameters throughout processing, etc.&lt;/li&gt;
  &lt;li&gt;Live example:
    &lt;ul&gt;
      &lt;li&gt;install kedro&lt;/li&gt;
      &lt;li&gt;kedro new. follow steps, e.g. naming things, etc.&lt;/li&gt;
      &lt;li&gt;created default template&lt;/li&gt;
      &lt;li&gt;kedro viz to visualise pipeline&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Run out of time, so rushes through lots of kedro features&lt;/li&gt;
  &lt;li&gt;Has YouTube series DataEngineerOne&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-13&quot;&gt;My thoughts&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Looks like an intuitive system. Looks simpler than other pipelines presented in the conference. But is it because it actually is simpler, or is it because I am just getting used to pipelines. (Before this conference, I hadn’t studied pipelines at all).&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Other posts in series EuroPython Conference 2020, Summary EuroPython Conference 2020, Day 1</summary></entry><entry><title type="html">EuroPython Conference 2020, Day 1</title><link href="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/23/europython1.html" rel="alternate" type="text/html" title="EuroPython Conference 2020, Day 1" /><published>2020-07-23T00:00:00-05:00</published><updated>2020-07-23T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/23/europython1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/conference/2020/07/23/europython1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/26/europython3.html&quot;&gt;EuroPython Conference 2020, Summary&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/conference/2020/07/24/europython2.html&quot;&gt;EuroPython Conference 2020, Day 2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I am attending the online conference &lt;a href=&quot;https://ep2020.europython.eu/&quot;&gt;EuroPython 2020&lt;/a&gt;, and I thought it would be good to record what my thoughts and the things I learn the talks.&lt;/p&gt;

&lt;h2 id=&quot;0800-waking-up&quot;&gt;08:00, Waking up&lt;/h2&gt;
&lt;p&gt;I struggled to wake up in time, for two main reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For the past several months, I have had no need to wake up early, and so my standard wake up time has been 9am.&lt;/li&gt;
  &lt;li&gt;I stayed up until 2am watching Round 2 of the &lt;a href=&quot;https://www.youtube.com/watch?v=CDZJynwAIV4&quot;&gt;Legends of Chess&lt;/a&gt; tournament…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But I managed! I then got onto the Discord server to get to the first keynote talk, &lt;a href=&quot;https://ep2020.europython.eu/talks/30-golden-rules-deep-learning-performance/&quot;&gt;30 Golden Rules of Deep Learning Performance&lt;/a&gt;, which sounds like it would be particularly insightful. But, unfortunately, the speaker could not give the talk so it was cancelled. At least it gives me time to get &lt;a href=&quot;www.huel.com&quot;&gt;breakfast&lt;/a&gt;!&lt;/p&gt;

&lt;h2 id=&quot;0900-docker-and-python-tania-allard&quot;&gt;09:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/4bVczWt-docker-and-python-making-them-play-nicely-and-securely-for-data-science-and-ml/&quot;&gt;Docker and Python&lt;/a&gt;, Tania Allard&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Why use Docker? Without Docker, hard to share your models because hard to make sure everyone is using the same modules/appropriate versions of packages.&lt;/li&gt;
  &lt;li&gt;What is Docker? Helps you solve this issue with ‘containers’. Bundles together the application and all packages/requirements.&lt;/li&gt;
  &lt;li&gt;Difference to virtual machines: Each application has its own container in Docker, which is small and efficient, whereas virutal machine is highly bloated as each applications is grouped with whole OS and unnecessary extra baggage.&lt;/li&gt;
  &lt;li&gt;Image - an archive with all the data need to run the app. Running an image creates a container.&lt;/li&gt;
  &lt;li&gt;Common challanges in DS:
    &lt;ul&gt;
      &lt;li&gt;Complex setups/dependencies, reliance on data, highly iterative/fast workflow, docker can be hard to learn.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Describes differences to web apps&lt;/li&gt;
  &lt;li&gt;Building docker images. Tania had many struggles/frustrations to learn Docker.
    &lt;ul&gt;
      &lt;li&gt;Many bad examples online/in tutorials.&lt;/li&gt;
      &lt;li&gt;If building from scratch, use official Python images, and the slim versions.&lt;/li&gt;
      &lt;li&gt;If not building from scratch (highly recommended), use Jupyter Docker stacks.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Best practices:
    &lt;ul&gt;
      &lt;li&gt;Be explicit about packages. Avoid ‘latest’ or ‘python 3’.&lt;/li&gt;
      &lt;li&gt;Add security context. LABEL securitytxt=’…’. E.g. snake.&lt;/li&gt;
      &lt;li&gt;Split complex run statements&lt;/li&gt;
      &lt;li&gt;Prefer Copy to Add&lt;/li&gt;
      &lt;li&gt;Leverage cache
        &lt;ul&gt;
          &lt;li&gt;Clean, e.g. conda clean&lt;/li&gt;
          &lt;li&gt;Only use necessary packages&lt;/li&gt;
          &lt;li&gt;Use Docker ignore (similar to .gitignore)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Minimise privilege.
        &lt;ul&gt;
          &lt;li&gt;Run as non-root user. Dockers runs as root by default&lt;/li&gt;
          &lt;li&gt;Minimise capabilities user&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Avoid leak sensitive information
        &lt;ul&gt;
          &lt;li&gt;Information in middle ‘layers’ may appear hidden, but there are tools to find them.&lt;/li&gt;
          &lt;li&gt;Use multi-stage builds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;This can be overwhelming, and that is normal. Try to automate and avoid re-inventing the wheel.
    &lt;ul&gt;
      &lt;li&gt;Use standard project template, e.g., cookie cutter data science.&lt;/li&gt;
      &lt;li&gt;Use tools like repo2docker. &lt;code class=&quot;highlighter-rouge&quot;&gt;conda instal jupyter repo2docker&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;jupyter-repo2docker &quot;.&quot;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Re-run docker image regularly. One benefit is making sure you have latest security patches. Don’t do this manually, use GitHub Actions or Travis, for example.&lt;/li&gt;
  &lt;li&gt;Top top tips:
    &lt;ul&gt;
      &lt;li&gt;Rebuild images frequently. Get security updates.&lt;/li&gt;
      &lt;li&gt;Do not work as root/minimise privileges&lt;/li&gt;
      &lt;li&gt;Don’t use Alpine Linux. You are paying price for small size. Use buster, stretch, or Jupyter stack.&lt;/li&gt;
      &lt;li&gt;Be explicit about what packages you are require, version EVERYTHING.&lt;/li&gt;
      &lt;li&gt;Leverage build cache. Separate tasks, so you do not need to rebuild whole image for small change.&lt;/li&gt;
      &lt;li&gt;Use one dockerfile per project&lt;/li&gt;
      &lt;li&gt;Use multi-stage builds.
f   * Make images identifiable&lt;/li&gt;
      &lt;li&gt;Use repo2docker&lt;/li&gt;
      &lt;li&gt;Automate. Do not build/push manually&lt;/li&gt;
      &lt;li&gt;Use a linter. E.g. VSCode has docker extension&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;A lot of this went over my head. The main lesson I learnt is that I should expect things to be tricky when I eventually do start using Docker. I will refer back to this video when I do start using Docker.&lt;/p&gt;

&lt;h2 id=&quot;1000-spacy-alexander-hendorf&quot;&gt;10:00 &lt;a href=&quot;https://ep2020.europython.eu/talks/7TXpVro-15-things-you-should-know-about-spacy/&quot;&gt;spaCy&lt;/a&gt;, Alexander Hendorf&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-1&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;NLP: avalanche of unstructured data&lt;/li&gt;
  &lt;li&gt;Estimate 20:80 split between structured and unstructured ata&lt;/li&gt;
  &lt;li&gt;Examples of NLP: chatbots, translation, sentiment analysis, speech-to-texxt or vice versa, spelling/grammar, text completion (&lt;a href=&quot;https://github.com/openai/gpt-3&quot;&gt;GPT-3&lt;/a&gt;! :D)&lt;/li&gt;
  &lt;li&gt;Example of Alexander’s work: certain group had large number of documents and search engine was not helping them. Used NLP to create clusters of documnets, create keywords, create summaries.&lt;/li&gt;
  &lt;li&gt;spaCy. Open source library for NLP, comes with pretrained language models, fast and efficient, designed for production usage, lots of out-of-the-box support.&lt;/li&gt;
  &lt;li&gt;Building blocks of spaCy
    &lt;ul&gt;
      &lt;li&gt;Tokenization&lt;/li&gt;
      &lt;li&gt;Part of speech tagging. E.g. which words are nouns or verbs, etc.&lt;/li&gt;
      &lt;li&gt;Lemmatization. cats-&amp;gt;cat&lt;/li&gt;
      &lt;li&gt;Sentence boundary detection&lt;/li&gt;
      &lt;li&gt;Named Entity Recognition. (Apple -&amp;gt; company). Depends on context!&lt;/li&gt;
      &lt;li&gt;Serialization. saving&lt;/li&gt;
      &lt;li&gt;Dependency parsing. How different tokens depend on each other&lt;/li&gt;
      &lt;li&gt;Entity linking&lt;/li&gt;
      &lt;li&gt;Training. Updating models&lt;/li&gt;
      &lt;li&gt;Text classification&lt;/li&gt;
      &lt;li&gt;Rule-based matching&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Built-in rules
    &lt;ul&gt;
      &lt;li&gt;Rules for specific languages, e.g., adding ‘s’ to end of noun makes it plural in English.&lt;/li&gt;
      &lt;li&gt;Usually does not cover many exceptions&lt;/li&gt;
      &lt;li&gt;Most languages won’t be supported. Most research done on English.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Built-in models
    &lt;ul&gt;
      &lt;li&gt;Language models. E.g. word vectors&lt;/li&gt;
      &lt;li&gt;Can train your own models with nlp.update()&lt;/li&gt;
      &lt;li&gt;Need a lot of data to train these models. Few documents is not enough&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;spaCy is pythonic
    &lt;ul&gt;
      &lt;li&gt;should understand objects, iterations, comprehensions, classes, methods&lt;/li&gt;
      &lt;li&gt;Might be overwhelming, but not as overwhelming as Pandas yet!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pipelines
    &lt;ul&gt;
      &lt;li&gt;Has nice image in slides&lt;/li&gt;
      &lt;li&gt;default pipline: tokenize, tag, parse, then your own stuff&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Visualisation
    &lt;ul&gt;
      &lt;li&gt;used to be separate package displacy&lt;/li&gt;
      &lt;li&gt;visualisation of sentence grammar/dependencies&lt;/li&gt;
      &lt;li&gt;visualise entities. e.g. given sentence, highlight grouping of nounes. e.g. is a word a person, or a date, or an animal, or…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Serialization
    &lt;ul&gt;
      &lt;li&gt;uses pickle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Danger zones
    &lt;ul&gt;
      &lt;li&gt;Privacy, bias, law, language is not fixed in stone&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Can’t do all languages&lt;/li&gt;
  &lt;li&gt;Extensions
    &lt;ul&gt;
      &lt;li&gt;spaCy universe&lt;/li&gt;
      &lt;li&gt;E.g. NeuralCoref.  Matching up ‘Angela Merkel’ and ‘chancellor’ recognised as same person.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bugs
    &lt;ul&gt;
      &lt;li&gt;spaCy will maintained, and quick response to bug reports&lt;/li&gt;
      &lt;li&gt;Extensions more variable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Status
    &lt;ul&gt;
      &lt;li&gt;Other options: NLTK, Gensin, TextBlob, Pattern&lt;/li&gt;
      &lt;li&gt;spaCy: usually close to the state of the art, especially for language models, flexible, extendable via spacy universe, fast (powered by cython)&lt;/li&gt;
      &lt;li&gt;For special cases, probably use other models. E.g. RASA for contextual textbots&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-1&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;I have not yet done any NLP, but when I do, I will be sure to look into spaCy after this talk!&lt;/p&gt;

&lt;h2 id=&quot;1030-differential-privacy-naoise-holohan&quot;&gt;10:30 &lt;a href=&quot;https://ep2020.europython.eu/talks/6Js4E4r-diffprivlib-privacy-preserving-machine-learning-with-scikit-learn/&quot;&gt;Differential Privacy&lt;/a&gt;, Naoise Holohan&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-2&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Many examples where ‘anonymised’ but actually could still identify individuals by matching data with other data publically available.
    &lt;ul&gt;
      &lt;li&gt;Netflix data. Matched with imdb databse&lt;/li&gt;
      &lt;li&gt;AOL data. NYT managed to identify individual and make available their full search&lt;/li&gt;
      &lt;li&gt;Limosine service. Person matched it with images of celebrities, and managed to find out about individuals use of taxis/limos&lt;/li&gt;
      &lt;li&gt;Many other examples out there.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Differential privacy. Main idea: blur noise.&lt;/li&gt;
  &lt;li&gt;Implemented in diffprivlib, for scikit learn.&lt;/li&gt;
  &lt;li&gt;Modules
    &lt;ul&gt;
      &lt;li&gt;Mechanisms. Algorithms to add noise&lt;/li&gt;
      &lt;li&gt;Models. Has scikit learn equivalents as its parent class&lt;/li&gt;
      &lt;li&gt;Tools. Analogue for NumPy.&lt;/li&gt;
      &lt;li&gt;Accountant. Track privacy budget. Help optimise balance between accuracy and privacy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Examples
    &lt;ul&gt;
      &lt;li&gt;Gives warning for privacy leakage with certain bound is not specified. If bound is not specified, then original dataset is used to estimate the parameter!&lt;/li&gt;
      &lt;li&gt;Pipelines. With and without privacy.
        &lt;ul&gt;
          &lt;li&gt;Without, got 80.3% accuracy&lt;/li&gt;
          &lt;li&gt;With, got 80.7% accuracy! Adding noise can actually reduce over-fitting. !!&lt;/li&gt;
          &lt;li&gt;Graph of epsilon vs accuracy. Low epsilon highly variable performance. Higher epsilon tends to 80% baseline&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Some exploratory data analysis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-2&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;I have actually heard of differential privacy before, via &lt;a href=&quot;https://www.youtube.com/watch?v=bScJdHX0Hac&quot;&gt;this talk&lt;/a&gt; from &lt;a href=&quot;https://faculty.ai/&quot;&gt;FacultyAI&lt;/a&gt;. To anybody interested in this topic, I recommend watching the FacultyAI talk for more background on differential privacy itself.&lt;/p&gt;

&lt;p&gt;Main lesson here is that if I want to analyse sensitive data, diffprivlib is a good open source option.&lt;/p&gt;

&lt;p&gt;The big surprise factor was that the accuracy can sometimes be better after adding privacy! Adding noise can reduce over-fitting.&lt;/p&gt;

&lt;h2 id=&quot;1215-parallel-and-asynchronous-programming-in-ds-chin-hwee-ong&quot;&gt;12:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/8DboZjY-speed-up-your-data-processing/&quot;&gt;Parallel and Asynchronous Programming in DS&lt;/a&gt;, Chin Hwee Ong&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-3&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background. Engineer at ST Engineering. Background in aerospace engineer and modelling. Contributor to pandas. Mentor at BigDataX.&lt;/li&gt;
  &lt;li&gt;Typical flow: extract raw data, process data, train model, evaluate and deploy model.&lt;/li&gt;
  &lt;li&gt;Bottlenecks in real world
    &lt;ul&gt;
      &lt;li&gt;Lack of data. Poor quality data&lt;/li&gt;
      &lt;li&gt;Data processing. 80/20 dilemma. More like 90/10!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data processing in python
    &lt;ul&gt;
      &lt;li&gt;For loops, &lt;code class=&quot;highlighter-rouge&quot;&gt;list = [], for i in range(100), list.append(i*i)&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;This is slow!&lt;/li&gt;
      &lt;li&gt;Comprehensions. &lt;code class=&quot;highlighter-rouge&quot;&gt;list = [i*i for i in range(100)]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Slightly better. No need to call append on each iteration&lt;/li&gt;
      &lt;li&gt;Pandas, optimised for in-memory analytics. But get performance issues when dealing with large datasets, e.g. 1&amp;gt;GB. Particularly in 100GB plus range.&lt;/li&gt;
      &lt;li&gt;Why not just use spark? Overhead cost of communication. Need very big data for this to be worthwhile. What to do in ‘small big data’?&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Small Big Data Manifesto&lt;/em&gt; by Itamar Turner-Trauring&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Parallel processing
    &lt;ul&gt;
      &lt;li&gt;Analogy: preparing toast.&lt;/li&gt;
      &lt;li&gt;Traditional breakfast in Singapore is tea, toast and egg&lt;/li&gt;
      &lt;li&gt;Sequential processing: one single-slice toaster&lt;/li&gt;
      &lt;li&gt;Parallel processing: four single-slice toaster. Each toaster is independent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Synchronous vs asynchronous
    &lt;ul&gt;
      &lt;li&gt;Analogy: also want coffee. Assume it takes 5 mins for each coffee, 2 mins for single toaster.&lt;/li&gt;
      &lt;li&gt;Synchronous execution: first make coffee, and then make toast.&lt;/li&gt;
      &lt;li&gt;Asynchronous: make coffee and toast at the same time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical considerations
    &lt;ul&gt;
      &lt;li&gt;Parellelism sounds great. Get mega time savings&lt;/li&gt;
      &lt;li&gt;Is code already optimised? Using loops instead of array operations&lt;/li&gt;
      &lt;li&gt;Problem architecture. If many tasks depends on previous tasks being completed, parallelism isn’t great. Data dependency vs task dependency.&lt;/li&gt;
      &lt;li&gt;Overhead costs. Limit to parallelisation. Amdahl’s.&lt;/li&gt;
      &lt;li&gt;Multi processing vs multi threading&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In python
    &lt;ul&gt;
      &lt;li&gt;concurrent.futures module&lt;/li&gt;
      &lt;li&gt;ProcessPoolExecutor vs ThreadPoolExecutor.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Example
    &lt;ul&gt;
      &lt;li&gt;Obtaining data from API. JSON data. 20x speed up versus list comprehension.&lt;/li&gt;
      &lt;li&gt;Rescaling x-ray images. map gives 40 seconds. list comprehension 24 seconds. ProcessPoolExecutor about 7s with 8 cores.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Takeaways
    &lt;ul&gt;
      &lt;li&gt;Not all processes should be parallelized. Amdahl’s law, system overhead, cost of re-writing code.&lt;/li&gt;
      &lt;li&gt;Don’t use for loops!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-3&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Something for me to investigate. I have not needed to use this yet. Nice bonus - I learnt about Singaporean breakfasts!&lt;/p&gt;

&lt;h2 id=&quot;1245-automate-nlp-model-deployment-william-arias&quot;&gt;12:45, &lt;a href=&quot;https://ep2020.europython.eu/talks/5hXHveq-deploy-your-machine-learning-bots-like-a-boss-with-cicd/&quot;&gt;Automate NLP model deployment&lt;/a&gt;, William Arias&lt;/h2&gt;
&lt;h3 id=&quot;notes-of-the-talk-4&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background. Colombian, lives in Prague. Works at GitLab&lt;/li&gt;
  &lt;li&gt;Often, data scientists are a one-person band. Have to do learn many different tool.&lt;/li&gt;
  &lt;li&gt;Define a symphony. Produce flowchart of data workflow. Make explicit where different people can/should contribute to process.
    &lt;ul&gt;
      &lt;li&gt;Favour for yourself&lt;/li&gt;
      &lt;li&gt;Makes easier for everyone to understand process&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Symphony components.
&lt;img src=&quot;/blog/images/europython_arias1.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;I found it hard to follow details here. I’d have to re-watch the video.&lt;/li&gt;
  &lt;li&gt;This might be standard knowlege for people who already work in software engineering. But somebody with maths background, say, this kind of automation and workflow is not obvious.&lt;/li&gt;
  &lt;li&gt;This will make your life easier!&lt;/li&gt;
  &lt;li&gt;Has video showing example of making small change to chat bot, and how much is automated.&lt;/li&gt;
  &lt;li&gt;See examples on &lt;a href=&quot;https://gitlab.com/warias/pycon2020&quot;&gt;github&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-4&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Probably too advanced for me at this stage. But, something I should be aware of when I work on bigger projects.&lt;/p&gt;

&lt;h2 id=&quot;1315-building-models-with-no-expertise-with-automl-laurent-picard&quot;&gt;13:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/C8WFfBR-building-smarter-solutions-with-no-expertise-in-machine-learning/&quot;&gt;Building models with no expertise with AutoML&lt;/a&gt;, Laurent Picard&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-5&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background, French, ebook pioneer, cofounder of bookeen&lt;/li&gt;
  &lt;li&gt;Their definition of ML: given data, extract data.&lt;/li&gt;
  &lt;li&gt;Correct definition: AI contains machine learning contains deep learning.&lt;/li&gt;
  &lt;li&gt;Graph showing increase of ‘Brain Model’ at Google. Number of directories using it. At 7000 around 2017.&lt;/li&gt;
  &lt;li&gt;AutoML - somewhere between ML APIs (developer skills) and ML (machine learning skills).&lt;/li&gt;
  &lt;li&gt;Ready-to-use models.&lt;/li&gt;
  &lt;li&gt;Vision API. Laurent in 90s tried to detect edges, and it was very hard.
    &lt;ul&gt;
      &lt;li&gt;Label detection. What is in picture?&lt;/li&gt;
      &lt;li&gt;Locate picture by matching with google’s database&lt;/li&gt;
      &lt;li&gt;Bounding boxes for objects in the picture, e.g. box for trousers, box for person&lt;/li&gt;
      &lt;li&gt;Face detection. Emotion prediction.&lt;/li&gt;
      &lt;li&gt;Text detection. Identify blocks of text. Works even if image is slanted.&lt;/li&gt;
      &lt;li&gt;Hand-writing detection. Not as good as text detection (obviously), but still good.&lt;/li&gt;
      &lt;li&gt;Web entity detection/image matching. Identify source of image, identify topic of image. E.g. picture of Tolkien identified as Tolkien and its source found.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;from google.cloud import vision&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Video intelligence
    &lt;ul&gt;
      &lt;li&gt;Apply image analysis to each frame&lt;/li&gt;
      &lt;li&gt;from google.cloud import videointelligence&lt;/li&gt;
      &lt;li&gt;codelabs.developers.google.com/codelabs/cloud-video-intelligence-python3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;NLP
    &lt;ul&gt;
      &lt;li&gt;Syntax analysis. Language detection, syntax analysis (dependency, grammar, etc.)&lt;/li&gt;
      &lt;li&gt;Entity detection. Understands context. Given match, gives unique id and wikipedia link!&lt;/li&gt;
      &lt;li&gt;Content classification.&lt;/li&gt;
      &lt;li&gt;Sentiment analysis. E.g helps company judge how people are talking about their service or product.&lt;/li&gt;
      &lt;li&gt;Tutorials available on codelabs&lt;/li&gt;
      &lt;li&gt;Translation API.&lt;/li&gt;
      &lt;li&gt;Speech-to-text API&lt;/li&gt;
      &lt;li&gt;Speech timestamps. Given script and audio, attach&lt;/li&gt;
      &lt;li&gt;Text-to-speech. WaveNet by DeepMind&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cloud AutomL
    &lt;ul&gt;
      &lt;li&gt;You provide data. AutoML does training, deployment and serving&lt;/li&gt;
      &lt;li&gt;Can create your own API for cloud model&lt;/li&gt;
      &lt;li&gt;For offline, can get TF Lite model for mobile, TF model for browser, or container for anywhere.&lt;/li&gt;
      &lt;li&gt;Example of identifying between different types of clouds. Upload around thousand images. Can specify computer hours and visualise results.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-5&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Not sure what my takeaway message is here. Looks like a useful and easy to use set of tools. But not sure when I will use it given that I am aiming to become a data scientist.&lt;/p&gt;

&lt;h2 id=&quot;1415-simulating-hours-of-robots-work-in-minutes-eran-friedman&quot;&gt;14:15, &lt;a href=&quot;https://ep2020.europython.eu/talks/9k2qHA7-boosting-simulation-performance-with-python/&quot;&gt;Simulating hours of robots’ work in minutes&lt;/a&gt;, Eran Friedman&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-6&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Works at Fabric. Helps develop ground robot.&lt;/li&gt;
  &lt;li&gt;SimPy library. Discreate event simulation&lt;/li&gt;
  &lt;li&gt;Three objects: environment, …&lt;/li&gt;
  &lt;li&gt;And I stopped taking notes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-6&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;I do not anticipate needing to know about simulations any time soon, and I am feeling exhausted from first several hours of talks, so I decided to take a break. SimPy looks cool, but not for me.&lt;/p&gt;

&lt;h2 id=&quot;1445-parallel-stream-processing-at-massive-scale-alejandro-saucedo&quot;&gt;14:45, &lt;a href=&quot;https://ep2020.europython.eu/talks/Ccb6D5Z-real-time-stream-processing-for-machine-learning-at-massive-scale/&quot;&gt;Parallel Stream Processing at Massive Scale&lt;/a&gt;, Alejandro Saucedo&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-7&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Chief Scientist at Institue for Ethical AI. Director at Seldon.&lt;/li&gt;
  &lt;li&gt;Realtime ML in today’s talk, conceptual intro to stream processing, tradeoffs in different tools, example case&lt;/li&gt;
  &lt;li&gt;Real-time ML model for reddit comments. To help automate comment moderation.&lt;/li&gt;
  &lt;li&gt;ETL, Extract Transform Load framework for data transformation. Batch processing. Variations: ETL, ELT, EL, LT. Many specialised tools. Image of about 40 different packages that deal with this.
    &lt;ul&gt;
      &lt;li&gt;EL, Nifi and Flume&lt;/li&gt;
      &lt;li&gt;ETL, Oozie, Airflow&lt;/li&gt;
      &lt;li&gt;ELT, Elasticsearch, Data Warehouse&lt;/li&gt;
      &lt;li&gt;Jupyter notebook?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Batch vs streaming
    &lt;ul&gt;
      &lt;li&gt;Data processed in batches. E.g. periodically&lt;/li&gt;
      &lt;li&gt;Stream processing. Process data as it comes in, each data entry at a time. Real time&lt;/li&gt;
      &lt;li&gt;In reality, have combination of the two. Rarely all or nothing.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stream concepts
    &lt;ul&gt;
      &lt;li&gt;Windows. Can have moving window or tumbling window&lt;/li&gt;
      &lt;li&gt;Checkpoints. Keep track of stream progress. Leads to other ideas, e.g. processing at most/at least once.&lt;/li&gt;
      &lt;li&gt;Water mark. Somehow allows you to deal with data that arrives later than is expected&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some tools. Flink, Kafka, Spark, Faust, Apache Beam, Seldon&lt;/li&gt;
  &lt;li&gt;Traditional ML workflow. Train a model on cleaning training data. Obtain ‘persisted’ model. Then get unseen data, and use model to make predictions.
    &lt;ul&gt;
      &lt;li&gt;Reddit example: clean text, spaCy tokenizer, TFIDF vectoriser, logistic regression.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;You are a DUMMY!!!!&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;You are dummy&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;[PRON, IS, DUMB]&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;[0010, 1000, 1100]&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt; (which equals moderated).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Stream-based workflow. Note that ‘core’ is part of Seldon.
&lt;img src=&quot;/blog/images/europython_2.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Gives example code in video for each step in workflow.&lt;/li&gt;
  &lt;li&gt;Seldon still developing service. Have open examples on github. They are open to feedback.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-7&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Good to learn about this newer workflow and the tools available for stream processing. Again, at this stage of my learning, I am unlikely to use the ideas directly any time soon, but it is good to have an awareness.&lt;/p&gt;

&lt;h2 id=&quot;1830-a-brief-history-of-jupyter-notebooks-william-horton&quot;&gt;18:30, &lt;a href=&quot;https://ep2020.europython.eu/talks/7UBMYed-a-brief-history-of-jupyter-notebooks/&quot;&gt;A Brief History of Jupyter Notebooks&lt;/a&gt;, William Horton&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-8&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Tension between traditional python IDE and jupyter notebooks
    &lt;ul&gt;
      &lt;li&gt;“I don’t like notebooks” - Joel Grus&lt;/li&gt;
      &lt;li&gt;First Notebook War, Martin Skarynski. Talk at PyData 2018&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Instead of arguing, lets understand the history. Better understanding as as result
    &lt;ul&gt;
      &lt;li&gt;No significant piece of software doesn’t come out of nowhere&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Long-term trends: scientific computing, literate programming, proprietary vs open source, python&lt;/li&gt;
  &lt;li&gt;Mathematica, 1988. By Stephen Wolfram. Theodore Gray created Notebook interface. Well received at the time.
    &lt;ul&gt;
      &lt;li&gt;Had two parts to notebooks. Kernel and front-end. Notebooks are objects in themselves that could be manipulated by mathematica.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Art of Computer Programming, by Knuth.
    &lt;ul&gt;
      &lt;li&gt;Literate programming. Implemented ‘WEB’ system.&lt;/li&gt;
      &lt;li&gt;TANGLE - generates compilable source code&lt;/li&gt;
      &lt;li&gt;WEAVE - generate formatted documentation&lt;/li&gt;
      &lt;li&gt;Used this idea to implement Tex!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Maple. In 1992, had ‘worksheet’ interface.&lt;/li&gt;
  &lt;li&gt;Maple, Mathematica.
    &lt;ul&gt;
      &lt;li&gt;Mathematical entry vs programming style entry, enter vs shift+enter, etc.&lt;/li&gt;
      &lt;li&gt;But both expensive and propritary&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Open source. SciPy, IPython and Matplotlib&lt;/li&gt;
  &lt;li&gt;Big name: Fernando Perez. Created IPython in 2001 as grad student.&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-8&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;I stopped taking notes, because I do not think I will need to refer back to this. Time to just enjoy the talk!&lt;/p&gt;

&lt;h2 id=&quot;1900-quickly-prototype-translation-from-scratch-and-serve-it-in-production-shreya-khurana&quot;&gt;19:00, &lt;a href=&quot;https://ep2020.europython.eu/talks/7W3cA68-train-serve-deploy-story-of-a-nlp-model-ft-pytorch-docker-uwsgi-and-nginx/&quot;&gt;Quickly prototype translation from scratch and serve it in production&lt;/a&gt;, Shreya Khurana&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-9&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background. Data Scientist at GoDaddy, deep learning NLP&lt;/li&gt;
  &lt;li&gt;Workflow in academia is different to business use. Deployment is whole extra part of the workflow.&lt;/li&gt;
  &lt;li&gt;Lots of new tools that you wouldn’t be familiar with from just training models.&lt;/li&gt;
  &lt;li&gt;Example: seq2seq model i.e. translation. E.g. german sentence to english sentence.
    &lt;ul&gt;
      &lt;li&gt;Small dataset from TedTalk transcripts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Fairseq. Used for preprocessing, training, model serving. In some unknown language - shell script?&lt;/li&gt;
  &lt;li&gt;Flask. Tool to create API. Development server. Example code given in talk.&lt;/li&gt;
  &lt;li&gt;uwsgi. Helps make Flask app secure / ready for production. There is uwsgi.ini file to configure stuff.&lt;/li&gt;
  &lt;li&gt;nginx. (pronounced ‘engine-x’). Idea of QPS - queries per second. Make sure all requests are appropriately routed to server. Unknown language for nginx.&lt;/li&gt;
  &lt;li&gt;supervisord. coordinates nginx and uwsgi.&lt;/li&gt;
  &lt;li&gt;Docker. The above system has many dependencies. Docker creates containers where you can isolate all the requirements and programs, which can loaded up and run remotely.&lt;/li&gt;
  &lt;li&gt;General good practice: check logs frequently, caching, unit tests.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-9&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;A lot of useful information here. I will be returning to this when I have to put a model into production.&lt;/p&gt;

&lt;h2 id=&quot;1930-painless-machine-learning-in-production-chase-stevens&quot;&gt;19:30, &lt;a href=&quot;https://ep2020.europython.eu/talks/3iErRxw-painless-machine-learning-in-production/&quot;&gt;Painless Machine Learning in Production&lt;/a&gt;, Chase Stevens&lt;/h2&gt;

&lt;h3 id=&quot;notes-of-the-talk-10&quot;&gt;Notes of the talk&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Background. Works for teikametrics&lt;/li&gt;
  &lt;li&gt;Focus on production, not on machine learning. Model building is relatively mature, but still need lots of work on improving production.&lt;/li&gt;
  &lt;li&gt;Goal of teikametrics - helps online e-commerce businesses.&lt;/li&gt;
  &lt;li&gt;Motivation: Ops is intrinsic to ML, ‘MLOps’ is unsustainable (where data scientists pass their models to software engineers). Conclusion: data scientists need to productionise their own models. But data scientists want to do data science. Hence, need tooling and services to make it easier as possible.&lt;/li&gt;
  &lt;li&gt;Looked for services to do full cycle (preprocess, train, evaluate, deploy, repeat), but couldn’t find any.&lt;/li&gt;
  &lt;li&gt;Interesting graph showing how AUC drops for models over time. Models need to be re-trained! Another example of how covid makes models from 2019 almost useless.&lt;/li&gt;
  &lt;li&gt;Different clients will have different markets which require different models.&lt;/li&gt;
  &lt;li&gt;Previous two points show importance of having efficient workflow and cycle.&lt;/li&gt;
  &lt;li&gt;MLOps is unsustainbly
    &lt;ul&gt;
      &lt;li&gt;Brief history of programming. Punch cards programmers separate from people who run programs, changes with terminal, late 90s, programmers separate from quality assurance and release team, rise of devops.&lt;/li&gt;
      &lt;li&gt;MLOps is making similar mistakes of past. Lots of slow back and forth between data scientists and production team.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Modern experience at tiekametrics.
    &lt;ul&gt;
      &lt;li&gt;Use cookiecutter on their sagemaker-framework. Asked a bunch of questions, which after answering, get repo made with good structure built in.&lt;/li&gt;
      &lt;li&gt;Define preprocessing function (SQL, Pandas), define train and validation training sets and model, define model loading function.&lt;/li&gt;
      &lt;li&gt;Various details skimmed over. E.g. need to update config file.&lt;/li&gt;
      &lt;li&gt;Whole list of tasks that care standardised and made easy. See talk for list.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Their stack:
&lt;img src=&quot;/blog/images/europython_3.png&quot; alt=&quot;image&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Various details given in talk&lt;/li&gt;
  &lt;li&gt;Big lesson. Do this! Big savings. Even little things: example of automating process of choosing which AWS instance to use.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-thoughts-10&quot;&gt;My thoughts&lt;/h3&gt;
&lt;p&gt;Another useful set of resources and examples I can use as a reference if/when I need to make production based decisions.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series EuroPython Conference 2020, Summary EuroPython Conference 2020, Day 2</summary></entry><entry><title type="html">Santander Dataset, Part III, Learning from others</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/07/18/santander3.html" rel="alternate" type="text/html" title="Santander Dataset, Part III, Learning from others" /><published>2020-07-18T00:00:00-05:00</published><updated>2020-07-18T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/07/18/santander3</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/07/18/santander3.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/07/13/santander2.html&quot;&gt;Santander Dataset, Part II, Feature Selection&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/07/01/santander1.html&quot;&gt;Santander Dataset, Part I&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I did some hyper-parameter optimisations, but there was nothing particularly noteworthy. I got some incremental improvements using GridSearch and that’s about it. After that, I had a look at what other people on Kaggle did and see what I can learn from them.&lt;/p&gt;

&lt;h2 id=&quot;read-the-instructions&quot;&gt;Read the instructions!&lt;/h2&gt;
&lt;p&gt;For some reason, I thought that the metric for this contest was accuracy? I suspect it is because I had read this line from the instructions: “For each Id in the test set, you must make a binary prediction of the target variable.” However, other people were submitting probabilities, not just binary predictions. So, I tried submitting the raw probabilities from my model, and the score jumped up from around 0.77 to 0.86! Something is a amiss. Have I misunderstood accuracy.  I re-read the instructions and find that I somehow missed this line: “Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.” That makes more sense. But if they are using AUROC, then why do they ask for a binary prediction?!&lt;/p&gt;

&lt;h2 id=&quot;eda&quot;&gt;EDA&lt;/h2&gt;
&lt;p&gt;This is something that I should have done, having noticed other people doing it for the &lt;a href=&quot;/blog/blog/python/data%20science/2020/06/25/creditcard6.html&quot;&gt;credit card dataset&lt;/a&gt;, but forgot to do. I will make sure to do this for next time! (I did very minimal exploration, but there is clearly more I could do).&lt;/p&gt;

&lt;h2 id=&quot;two-other-algorithms&quot;&gt;Two other algorithms&lt;/h2&gt;
&lt;p&gt;There are two more algorithms to add to my toolbox: Naive Bayes and LightGBM.  Naive Bayes is intuitive and I am surprised I have not encountered it already. LightGBM seems to be a faster alternative to XGBoost, and this seems to be the most popular algorithm used in this challenge.&lt;/p&gt;

&lt;h2 id=&quot;creating-a-model-for-each-feature-separately&quot;&gt;Creating a model for each feature separately&lt;/h2&gt;
&lt;p&gt;This idea seems to be first described in this &lt;a href=&quot;https://www.kaggle.com/ymatioun/santander-model-one-feature-at-a-time&quot;&gt;example&lt;/a&gt; and &lt;a href=&quot;https://www.kaggle.com/cdeotte/modified-naive-bayes-santander-0-899&quot;&gt;here&lt;/a&gt;. The intuition for why this works is that the features are seemingly independent, so you can combine the predictions made from considering each feature, one at a time. I can’t remember which example it is, but somebody else calculated all the pairwise correlations between features and found they were all very small.&lt;/p&gt;

&lt;h2 id=&quot;using-frequency-as-new-feature&quot;&gt;Using frequency as new feature&lt;/h2&gt;
&lt;p&gt;This idea was referred to as the magic feature (e.g. &lt;a href=&quot;https://www.kaggle.com/cdeotte/200-magical-models-santander-0-920&quot;&gt;here&lt;/a&gt;): for each feature ‘F’, add a new feature ‘F_freq’ which is the frequency of the first feature ‘F’. It is not intuitive to me why this should improve the performance of the model.&lt;/p&gt;

&lt;h2 id=&quot;visualising-a-tree-based-algorithm&quot;&gt;Visualising a tree-based algorithm&lt;/h2&gt;
&lt;p&gt;In this &lt;a href=&quot;https://www.kaggle.com/cdeotte/200-magical-models-santander-0-920&quot;&gt;example&lt;/a&gt;, there are excellent visuals demonstrating how LightGBM is making its predictions. In particular, there are excellent visuals that demonstrate how including the magic frequency feature improves the models.&lt;/p&gt;

&lt;h2 id=&quot;a-remarkable-discovery&quot;&gt;A remarkable discovery&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split&quot;&gt;YaG320&lt;/a&gt; made an incredible discovery: by looking at the frequencies that different values occur, they concluded that there must be synethic data and then separated out the real data from the synthetic. The reasoning was clever: by noticing that there were fewer unique values in the test data than in the training data, they suspected that the test data started out as some real data and then augmented with some synthetic data. Furthermore, the synthetic data will only use values that occured in the real data. To sniff out the synthetic data, you have to ask yourself: are any of its feature values unique? If yes, then it cannot be synthetic (as synthetic only uses values that already occured in the real data), and if not, then it is very likely synthetic (not certain but very likely). YaG320 wrote code to implement this idea, and found that exactly half the code was real and half was synthetic. Impressive detective work! By removing the fake synthetic data from the construction of their models, people were able to improve their models.&lt;/p&gt;

&lt;p&gt;It is unlikely this exact idea will be useful for me in any future projects I will do. However, it highlights the power and thrill of data science. By looking at a bunch of numbers (and with a healthy dose of creativity) one can make deductions that would otherwise be completely hidden.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There is a lot for me still to learn! Trying to analyse these Kaggle datasets and then comparing my approach to others seems to be an excellent way to learn and I will be sure to continue it. However, I need to practice some data cleaning/data scraping, so I will start some projects in that vain soon.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Santander Dataset, Part II, Feature Selection Santander Dataset, Part I</summary></entry><entry><title type="html">Neural Networks, Part II, First MNIST model</title><link href="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/14/neural2.html" rel="alternate" type="text/html" title="Neural Networks, Part II, First MNIST model" /><published>2020-07-14T00:00:00-05:00</published><updated>2020-07-14T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/14/neural2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/14/neural2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/python/data%20science/neural%20network/2020/07/09/neural1.html&quot;&gt;Neural Networks, Part I, Basic network from scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;first-mnist-model&quot;&gt;First MNIST model&lt;/h2&gt;
&lt;p&gt;Using the neural network class from Part I, I train a neural network on the MNIST dataset.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_valid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist_loader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neural1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accuracy on testing data: {net.accuracy(data_test)}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accuracy on testing data: {net.accuracy(data_test)}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'network1.config'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results of running this were:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Accuracy on testing data: 0.08475
Epoch 0 starting.   Epoch 0 done. Accuracy is 0.902
Epoch 1 starting.   Epoch 1 done. Accuracy is 0.912
Epoch 2 starting.   Epoch 2 done. Accuracy is 0.931
Epoch 3 starting.   Epoch 3 done. Accuracy is 0.939
Epoch 4 starting.   Epoch 4 done. Accuracy is 0.930
Epoch 5 starting.   Epoch 5 done. Accuracy is 0.943
Epoch 6 starting.   Epoch 6 done. Accuracy is 0.943
Epoch 7 starting.   Epoch 7 done. Accuracy is 0.948
Epoch 8 starting.   Epoch 8 done. Accuracy is 0.948
Epoch 9 starting.   Epoch 9 done. Accuracy is 0.950
Accuracy on testing data: 0.9496333333333333
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;I will continue to work through &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/chap1.html&quot;&gt;Nielsen’s online book&lt;/a&gt;, learning more about neural networks.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Neural Networks, Part I, Basic network from scratch</summary></entry><entry><title type="html">Santander Dataset, Part II, Feature Selection</title><link href="https://lovkush-a.github.io/blog/python/data%20science/2020/07/13/santander2.html" rel="alternate" type="text/html" title="Santander Dataset, Part II, Feature Selection" /><published>2020-07-13T00:00:00-05:00</published><updated>2020-07-13T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/2020/07/13/santander2</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/2020/07/13/santander2.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/07/18/santander3.html&quot;&gt;Santander Dataset, Part III, Learning from others&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;/blog/python/data%20science/2020/07/01/santander1.html&quot;&gt;Santander Dataset, Part I&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;After some Googling and reading of various blog posts and articles, I decide to carry out a few different feature selection techniques, record them all in a pandas frame, and pick out the important features as appropriate. The feature selection techniques I use are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Calculate ANOVA F-value between each feature and prediction target&lt;/li&gt;
  &lt;li&gt;Obtain feature importances from XGBoost model&lt;/li&gt;
  &lt;li&gt;Calculate correlations between each feature and prediction target&lt;/li&gt;
  &lt;li&gt;Obtain coefficients from logistic regression with L1-regularisation&lt;/li&gt;
  &lt;li&gt;Obtain coefficients from logistic regression with L2-regularisation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;visualising-the-feature-scores&quot;&gt;Visualising the feature scores&lt;/h2&gt;
&lt;p&gt;Below are plots showing how the different methods of measuring feature importance compare with one another.
&lt;img src=&quot;/blog/images/santander2_features.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The main takeaways for me are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The different measures are all strong correlated with one another. This is a good thing of course, because it means there really is a consistent notion of feature importance.&lt;/li&gt;
  &lt;li&gt;The ANOVA F-values and correlations seem to provide exactly the same information. This is presumably not a coincidence, and there will probably be simple mathematical relationship between correlation and the F-values.&lt;/li&gt;
  &lt;li&gt;The L1- and L2-regularisations have a perfect correlation. Visually scanning the coefficients also showed they were almost exactly the same. This makes me suspicious and wonder if I did something wrong. As far as I could tell I did not. This is something for me to investigate in future, because I was expecting L1 and L2 regularisations to produce some noticable difference.&lt;/li&gt;
  &lt;li&gt;The logistic regressions and correlations have a very strong correlation. From my understanding this is not a coincidence - I believe there is a direct relationship between the coefficients and correlations (at least when there is only one feature variable).&lt;/li&gt;
  &lt;li&gt;The XGBoost feature importances are least correlated with the others. I suppose this makes, because I think the other four quantities have direct mathematical relationships between them, whereas tree-models are qualitatively different.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To remove the non-linearity in some of the charts above, I decided to also plot feature &lt;em&gt;ranks&lt;/em&gt; that these different measures produce. 
&lt;img src=&quot;/blog/images/santander2_ranks.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is nothing new shown in these graphs - it just makes the patterns listed above a bit clearer.&lt;/p&gt;

&lt;h2 id=&quot;models-with-only-the-most-important-features&quot;&gt;Models with only the most important features&lt;/h2&gt;
&lt;p&gt;Next I produced several logistic models keeping differing amounts of features removed. I used logistic models because they were the quickest to create.
&lt;img src=&quot;/blog/images/santander2_feat5.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/images/santander2_feat10.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/images/santander2_feat50.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/images/santander2_feat100.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/images/santander2_feat150.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/blog/images/santander2_feat200.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The patterns here are clear. My takeaways are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;As you increase the number of features kept, the model improves.&lt;/li&gt;
  &lt;li&gt;The 100 least important features provide very little information to the models.&lt;/li&gt;
  &lt;li&gt;However, the 100 least important features do provide &lt;em&gt;some&lt;/em&gt; information. The models did not improve by removing them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It looks like removing the least important features has not improved our models. The one thing it did improve was the time taken to create the models. Also, in a real-life situation (where we knew what the variables corresponded to), we would have gained insight into which variables are important, which presumably would help in decision-making.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;The next thing I will do is some hyper-parameter optimisations. After that, I will have used up all the tricks I have available, and then look at other people’s models and see what I can learn.&lt;/p&gt;</content><author><name></name></author><summary type="html">Other posts in series Santander Dataset, Part III, Learning from others Santander Dataset, Part I</summary></entry><entry><title type="html">Neural Networks, Part I, Basic network from scratch</title><link href="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" rel="alternate" type="text/html" title="Neural Networks, Part I, Basic network from scratch" /><published>2020-07-09T00:00:00-05:00</published><updated>2020-07-09T00:00:00-05:00</updated><id>https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1</id><content type="html" xml:base="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html">&lt;h2 id=&quot;other-posts-in-series&quot;&gt;Other posts in series&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/python/data%20science/neural%20network/2020/07/14/neural2.html&quot;&gt;Neural Networks, Part II, First MNIST model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I finally take the plunge and create my first neural network. I have been holding back because I wanted to create my first neural networks from scratch before using the ready-made packages like TensorFlow or PyTorch. This is so that I would develop a deeper understanding (and I should probably do the same thing for the other big algorithms I have already used, like Random Forests). I take the plunge now because I came across this &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/chap1.html&quot;&gt;tutorial&lt;/a&gt; by &lt;a href=&quot;http://michaelnielsen.org/&quot;&gt;Michael Nielsen&lt;/a&gt; which explains everything from scratch. (Funnily, I found this tutorial indirectly, via Michael’s excellent article on &lt;a href=&quot;https://quantum.country/&quot;&gt;Quantum Computation&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The neural network I create is almost completely vanilla: no fancy architectures, the loss function is RSS, I use the sigmoid function for the activation function. The one non-vanilla idea was to use mini-batches to estimate the gradient of the cost function, instead of using the whole training dataset. After reading through Chapter 1 of Nielsen’s tutorial and skimming through the example code, I tried to create the program from scratch. I did check back with the example code on several occasions to check I was not going astray, so my code and his example are very similar.&lt;/p&gt;

&lt;h2 id=&quot;testing-the-code&quot;&gt;Testing the code&lt;/h2&gt;
&lt;p&gt;To test the code works, I created some made up easy data to be classified (see code below) and achieved the following output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Epoch 0 starting.   Epoch 0 done. Accuracy is 0.518
Epoch 1 starting.   Epoch 1 done. Accuracy is 0.582
Epoch 2 starting.   Epoch 2 done. Accuracy is 0.893
Epoch 3 starting.   Epoch 3 done. Accuracy is 0.919
Epoch 4 starting.   Epoch 4 done. Accuracy is 0.956
Epoch 5 starting.   Epoch 5 done. Accuracy is 0.973
Epoch 6 starting.   Epoch 6 done. Accuracy is 0.966
Epoch 7 starting.   Epoch 7 done. Accuracy is 0.966
Epoch 8 starting.   Epoch 8 done. Accuracy is 0.967
Epoch 9 starting.   Epoch 9 done. Accuracy is 0.971
Accuracy on testing data: 0.968
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It was satisfying to see that the code appears to work!&lt;/p&gt;

&lt;h2 id=&quot;a-proud-moment&quot;&gt;A proud moment&lt;/h2&gt;
&lt;p&gt;A part of doing things from scratch included deriving the back-propogation formulae. I found this trickier than I was expecting - afterall, I just have to use the Chain Rule over and over again. How hard can that be?? After straining my mind for some time, I think I have got it but am not sure.  Before trying to code it up, I have a look at Nielsen’s code to check, and I got it correct. I was chuffed with myself! :D&lt;/p&gt;

&lt;h2 id=&quot;learning-points&quot;&gt;Learning points&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The main mistake I made when coding up the algorithm was not paying attention how a vector should be represented in NumPy. In particular, NumPy does not treat a rank-1 array of size (n) the same as a rank-2 array of size (1,n), for example, with transposing. This took some time to debug, because my first suspicion was that I mis-typed the formulae, or that I got the indices mixed up, or some other little error. In the end, I had to change how I coded the vectors to rank-2 arrays of size (1,n).&lt;/li&gt;
  &lt;li&gt;Nielsen often had a tidier way of coding the same steps or calculations, often by using zip. This is a useful little function which I will be sure to use in the future!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;The immediate next step is to use this code to read hand-writing using the MNIST dataset, and then work through the rest of Nielsen’s tutorial where we optimise the network in various ways. After that, the world is my oyster! At some point, I need to learn some RL, so I can continue on my AI for Games project.&lt;/p&gt;

&lt;h2 id=&quot;the-code&quot;&gt;The code&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]]&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])]&lt;/span&gt;
    

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;feed_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;
         
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vsigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
    

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_dt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch {epoch} starting.   &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_via_minibatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch {epoch} done. Accuracy is {acc:.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_via_minibatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;delta_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# introduce shorthand notation for weights and biases
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# feedforward. store values of a and z
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;a_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vsigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# define variables to store gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grad_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# initialise gradients for a and z in final layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grad_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vsigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# back propogate
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grad_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grad_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grad_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grad_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vsigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_w&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feed_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;




&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vsigmoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectorize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vsigmoid_prime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectorize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Accuracy on testing data: {net.accuracy(data_test)}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Other posts in series Neural Networks, Part II, First MNIST model</summary></entry></feed>