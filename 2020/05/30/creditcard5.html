<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Investigating Credit Card Fraud, Part V | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Investigating Credit Card Fraud, Part V" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872." />
<meta property="og:description" content="I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-30T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872.","@type":"BlogPosting","headline":"Investigating Credit Card Fraud, Part V","dateModified":"2020-05-30T00:00:00-05:00","datePublished":"2020-05-30T00:00:00-05:00","url":"https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>





<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Investigating Credit Card Fraud, Part V | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Investigating Credit Card Fraud, Part V" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872." />
<meta property="og:description" content="I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-30T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872.","@type":"BlogPosting","headline":"Investigating Credit Card Fraud, Part V","dateModified":"2020-05-30T00:00:00-05:00","datePublished":"2020-05-30T00:00:00-05:00","url":"https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/2020/05/30/creditcard5.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Lovkush Agarwal</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Investigating Credit Card Fraud, Part V</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-30T00:00:00-05:00" itemprop="datePublished">
        May 30, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>I complete the hyper-parameter optimisations for the random forest and xgboost models. I then create a final model using these values to produce AUCs of 0.852 and 0.872.</p>

<h2 id="other-posts-in-series">Other posts in series</h2>

<ul>
  <li>
    <p><a href="/python/data%20science/2020/06/25/creditcard6.html">Credit Card Fraud, Part VI, Summary and Lessons from Kaggle</a></p>
  </li>
  <li>
    <p><a href="/2020/05/29/creditcard4.html">Investigating Credit Card Fraud, Part IV</a></p>
  </li>
  <li>
    <p><a href="/2020/05/19/creditcard3.html">Investigating Credit Card Fraud, Part III</a></p>
  </li>
  <li>
    <p><a href="/python/data%20science/2020/05/16/creditcard2.html">Investigating Credit Card Fraud, Part II, Removing data</a></p>
  </li>
  <li>
    <p><a href="/python/data%20science/2020/05/14/creditcard1.html">Investigating Credit Card Fraud, Part I, First Models</a></p>
  </li>
</ul>

<h2 id="forest-model-hyper-parameter-selection">Forest model, hyper-parameter selection</h2>
<p>I tidied up the code from yesterday to allow me to optimise for more than one parameter at once. For each combination of hyper-parameters, I obtained 20 different AUCs (by using five 4-fold cross validations). The results were stored in a pandas dataframe. The code for this is at the bottom of the page.</p>

<p>I then averaged over all the folds and sorted the results. The code for this and the output is below.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>auc_forest.max_depth.fillna(value = 0, inplace = True)
auc_forest_mean = auc_forest.groupby(['n_estimators', 'max_depth', 'max_features']).auc.mean()
auc_forest_mean.sort_values(ascending = False).head(20)

n_estimators  max_depth  max_features    auc
50.0          0.0        10.0            0.774015
              50.0       10.0            0.774015
60.0          0.0        10.0            0.772589
              50.0       10.0            0.772589
              10.0       10.0            0.772573
50.0          10.0       10.0            0.772328
40.0          10.0       10.0            0.771290
80.0          0.0        10.0            0.771108
              50.0       10.0            0.771108
40.0          0.0        10.0            0.770744
              50.0       10.0            0.770744
50.0          0.0        7.0             0.770522
              50.0       7.0             0.770522
80.0          10.0       10.0            0.770487
50.0          10.0       7.0             0.770472
60.0          50.0       7.0             0.770472
              0.0        7.0             0.770472
              10.0       7.0             0.770025
40.0          50.0       5.0             0.769278
                         auto            0.769278
</code></pre></div></div>

<p>A few things were found by doing this:</p>
<ul>
  <li>The best options for the hyper-parameters are n_estimators = 50, max_depth = None and max_features = 10.</li>
  <li>max_depth = None and max_depth = 50 produced the same models. This means that maximum depth achieved without any limits is less than 50.</li>
  <li>max_features = auto and max_features = 5 produced the same models. This is obvious in retrospect: auto means taking the square root of the number of features, and we had about 30 features.</li>
</ul>

<h2 id="forest-model-final-model">Forest model, final model</h2>
<p>Using these hyper-parameters, I created a the final Random Forest model. The precision-recall curve is below:</p>

<p><img src="/blog/images/creditcard_5_forest.png" alt="image" />
<img src="/blog/images/creditcard_1_forest.png" alt="image" /></p>

<p>For comparison, the very first random forest model is also included. As can be seen, there is an improvement but a seemingly minimal one. Based on examples I have seen elsewhere, these minor improvements are what can be expected from hyper-parameter optimisations.</p>

<h2 id="xgboost-model">XGBoost model</h2>
<p>I repeated the process above for XGBoost models.  The best parameter settings were as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n_estimators  max_depth  learning_rate    auc
50.0          5.0        0.05             0.761125
100.0         5.0        0.02             0.760002
50.0          10.0       0.05             0.759094
              15.0       0.05             0.758146
100.0         10.0       0.02             0.757185
              15.0       0.02             0.756748
200.0         10.0       0.02             0.747032
              15.0       0.02             0.743830
50.0          15.0       0.10             0.742954
              10.0       0.10             0.739922
100.0         10.0       0.05             0.737840
              15.0       0.05             0.737013
50.0          10.0       0.02             0.729299
              15.0       0.02             0.729239
              5.0        0.02             0.729049
200.0         5.0        0.02             0.727433
50.0          15.0       0.30             0.726696
              5.0        0.20             0.726479
100.0         5.0        0.20             0.724851
              15.0       0.30             0.722728
</code></pre></div></div>

<p>Using the settings from the top row, I created my final model, whose precision-recall curve is below.  I have included the original curve, too.</p>

<p><img src="/blog/images/creditcard_5_xgb.png" alt="image" />
<img src="/blog/images/creditcard_1_xgb.png" alt="image" /></p>

<p>!! After doing the optimisations, the model became worse! The AUC decreased by 0.002. The  explanation for this must be that removing 99% of the data actually changes the behaviour of the model.</p>

<p>I re-did the process but only removing 90% of the data (recall from Part II that in XGBoost, removing 90% of the data did not decrease performance that much). This time, the optimal settings were as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n_estimators  max_depth  learning_rate    auc
200.0         10.0       0.10             0.816130
              5.0        0.10             0.815648
100.0         5.0        0.10             0.807745
              10.0       0.10             0.806940
200.0         10.0       0.05             0.805212
              5.0        0.05             0.801478
50.0          10.0       0.10             0.797015
              5.0        0.10             0.794567
100.0         5.0        0.05             0.793189
              10.0       0.05             0.792732
200.0         5.0        0.02             0.785652
              10.0       0.02             0.783957
50.0          5.0        0.05             0.779087
              10.0       0.05             0.778968
100.0         5.0        0.02             0.776565
              10.0       0.02             0.775092
50.0          5.0        0.02             0.761190
              10.0       0.02             0.760388
</code></pre></div></div>
<p>The optimal parameters changed (thankfully!).  I then re-created the final model and this time there was an improvement:</p>

<p><img src="/blog/images/creditcard_5_xgb2.png" alt="image" />
<img src="/blog/images/creditcard_1_xgb.png" alt="image" /></p>

<h2 id="next-time">Next time</h2>
<p>My next blog post will be the final one in this series. I will summarise what I have done and what I have learnt. I will also have a look at what others did and see what I can learn from them.</p>

<h2 id="the-code">The code</h2>
<p>The code is provided for the Random Forest optimisation. The code for XGBoost is similar.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">#</span> <span class="n">import</span> <span class="n">modules</span>
<span class="n">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="k">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">model_selection</span> <span class="n">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span>

<span class="k">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span> <span class="n">import</span> <span class="n">precision_recall_curve</span>
<span class="k">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span> <span class="n">import</span> <span class="n">auc</span>
<span class="k">from</span> <span class="n">matplotlib</span> <span class="n">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="k">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">ensemble</span> <span class="n">import</span> <span class="n">RandomForestClassifier</span>
<span class="k">from</span> <span class="n">xgboost</span> <span class="n">import</span> <span class="n">XGBClassifier</span>

<span class="n">import</span> <span class="n">itertools</span>


<span class="p">#</span><span class="n">import</span> <span class="n">data</span>
<span class="n">data</span> <span class="p">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"creditcard.csv"</span><span class="p">)</span>
<span class="n">y</span> <span class="p">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Class</span>
<span class="n">X</span> <span class="p">=</span> <span class="n">data</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Class'</span><span class="p">,</span> <span class="s1">'Time'</span><span class="p">],</span> <span class="n">axis</span> <span class="p">=</span> <span class="m">1</span><span class="p">)</span>

<span class="p">#</span><span class="nb">create</span> <span class="n">train</span><span class="p">-</span><span class="n">valid</span> <span class="n">versus</span> <span class="n">test</span> <span class="n">split</span>
<span class="n">Xtv</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">ytv</span><span class="p">,</span> <span class="n">y_test</span> <span class="p">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="p">=</span><span class="m">0</span><span class="p">,</span> <span class="n">test_size</span><span class="p">=</span><span class="m">0.2</span><span class="p">)</span>


<span class="p">#</span> <span class="nb">create</span> <span class="k">function</span> <span class="n">which</span> <span class="n">takes</span> <span class="k">model</span> <span class="k">and</span> <span class="n">data</span>
<span class="p">#</span> <span class="n">returns</span> <span class="n">auc</span>

<span class="n">def</span> <span class="n">auc_model</span><span class="p">(</span><span class="k">model</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">yv</span><span class="p">):</span>
    <span class="k">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xt</span><span class="p">,</span><span class="n">yt</span><span class="p">)</span>
   
    <span class="n">preds</span> <span class="p">=</span> <span class="k">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Xv</span><span class="p">)</span>
    <span class="n">preds</span> <span class="p">=</span> <span class="n">preds</span><span class="p">[:,</span><span class="m">1</span><span class="p">]</span>
    
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="p">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">yv</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="n">auc_current</span> <span class="p">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
    
    <span class="n">return</span> <span class="n">auc_current</span>


<span class="p">#</span> <span class="nb">create</span> <span class="k">options</span> <span class="n">for</span> <span class="n">hyperparameter</span>
<span class="n">n_estimators</span> <span class="p">=</span> <span class="p">[</span><span class="m">40</span><span class="p">,</span> <span class="m">50</span><span class="p">,</span> <span class="m">60</span><span class="p">,</span> <span class="m">80</span><span class="p">]</span>
<span class="n">max_depth</span> <span class="p">=</span> <span class="p">[</span><span class="n">None</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="m">50</span><span class="p">]</span>
<span class="n">max_features</span> <span class="p">=</span> <span class="p">[</span><span class="s1">'auto'</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">10</span><span class="p">]</span>
<span class="n">random_state</span> <span class="p">=</span> <span class="k">range</span><span class="p">(</span><span class="m">5</span><span class="p">)</span>

<span class="p">#</span> <span class="nb">create</span> <span class="n">frame</span> <span class="k">to</span> <span class="n">store</span> <span class="n">auc</span> <span class="n">data</span>
<span class="n">auc_forest</span> <span class="p">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'n_estimators'</span><span class="p">:</span> <span class="p">[],</span>
                           <span class="s1">'max_depth'</span><span class="p">:</span> <span class="p">[],</span>
                           <span class="s1">'max_features'</span><span class="p">:</span> <span class="p">[],</span>
                           <span class="s1">'fold'</span><span class="p">:</span> <span class="p">[],</span>
                           <span class="s1">'auc'</span><span class="p">:</span> <span class="p">[]</span>
                          <span class="p">})</span>


<span class="p">#</span> <span class="n">loop</span> <span class="n">through</span> <span class="n">hyper</span> <span class="n">parameter</span> <span class="n">space</span>

<span class="n">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">mf</span><span class="p">,</span> <span class="n">rs</span> <span class="k">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">max_features</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
    <span class="n">kf</span> <span class="p">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="p">=</span> <span class="m">4</span><span class="p">,</span>
           <span class="n">shuffle</span> <span class="p">=</span> <span class="nb">True</span><span class="p">,</span>
           <span class="n">random_state</span> <span class="p">=</span> <span class="n">rs</span><span class="p">)</span>
    
    <span class="k">model</span> <span class="p">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="p">=</span> <span class="n">n</span><span class="p">,</span>
                                   <span class="n">max_depth</span> <span class="p">=</span> <span class="n">md</span><span class="p">,</span>
                                   <span class="n">max_features</span> <span class="p">=</span> <span class="n">mf</span><span class="p">,</span>
                                   <span class="n">random_state</span> <span class="p">=</span> <span class="m">0</span><span class="p">)</span>
    
    <span class="n">i</span><span class="p">=</span><span class="m">0</span>
    <span class="n">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="k">in</span> <span class="n">kf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">Xtv</span><span class="p">):</span>
        <span class="n">Xt</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">yv</span> <span class="p">=</span> <span class="n">Xtv</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">Xtv</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">valid</span><span class="p">],</span> <span class="n">ytv</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">ytv</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span>

        <span class="p">#</span> <span class="n">remove</span> <span class="m">99</span><span class="p">%</span> <span class="k">of</span> <span class="n">the</span> <span class="n">non</span><span class="p">-</span><span class="n">fraudulent</span> <span class="n">claims</span> <span class="k">from</span> <span class="n">training</span> <span class="n">data</span> <span class="k">to</span> <span class="n">speed</span> <span class="n">up</span> <span class="n">fitting</span>
        <span class="n">selection</span> <span class="p">=</span> <span class="p">(</span><span class="n">Xt</span><span class="p">.</span><span class="n">index</span> <span class="p">%</span> <span class="m">100</span> <span class="p">==</span> <span class="m">1</span><span class="p">)</span> <span class="p">|</span> <span class="p">(</span><span class="n">yt</span> <span class="p">==</span> <span class="m">1</span><span class="p">)</span>
        <span class="n">Xt_reduced</span> <span class="p">=</span> <span class="n">Xt</span><span class="p">[</span><span class="n">selection</span><span class="p">]</span>
        <span class="n">yt_reduced</span> <span class="p">=</span> <span class="n">yt</span><span class="p">[</span><span class="n">selection</span><span class="p">]</span>

        <span class="n">auc_current</span> <span class="p">=</span> <span class="n">auc_model</span><span class="p">(</span><span class="k">model</span><span class="p">,</span> <span class="n">Xt_reduced</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt_reduced</span><span class="p">,</span> <span class="n">yv</span><span class="p">)</span>
        <span class="n">auc_forest</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">auc_forest</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="m">0</span><span class="p">]]</span> <span class="p">=</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">mf</span><span class="p">,</span> <span class="m">4</span><span class="p">*</span><span class="n">rs</span><span class="p">+</span><span class="n">i</span><span class="p">,</span> <span class="n">auc_current</span><span class="p">]</span>

        <span class="n">i</span><span class="p">+=</span><span class="m">1</span>
</code></pre></div></div>


  </div><a class="u-url" href="/blog/2020/05/30/creditcard5.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog for my data science learning and projects</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/lovkush-a" title="lovkush-a"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/lovkushatleeds" title="lovkushatleeds"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
