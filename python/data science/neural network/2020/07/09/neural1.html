<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Neural Networks, Part I, Basic network from scratch | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Neural Networks, Part I, Basic network from scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I create my first ever neural network. It is a vanilla network, written from scratch in Python." />
<meta property="og:description" content="I create my first ever neural network. It is a vanilla network, written from scratch in Python." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-09T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-09T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html"},"description":"I create my first ever neural network. It is a vanilla network, written from scratch in Python.","@type":"BlogPosting","url":"https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html","headline":"Neural Networks, Part I, Basic network from scratch","dateModified":"2020-07-09T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>





<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Neural Networks, Part I, Basic network from scratch | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Neural Networks, Part I, Basic network from scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I create my first ever neural network. It is a vanilla network, written from scratch in Python." />
<meta property="og:description" content="I create my first ever neural network. It is a vanilla network, written from scratch in Python." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-09T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-09T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html"},"description":"I create my first ever neural network. It is a vanilla network, written from scratch in Python.","@type":"BlogPosting","url":"https://lovkush-a.github.io/blog/python/data%20science/neural%20network/2020/07/09/neural1.html","headline":"Neural Networks, Part I, Basic network from scratch","dateModified":"2020-07-09T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Lovkush Agarwal</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Neural Networks, Part I, Basic network from scratch</h1><p class="page-description">I create my first ever neural network. It is a vanilla network, written from scratch in Python.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-09T00:00:00-05:00" itemprop="datePublished">
        Jul 9, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#data science">data science</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#neural network">neural network</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#other-posts-in-series">Other posts in series</a></li>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#testing-the-code">Testing the code</a></li>
<li class="toc-entry toc-h2"><a href="#a-proud-moment">A proud moment</a></li>
<li class="toc-entry toc-h2"><a href="#learning-points">Learning points</a></li>
<li class="toc-entry toc-h2"><a href="#next-steps">Next steps</a></li>
<li class="toc-entry toc-h2"><a href="#the-code">The code</a></li>
</ul><h2 id="other-posts-in-series">
<a class="anchor" href="#other-posts-in-series" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other posts in series</h2>

<ul>
  <li><a href="/blog/python/data%20science/neural%20network/2020/07/14/neural2.html">Neural Networks, Part II, First MNIST model</a></li>
</ul>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<p>I finally take the plunge and create my first neural network. I have been holding back because I wanted to create my first neural networks from scratch before using the ready-made packages like TensorFlow or PyTorch. This is so that I would develop a deeper understanding (and I should probably do the same thing for the other big algorithms I have already used, like Random Forests). I take the plunge now because I came across this <a href="http://neuralnetworksanddeeplearning.com/chap1.html">tutorial</a> by <a href="http://michaelnielsen.org/">Michael Nielsen</a> which explains everything from scratch. (Funnily, I found this tutorial indirectly, via Michaelâ€™s excellent article on <a href="https://quantum.country/">Quantum Computation</a>).</p>

<p>The neural network I create is almost completely vanilla: no fancy architectures, the loss function is RSS, I use the sigmoid function for the activation function. The one non-vanilla idea was to use mini-batches to estimate the gradient of the cost function, instead of using the whole training dataset. After reading through Chapter 1 of Nielsenâ€™s tutorial and skimming through the example code, I tried to create the program from scratch. I did check back with the example code on several occasions to check I was not going astray, so my code and his example are very similar.</p>

<h2 id="testing-the-code">
<a class="anchor" href="#testing-the-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Testing the code</h2>
<p>To test the code works, I created some made up easy data to be classified (see code below) and achieved the following output:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 0 starting.   Epoch 0 done. Accuracy is 0.518
Epoch 1 starting.   Epoch 1 done. Accuracy is 0.582
Epoch 2 starting.   Epoch 2 done. Accuracy is 0.893
Epoch 3 starting.   Epoch 3 done. Accuracy is 0.919
Epoch 4 starting.   Epoch 4 done. Accuracy is 0.956
Epoch 5 starting.   Epoch 5 done. Accuracy is 0.973
Epoch 6 starting.   Epoch 6 done. Accuracy is 0.966
Epoch 7 starting.   Epoch 7 done. Accuracy is 0.966
Epoch 8 starting.   Epoch 8 done. Accuracy is 0.967
Epoch 9 starting.   Epoch 9 done. Accuracy is 0.971
Accuracy on testing data: 0.968
</code></pre></div></div>

<p>It was satisfying to see that the code appears to work!</p>

<h2 id="a-proud-moment">
<a class="anchor" href="#a-proud-moment" aria-hidden="true"><span class="octicon octicon-link"></span></a>A proud moment</h2>
<p>A part of doing things from scratch included deriving the back-propogation formulae. I found this trickier than I was expecting - afterall, I just have to use the Chain Rule over and over again. How hard can that be?? After straining my mind for some time, I think I have got it but am not sure.  Before trying to code it up, I have a look at Nielsenâ€™s code to check, and I got it correct. I was chuffed with myself! :D</p>

<h2 id="learning-points">
<a class="anchor" href="#learning-points" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning points</h2>
<ul>
  <li>The main mistake I made when coding up the algorithm was not paying attention how a vector should be represented in NumPy. In particular, NumPy does not treat a rank-1 array of size (n) the same as a rank-2 array of size (1,n), for example, with transposing. This took some time to debug, because my first suspicion was that I mis-typed the formulae, or that I got the indices mixed up, or some other little error. In the end, I had to change how I coded the vectors to rank-2 arrays of size (1,n).</li>
  <li>Nielsen often had a tidier way of coding the same steps or calculations, often by using zip. This is a useful little function which I will be sure to use in the future!</li>
</ul>

<h2 id="next-steps">
<a class="anchor" href="#next-steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Next steps</h2>
<p>The immediate next step is to use this code to read hand-writing using the MNIST dataset, and then work through the rest of Nielsenâ€™s tutorial where we optimise the network in various ways. After that, the world is my oyster! At some point, I need to learn some RL, so I can continue on my AI for Games project.</p>

<h2 id="the-code">
<a class="anchor" href="#the-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>The code</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="p">))</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">))</span>
                        <span class="k">for</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
    

    <span class="k">def</span> <span class="nf">feed_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
         
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">vsigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
 
        <span class="k">return</span> <span class="n">a</span>
    

    <span class="k">def</span> <span class="nf">sgd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="n">n_dt</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
        <span class="n">mbs</span> <span class="o">=</span> <span class="n">mini_batch_size</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Epoch {epoch} starting.   "</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s">""</span><span class="p">)</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
            
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_train</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mbs</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_dt</span><span class="p">,</span> <span class="n">mbs</span><span class="p">)]</span>

            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_via_minibatch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

            <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Epoch {epoch} done. Accuracy is {acc:.3f}"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span>
    

    <span class="k">def</span> <span class="nf">update_via_minibatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="n">mbs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">)</span>
        
        <span class="n">delta_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="p">))</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="n">delta_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>

        <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">db</span><span class="p">,</span> <span class="n">dw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
            <span class="n">delta_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">b1</span> <span class="o">+</span> <span class="n">b2</span> <span class="k">for</span> <span class="n">b1</span><span class="p">,</span><span class="n">b2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">delta_b</span><span class="p">,</span> <span class="n">db</span><span class="p">)]</span>
            <span class="n">delta_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">w1</span> <span class="o">+</span> <span class="n">w2</span> <span class="k">for</span> <span class="n">w1</span><span class="p">,</span><span class="n">w2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">delta_w</span><span class="p">,</span> <span class="n">dw</span><span class="p">)]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span><span class="o">/</span><span class="n">mbs</span><span class="p">)</span><span class="o">*</span><span class="n">db</span>
                        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">db</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">delta_b</span><span class="p">)]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span><span class="o">/</span><span class="n">mbs</span><span class="p">)</span><span class="o">*</span><span class="n">dw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">dw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">delta_w</span><span class="p">)]</span>
        <span class="k">return</span> <span class="bp">None</span>


    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># introduce shorthand notation for weights and biases
</span>        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span>

        <span class="c1"># feedforward. store values of a and z
</span>        <span class="n">a_temp</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">z_temp</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">z_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a_temp</span><span class="p">,</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">a_temp</span> <span class="o">=</span> <span class="n">vsigmoid</span><span class="p">(</span><span class="n">z_temp</span><span class="p">)</span>
            <span class="n">z</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z_temp</span><span class="p">)</span>
            <span class="n">a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a_temp</span><span class="p">)</span>
        
        <span class="c1"># define variables to store gradients
</span>        <span class="n">grad_a</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>
        <span class="n">grad_z</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">z</span><span class="p">]</span>
        <span class="n">grad_b</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">b</span><span class="p">]</span>
        <span class="n">grad_w</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">w</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span>

        <span class="c1"># initialise gradients for a and z in final layer
</span>        <span class="n">grad_a</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">vsigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">grad_a</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">grad_z</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>

        <span class="c1"># back propogate
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">grad_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_z</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">grad_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">grad_z</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">grad_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_z</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">grad_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">vsigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">grad_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">grad_b</span><span class="p">,</span> <span class="n">grad_w</span>


    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_test</span><span class="p">):</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">data_test</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">match</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
            <span class="n">acc</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">match</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>




<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span><span class="o">/</span><span class="p">((</span><span class="mi">1</span><span class="o">+</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">vsigmoid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">)</span>
<span class="n">vsigmoid_prime</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">sigmoid_prime</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    
    <span class="n">data_train</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">data_train</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>

    <span class="n">net</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>

    <span class="n">data_test</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">data_test</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>

    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Accuracy on testing data: {net.accuracy(data_test)}"</span><span class="p">)</span>

<span class="n">test</span><span class="p">()</span>
</code></pre></div></div>

  </div><a class="u-url" href="/blog/python/data%20science/neural%20network/2020/07/09/neural1.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog for my data science learning and projects</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/lovkush-a" title="lovkush-a"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/lovkushatleeds" title="lovkushatleeds"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
