<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Investigating Credit Card Fraud, Part II, Removing data</h1><p class="page-description">I see what happens if I remove entries from the dataset. The hope is that it reduces the time needed to create the models without too much reduction in performance.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-16T00:00:00-05:00" itemprop="datePublished">
        May 16, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#data science">data science</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#other-posts-in-series">Other posts in series</a></li>
<li class="toc-entry toc-h2"><a href="#my-thinking-and-plan">My thinking and plan</a></li>
<li class="toc-entry toc-h2"><a href="#results-for-random-forests">Results for Random Forests</a></li>
<li class="toc-entry toc-h2"><a href="#results-for-xgboost">Results for XGBoost</a></li>
<li class="toc-entry toc-h2"><a href="#next-steps">Next steps</a></li>
<li class="toc-entry toc-h2"><a href="#the-code">The code</a></li>
</ul><h2 id="other-posts-in-series">
<a class="anchor" href="#other-posts-in-series" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other posts in series</h2>

<ul>
  <li>
    <p><a href="/blog/python/data%20science/2020/06/25/creditcard6.html">Investigating Credit Card Fraud, Part VI, Summary and Lessons from Kaggle</a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/05/30/creditcard5.html">Investigating Credit Card Fraud, Part V, Final Models</a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/05/29/creditcard4.html">Investigating Credit Card Fraud, Part IV, <code class="highlighter-rouge">n_estimators</code></a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/05/19/creditcard3.html">Investigating Credit Card Fraud, Part III, Handmade Model</a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/05/14/creditcard1.html">Investigating Credit Card Fraud, Part I, First Models</a></p>
  </li>
</ul>

<h2 id="my-thinking-and-plan">
<a class="anchor" href="#my-thinking-and-plan" aria-hidden="true"><span class="octicon octicon-link"></span></a>My thinking and plan</h2>
<p>When doing the initial investigations, I noticed it took some time for the fitting, in particular for the random forest models to be fit.  I want to do some hyper-parameter optimisations, but do not want to wait hours for it.  Therefore, I wanted to reduce the time it takes.</p>

<p>I figured that 10% of the non-fraudulent data should contain most of the patterns that 100% of the non-fraudulent data does, and presumably having smaller datasets reduced the run time.</p>

<p>To reduce the datasets, I first split the data using train_test_split as normal. Then, I kept only those non-fraudulent entries whose index had final digit 0 - so I only have 10% remaining.</p>

<p>To better understand the effect removing data has, I tried removing different amounts of data, from 50% to 99%.  The code for all this is at the bottom of the page.</p>

<h2 id="results-for-random-forests">
<a class="anchor" href="#results-for-random-forests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results for Random Forests</h2>
<p>The charts below show what happened as I varied how much data was removed.</p>

<p><img src="/blog/images/creditcard_2_forest_times.png" alt="image">
<img src="/blog/images/creditcard_2_forest_aucs.png" alt="image"></p>

<p>As I hoped, the time taken for the fitting to take place reduces as the dataset is made smaller. (In fact, time taken is linear with size of dataset. I don’t know if this is surprising or not, but I imagine it is clear if one knows implementation details of the algorithms). Also as I predicted, the effectiveness does not drop considerably by removing data.</p>

<p>The charts below show some of the resulting AUC curves, so we can see where the drop in performance occurs.</p>

<p><img src="/blog/images/creditcard_2_forest_100.png" alt="image">
<img src="/blog/images/creditcard_2_forest_50.png" alt="image">
<img src="/blog/images/creditcard_2_forest_20.png" alt="image">
<img src="/blog/images/creditcard_2_forest_10.png" alt="image">
<img src="/blog/images/creditcard_2_forest_5.png" alt="image">
<img src="/blog/images/creditcard_2_forest_1.png" alt="image"></p>

<p>We can see that removing non-fraudulent data has resulted in reduced precision, with no visible drop in recall.  This makes sense: I did not remove any of the fraudulent entries, so it looks like the models were still able extract the same information about them.</p>

<p>This is encouraging. In the context of credit card fraud, recall is more important than precision: the cost of fraud is greater than cost of annoying customers by mis-labelling their transactions as fraudulent.</p>

<h2 id="results-for-xgboost">
<a class="anchor" href="#results-for-xgboost" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results for XGBoost</h2>
<p>I ran the process on XGBoost models too. The charts are below.</p>

<p><img src="/blog/images/creditcard_2_xgb_times.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_aucs.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_100.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_50.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_20.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_10.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_5.png" alt="image">
<img src="/blog/images/creditcard_2_xgb_1.png" alt="image"></p>

<p>The results are similar to those for the random forest. The compute time is linear with the amount of data kept, and performance does not drop much either. Surprisingly, the performance is almost the same with only 10% of the data: only a 0.007 drop in the AUC! It looks like XGBoost is more ‘data-efficient’ than Random Forest: to get good performance, XGBoost requires less data than Random Forests.</p>

<h2 id="next-steps">
<a class="anchor" href="#next-steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Next steps</h2>
<p>The next steps will be to do some hyper-parameter optimisations. But before that, like mentioned in Part 1, I want to better understand the data by creating a crude hand-made model. It will be interesting to see how it compares! My hope is to get an AUC of 0.7.</p>

<h2 id="the-code">
<a class="anchor" href="#the-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>The code</h2>
<p>Below is the code to produce the XGBoost models and charts. The code for Random Forest is similar.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import modules
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">auc</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>



<span class="c1"># import data and create train_test split
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"creditcard.csv"</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Class</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Class'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Xt</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">yv</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>



<span class="c1"># create function which takes model and data
# returns auc, time taken, and saves plot.
</span>
<span class="k">def</span> <span class="nf">auc_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">saveas</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">yv</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xt</span><span class="p">,</span><span class="n">yt</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    
    <span class="n">time</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span>
    
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Xv</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">yv</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="n">auc_current</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'basic'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Recall'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Precision'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span> <span class="o">+</span> <span class="n">f</span><span class="s">'. AUC={auc_current:.3f}'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">saveas</span> <span class="o">+</span> <span class="s">'.png'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">time</span><span class="p">,</span> <span class="n">auc_current</span>



<span class="c1"># create multiply xgb models with varying amount of data removed
</span>
<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>

<span class="n">fraction_kept</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.02</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">aucs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fraction_kept</span><span class="p">:</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xt</span><span class="o">.</span><span class="n">index</span> <span class="o">%</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">f</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">yt</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Xt_reduced</span> <span class="o">=</span> <span class="n">Xt</span><span class="p">[</span><span class="n">selection</span><span class="p">]</span>
    <span class="n">yt_reduced</span> <span class="o">=</span> <span class="n">yt</span><span class="p">[</span><span class="n">selection</span><span class="p">]</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">f</span><span class="s">'XGB Model. Keeping {100*f:.0f}</span><span class="si">% </span><span class="s">of non-fraudulent data'</span>
    <span class="n">saveas</span> <span class="o">=</span> <span class="n">f</span><span class="s">'creditcard_2_xgb_{100*f:.0f}'</span>
    
    <span class="n">time_new</span><span class="p">,</span> <span class="n">auc_new</span> <span class="o">=</span> <span class="n">auc_model</span><span class="p">(</span><span class="n">model_xgb</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">saveas</span><span class="p">,</span> <span class="n">Xt_reduced</span><span class="p">,</span> <span class="n">Xv</span><span class="p">,</span> <span class="n">yt_reduced</span><span class="p">,</span> <span class="n">yv</span><span class="p">)</span>
    <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time_new</span><span class="p">)</span>
    <span class="n">aucs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc_new</span><span class="p">)</span>



<span class="c1"># plot charts to show effect of changing fraction of non-frauduluent data removed
</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fraction_kept</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Fraction of non-fraudulent data kept'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Time to fit the model, seconds'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'XGB. Fraction of non-fraudulent data kept vs time for fitting'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'creditcard_2_xgb_times'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fraction_kept</span><span class="p">,</span> <span class="n">aucs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Fraction of non-fraudulent data kept'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'AUC of model'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'XGB. Fraction of non-fraudulent data kept vs AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'creditcard_2_xgb_aucs'</span><span class="p">)</span>
</code></pre></div></div>


  </div><a class="u-url" href="/blog/python/data%20science/2020/05/16/creditcard2.html" hidden></a>
</article>