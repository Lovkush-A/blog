<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Santander Dataset, Part II, Feature Selection</h1><p class="page-description">I carry out several feature selection algorithms, with the hope of removing features that are reducing the performance of the models.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-13T00:00:00-05:00" itemprop="datePublished">
        Jul 13, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#data science">data science</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#other-posts-in-series">Other posts in series</a></li>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#visualising-the-feature-scores">Visualising the feature scores</a></li>
<li class="toc-entry toc-h2"><a href="#models-with-only-the-most-important-features">Models with only the most important features</a></li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
<li class="toc-entry toc-h2"><a href="#next-steps">Next steps</a></li>
</ul><h2 id="other-posts-in-series">
<a class="anchor" href="#other-posts-in-series" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other posts in series</h2>

<ul>
  <li>
    <p><a href="/blog/python/data%20science/2020/07/18/santander3.html">Santander Dataset, Part III, Learning from others</a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/07/01/santander1.html">Santander Dataset, Part I</a></p>
  </li>
</ul>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<p>After some Googling and reading of various blog posts and articles, I decide to carry out a few different feature selection techniques, record them all in a pandas frame, and pick out the important features as appropriate. The feature selection techniques I use are:</p>
<ul>
  <li>Calculate ANOVA F-value between each feature and prediction target</li>
  <li>Obtain feature importances from XGBoost model</li>
  <li>Calculate correlations between each feature and prediction target</li>
  <li>Obtain coefficients from logistic regression with L1-regularisation</li>
  <li>Obtain coefficients from logistic regression with L2-regularisation</li>
</ul>

<h2 id="visualising-the-feature-scores">
<a class="anchor" href="#visualising-the-feature-scores" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualising the feature scores</h2>
<p>Below are plots showing how the different methods of measuring feature importance compare with one another.
<img src="/blog/images/santander2_features.png" alt=""></p>

<p>The main takeaways for me are:</p>
<ul>
  <li>The different measures are all strong correlated with one another. This is a good thing of course, because it means there really is a consistent notion of feature importance.</li>
  <li>The ANOVA F-values and correlations seem to provide exactly the same information. This is presumably not a coincidence, and there will probably be simple mathematical relationship between correlation and the F-values.</li>
  <li>The L1- and L2-regularisations have a perfect correlation. Visually scanning the coefficients also showed they were almost exactly the same. This makes me suspicious and wonder if I did something wrong. As far as I could tell I did not. This is something for me to investigate in future, because I was expecting L1 and L2 regularisations to produce some noticable difference.</li>
  <li>The logistic regressions and correlations have a very strong correlation. From my understanding this is not a coincidence - I believe there is a direct relationship between the coefficients and correlations (at least when there is only one feature variable).</li>
  <li>The XGBoost feature importances are least correlated with the others. I suppose this makes, because I think the other four quantities have direct mathematical relationships between them, whereas tree-models are qualitatively different.</li>
</ul>

<p>To remove the non-linearity in some of the charts above, I decided to also plot feature <em>ranks</em> that these different measures produce. 
<img src="/blog/images/santander2_ranks.png" alt=""></p>

<p>There is nothing new shown in these graphs - it just makes the patterns listed above a bit clearer.</p>

<h2 id="models-with-only-the-most-important-features">
<a class="anchor" href="#models-with-only-the-most-important-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Models with only the most important features</h2>
<p>Next I produced several logistic models keeping differing amounts of features removed. I used logistic models because they were the quickest to create.
<img src="/blog/images/santander2_feat5.png" alt="">
<img src="/blog/images/santander2_feat10.png" alt="">
<img src="/blog/images/santander2_feat50.png" alt="">
<img src="/blog/images/santander2_feat100.png" alt="">
<img src="/blog/images/santander2_feat150.png" alt="">
<img src="/blog/images/santander2_feat200.png" alt=""></p>

<p>The patterns here are clear. My takeaways are:</p>
<ul>
  <li>As you increase the number of features kept, the model improves.</li>
  <li>The 100 least important features provide very little information to the models.</li>
  <li>However, the 100 least important features do provide <em>some</em> information. The models did not improve by removing them.</li>
</ul>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>
<p>It looks like removing the least important features has not improved our models. The one thing it did improve was the time taken to create the models. Also, in a real-life situation (where we knew what the variables corresponded to), we would have gained insight into which variables are important, which presumably would help in decision-making.</p>

<h2 id="next-steps">
<a class="anchor" href="#next-steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Next steps</h2>
<p>The next thing I will do is some hyper-parameter optimisations. After that, I will have used up all the tricks I have available, and then look at other people’s models and see what I can learn.</p>

  </div><a class="u-url" href="/blog/python/data%20science/2020/07/13/santander2.html" hidden></a>
</article>