<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Santander Dataset, Part I | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Santander Dataset, Part I" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models." />
<meta property="og:description" content="I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-01T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-01T00:00:00-05:00","dateModified":"2020-07-01T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html"},"description":"I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models.","@type":"BlogPosting","url":"https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html","headline":"Santander Dataset, Part I","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>





<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Santander Dataset, Part I | Lovkush Agarwal</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Santander Dataset, Part I" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models." />
<meta property="og:description" content="I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models." />
<link rel="canonical" href="https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html" />
<meta property="og:url" content="https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html" />
<meta property="og:site_name" content="Lovkush Agarwal" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-01T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-01T00:00:00-05:00","dateModified":"2020-07-01T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html"},"description":"I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models.","@type":"BlogPosting","url":"https://lovkush-a.github.io/blog/python/data%20science/2020/07/01/santander1.html","headline":"Santander Dataset, Part I","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://lovkush-a.github.io/blog/feed.xml" title="Lovkush Agarwal" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-29327017-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Lovkush Agarwal</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Santander Dataset, Part I</h1><p class="page-description">I start a new project modelling another Kaggle dataset. To start things off, I create some default models, to establish a starting point for future models.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-01T00:00:00-05:00" itemprop="datePublished">
        Jul 1, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#data science">data science</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#other-posts-in-series">Other posts in series</a></li>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#default-models">Default models</a>
<ul>
<li class="toc-entry toc-h3"><a href="#logistic-regression">Logistic Regression</a></li>
<li class="toc-entry toc-h3"><a href="#decision-tree">Decision Tree</a></li>
<li class="toc-entry toc-h3"><a href="#knn">kNN</a></li>
<li class="toc-entry toc-h3"><a href="#xgboost">XGboost</a></li>
<li class="toc-entry toc-h3"><a href="#svm">SVM</a></li>
<li class="toc-entry toc-h3"><a href="#handmade-model">Handmade model</a></li>
<li class="toc-entry toc-h3"><a href="#random-model">Random model</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#next-steps">Next steps</a></li>
</ul><h2 id="other-posts-in-series">
<a class="anchor" href="#other-posts-in-series" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other posts in series</h2>

<ul>
  <li>
    <p><a href="/blog/python/data%20science/2020/07/18/santander3.html">Santander Dataset, Part III, Learning from others</a></p>
  </li>
  <li>
    <p><a href="/blog/python/data%20science/2020/07/13/santander2.html">Santander Dataset, Part II, Feature Selection</a></p>
  </li>
</ul>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<p>I have started a new project. I had another look at the Kaggle datasets and chose <a href="https://www.kaggle.com/c/santander-customer-transaction-prediction">this Santander</a> dataset. The data is (superficially?) similar to that from the Credit Card Fraud dataset I have previously analysed: the data is clean, all numerical, and the task is to create a binary classifier.  A big difference is that this Santander dataset has 200 features, whereas the Credit Card Fraud one had only 30 features. I presume this will make a difference (maybe I have to do some feature selection?), but I guess I will find out soon! Another difference is that we have two datasets: a training dataset on which we should create our models, and a testing dataset on which we use our models to make predictions which are then submitted to Kaggle.</p>

<p>Like with the credit card fraud project, I will start this one by creating some default models, and hopefully gain some ideas on how I ought to progress.</p>

<h2 id="default-models">
<a class="anchor" href="#default-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Default models</h2>
<p>Some minimal data exploration shows that 90% of the training data has a target feature of 0 and 10% has target feature of 1. Due to this skew, I decide to us AUPRC to evaluate the models. Note that I split this training set further into a sub-training set and sub-testing set, fit the models on the sub-training set and evaluate the models using AUPRC on the sub-testing test. (Is there better terminology for this kind of thing?!).</p>

<p>Also, I did minor pre-processing, namely, I re-scaled the features to have a mean of 0 and a standard deviation of 1.</p>

<h3 id="logistic-regression">
<a class="anchor" href="#logistic-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logistic Regression</h3>
<p><img src="/blog/images/santander1_logistic.png" alt="">
This does not look good. Lets see how other models do.</p>

<h3 id="decision-tree">
<a class="anchor" href="#decision-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Decision Tree</h3>
<p><img src="/blog/images/santander1_tree.png" alt="">
This does even worse! I guess this should be expected of decision trees. It is also worth noting that this took a couple of minutes to create, so I decided not to create a random forest, because I presume it would take a very long time.</p>

<h3 id="knn">
<a class="anchor" href="#knn" aria-hidden="true"><span class="octicon octicon-link"></span></a>kNN</h3>
<p><img src="/blog/images/santander1_knn.png" alt="">
This also does poorly. However, I recently started reading <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Elements of Statistical Learning</a> and it describes the ‘curse of dimensionality’, so I am not surprised by this low performance. Roughly, if you have many features, the nearest neighbours of a point are unlikely to be close to the point, and so not representative of that point.</p>

<h3 id="xgboost">
<a class="anchor" href="#xgboost" aria-hidden="true"><span class="octicon octicon-link"></span></a>XGboost</h3>
<p><img src="/blog/images/santander1_xgb.png" alt="">
This has basically the same PRC as logistic regression, and much worse than what was achieved in the default credit card dataset.</p>

<h3 id="svm">
<a class="anchor" href="#svm" aria-hidden="true"><span class="octicon octicon-link"></span></a>SVM</h3>
<p><img src="/blog/images/santander1_svm.png" alt="">
And once again, a similar PRC to logistic regression and xgboost. Note that this one took a few hours to complete, so I will not be using these again for this project.</p>

<h3 id="handmade-model">
<a class="anchor" href="#handmade-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Handmade model</h3>
<p><img src="/blog/images/santander1_handmade.png" alt="">
I used the same <a href="/blog/2020/05/19/creditcard3.html">handmade model</a> that I created in the credit card fraud project over here. As can be seen, this performance is in between the worst so far (decision tree and knn) and the best so far (xgboost, regression, svm). To me, this suggests that main issue is not with the number of features, but that maybe the dataset itself is difficult to work with and that it is hard to distinguish between the two classes.</p>

<h3 id="random-model">
<a class="anchor" href="#random-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random model</h3>
<p><img src="/blog/images/santander1_random.png" alt="">
Based on all these graphs above, it was clear I had misunderstood something basic about the PRC graph. I believed that the worst case scenario for this curve was a straight line joining the two corners, and initially thought that these models were doing either worse or just as good as a random model. After thinking for a bit, I realised my mis-understanding. To confirm my feelings, I created a purely random model and the PRC is above. This curve makes sense: we get a straight line with a precision of 0.1 because 10% of the data has a target value of 1. If you’re just making random guesses, then you should expect that 10% of the predicted positive cases are truly positive, i.e., you should expect to get a precision of 0.1.</p>

<p>I think this misunderstanding arose because I got mixed up with ROC curves, in which a random model does produce a straight line.</p>

<h2 id="next-steps">
<a class="anchor" href="#next-steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Next steps</h2>
<p>I will try to improve the models by doing some feature selection.</p>

  </div><a class="u-url" href="/blog/python/data%20science/2020/07/01/santander1.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog for my data science learning and projects</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/lovkush-a" title="lovkush-a"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/lovkushatleeds" title="lovkushatleeds"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
