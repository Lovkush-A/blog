---
toc: true
layout: post
description: I end this project by summarising what I did and summarising what I learnt by having a look at other people's examples on Kaggle.
categories: [python, data science]
title: Credit Card Fraud, Part VI, Summary and Lessons from Kaggle
image: "images/creditcard_6_xgb_roc2.png"
---
## Summaries
### Part I
In Part I, I describe the framework and create the first set of models using default settings. I tried logistic regression, decision tree, random forest and xgboost models, and they respectively achieved an AUPRC of 0.616, 0.746, 0.842 and 0.856. Since then, I have learnt about more models and if I were to do this project again, I would also have included a support vector machine model and a k-nearest-neighbour model.

![]({{ site.baseurl }}/images/creditcard_1_logistic.png)
![]({{ site.baseurl }}/images/creditcard_1_tree.png)
![]({{ site.baseurl }}/images/creditcard_1_forest.png)
